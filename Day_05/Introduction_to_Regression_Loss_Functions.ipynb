{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MySureStart/spring_2023_vail-oholguins/blob/main/Day_05/Introduction_to_Regression_Loss_Functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "861ncVuLPeyF"
      },
      "source": [
        "![image_2021-10-30_133041.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Day 5 Objectives: \n",
        "* To introduce you to loss functions. \n"
      ],
      "metadata": {
        "id": "5rokz_Xr0kDG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCtJpzBrYWqr"
      },
      "source": [
        "# Loss Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4fAWIkUYUyR"
      },
      "source": [
        "Loss functions define what a good prediction is and isn’t. Choosing the right loss function dictates how well your estimator (machine learning model) will be. The criteria by which an estimator is scrutinized is its performance - how accurate the model's decisions are. This calls for a way to measure how far a particular iteration of the model is from the actual values. This is where loss functions come into play.\n",
        "\n",
        "Loss functions measure how far an estimated value is from its true value. A loss function maps decisions to their associated costs. Loss functions are not fixed, they change depending on the task in hand and the goal to be met.\n",
        "\n",
        "Worth to note we can speak of different kind of loss functions: **regression loss** functions and **classification loss** functions.\n",
        "\n",
        "Regression loss function describes the difference between the values that a model is predicting and the actual values of the labels. So the loss function has a meaning on a labeled data when we compare the prediction to the label at a single point of time. This loss function is often called the error function or the error formula. Typical error functions we use for regression models are L1 and L2, Huber loss, Quantile loss, log cosh loss.\n",
        "\n",
        "**Note**: L1 loss is also know as Mean Absolute Error. L2 Loss is also know as Mean Square Error or Quadratic loss.\n",
        "\n",
        "Loss functions for classification represent the price paid for inaccuracy of predictions in classification problems (problems of identifying which category a particular observation belongs to). To name a few: log loss, focal loss, exponential loss, hinge loss, relative entropy loss and other.\n",
        "\n",
        "*Note*: While more commonly used in regression, the square loss function can be re-written and utilized for classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I1Y9BQxq72l"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6Hpicvr6XJ0"
      },
      "source": [
        "# Regression Losses\n",
        "\n",
        "Remember, in regression, the output would be a real value. We need some loss functions which compares two real values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMoFFw2VUR7j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd9fd4ba-1ddc-4dcb-cae9-4f2256dbf634"
      },
      "source": [
        "(train_features, train_labels), (test_features, test_labels) = keras.datasets.boston_housing.load_data()\n",
        "\n",
        "# get per-feature statistics (mean, standard deviation) from the training set to normalize by\n",
        "train_mean = np.mean(train_features, axis=0)\n",
        "train_std = np.std(train_features, axis=0)\n",
        "train_features = (train_features - train_mean) / train_std"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/boston_housing.npz\n",
            "57026/57026 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAdSFpdB6aDH"
      },
      "source": [
        "## Mean Squared Error [MSE]\n",
        "\n",
        "As the name suggests, Mean square error is measured as the average of squared difference between predictions and actual observations. It’s only concerned with the average magnitude of error irrespective of their direction. \n",
        "\n",
        "However, due to squaring, predictions which are far away from actual values are penalized heavily in comparison to less deviated predictions. Plus MSE has nice mathematical properties which makes it easier to calculate gradients.\n",
        "\n",
        "Let's assume there are $n$ data samples, for $i^{th}$ sample; the actual output is $y_i$ and $\\hat{y}_i$ is the estimated output from the regression model. \n",
        "\n",
        "We first square the difference between the original and estimated output with $(y_i - \\hat{y}_i)^2$. Then we take sum of the squared difference for all the samples. And finally divide it by the total count of samples, which is $n$. \n",
        "\n",
        "$$MSE = \\frac{\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}{n}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5OO5ZfoYtCJ",
        "outputId": "01012a19-fa23-44a3-b2b0-babdc978a36b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = keras.Sequential([\n",
        "        tf.keras.layers.Dense(10, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(50, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(20, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='mse',\n",
        "              metrics=['mse'])\n",
        "\n",
        "model.fit(train_features, train_labels, epochs=500, validation_split = 0.1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "12/12 [==============================] - 7s 20ms/step - loss: 595.9063 - mse: 595.9063 - val_loss: 495.2377 - val_mse: 495.2377\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 572.8571 - mse: 572.8571 - val_loss: 474.8853 - val_mse: 474.8853\n",
            "Epoch 3/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 546.4629 - mse: 546.4629 - val_loss: 448.1055 - val_mse: 448.1055\n",
            "Epoch 4/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 509.4462 - mse: 509.4462 - val_loss: 408.7358 - val_mse: 408.7358\n",
            "Epoch 5/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 455.5752 - mse: 455.5752 - val_loss: 350.5110 - val_mse: 350.5110\n",
            "Epoch 6/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 381.3395 - mse: 381.3395 - val_loss: 273.8528 - val_mse: 273.8528\n",
            "Epoch 7/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 290.7801 - mse: 290.7801 - val_loss: 185.2934 - val_mse: 185.2934\n",
            "Epoch 8/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 194.2817 - mse: 194.2817 - val_loss: 113.3795 - val_mse: 113.3795\n",
            "Epoch 9/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 131.0245 - mse: 131.0245 - val_loss: 82.7013 - val_mse: 82.7013\n",
            "Epoch 10/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 105.9412 - mse: 105.9412 - val_loss: 72.1456 - val_mse: 72.1456\n",
            "Epoch 11/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 88.7084 - mse: 88.7084 - val_loss: 59.0074 - val_mse: 59.0074\n",
            "Epoch 12/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 73.4556 - mse: 73.4556 - val_loss: 48.0271 - val_mse: 48.0271\n",
            "Epoch 13/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 61.4129 - mse: 61.4129 - val_loss: 39.8640 - val_mse: 39.8640\n",
            "Epoch 14/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 50.7376 - mse: 50.7376 - val_loss: 34.3631 - val_mse: 34.3631\n",
            "Epoch 15/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 42.4893 - mse: 42.4893 - val_loss: 29.2210 - val_mse: 29.2210\n",
            "Epoch 16/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 35.8798 - mse: 35.8798 - val_loss: 25.5986 - val_mse: 25.5986\n",
            "Epoch 17/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 31.3513 - mse: 31.3513 - val_loss: 22.2688 - val_mse: 22.2688\n",
            "Epoch 18/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 27.9266 - mse: 27.9266 - val_loss: 20.4096 - val_mse: 20.4096\n",
            "Epoch 19/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 25.7189 - mse: 25.7189 - val_loss: 18.7239 - val_mse: 18.7239\n",
            "Epoch 20/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 23.9370 - mse: 23.9370 - val_loss: 18.2062 - val_mse: 18.2062\n",
            "Epoch 21/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 22.7865 - mse: 22.7865 - val_loss: 17.2031 - val_mse: 17.2031\n",
            "Epoch 22/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 21.8367 - mse: 21.8367 - val_loss: 16.4955 - val_mse: 16.4955\n",
            "Epoch 23/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 21.1216 - mse: 21.1216 - val_loss: 16.5297 - val_mse: 16.5297\n",
            "Epoch 24/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 20.4604 - mse: 20.4604 - val_loss: 15.7376 - val_mse: 15.7376\n",
            "Epoch 25/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 19.8984 - mse: 19.8984 - val_loss: 15.5168 - val_mse: 15.5168\n",
            "Epoch 26/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 19.3622 - mse: 19.3622 - val_loss: 15.1916 - val_mse: 15.1916\n",
            "Epoch 27/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 18.9091 - mse: 18.9091 - val_loss: 14.7245 - val_mse: 14.7245\n",
            "Epoch 28/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 18.5800 - mse: 18.5800 - val_loss: 14.1938 - val_mse: 14.1938\n",
            "Epoch 29/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 18.0810 - mse: 18.0810 - val_loss: 14.3435 - val_mse: 14.3435\n",
            "Epoch 30/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 17.7822 - mse: 17.7822 - val_loss: 14.0578 - val_mse: 14.0578\n",
            "Epoch 31/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 17.4374 - mse: 17.4374 - val_loss: 13.7852 - val_mse: 13.7852\n",
            "Epoch 32/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 17.0481 - mse: 17.0481 - val_loss: 13.5676 - val_mse: 13.5676\n",
            "Epoch 33/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 16.8118 - mse: 16.8118 - val_loss: 12.8843 - val_mse: 12.8843\n",
            "Epoch 34/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 16.4364 - mse: 16.4364 - val_loss: 13.2550 - val_mse: 13.2550\n",
            "Epoch 35/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 16.1293 - mse: 16.1293 - val_loss: 12.9160 - val_mse: 12.9160\n",
            "Epoch 36/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 15.7903 - mse: 15.7903 - val_loss: 12.6866 - val_mse: 12.6866\n",
            "Epoch 37/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 15.6355 - mse: 15.6355 - val_loss: 12.1093 - val_mse: 12.1093\n",
            "Epoch 38/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 15.3077 - mse: 15.3077 - val_loss: 12.5173 - val_mse: 12.5173\n",
            "Epoch 39/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 15.2071 - mse: 15.2071 - val_loss: 12.0651 - val_mse: 12.0651\n",
            "Epoch 40/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 14.9346 - mse: 14.9346 - val_loss: 12.1056 - val_mse: 12.1056\n",
            "Epoch 41/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 14.7077 - mse: 14.7077 - val_loss: 11.6474 - val_mse: 11.6474\n",
            "Epoch 42/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 14.4972 - mse: 14.4972 - val_loss: 11.9937 - val_mse: 11.9937\n",
            "Epoch 43/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 14.2131 - mse: 14.2131 - val_loss: 11.7800 - val_mse: 11.7800\n",
            "Epoch 44/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 14.0948 - mse: 14.0948 - val_loss: 11.3955 - val_mse: 11.3955\n",
            "Epoch 45/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 13.9793 - mse: 13.9793 - val_loss: 11.9046 - val_mse: 11.9046\n",
            "Epoch 46/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 13.8376 - mse: 13.8376 - val_loss: 11.0524 - val_mse: 11.0524\n",
            "Epoch 47/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 13.7387 - mse: 13.7387 - val_loss: 11.9951 - val_mse: 11.9951\n",
            "Epoch 48/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 13.4109 - mse: 13.4109 - val_loss: 11.2568 - val_mse: 11.2568\n",
            "Epoch 49/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 13.3322 - mse: 13.3322 - val_loss: 11.3015 - val_mse: 11.3015\n",
            "Epoch 50/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 13.1918 - mse: 13.1918 - val_loss: 11.6977 - val_mse: 11.6977\n",
            "Epoch 51/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 12.9745 - mse: 12.9745 - val_loss: 11.0406 - val_mse: 11.0406\n",
            "Epoch 52/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 12.7537 - mse: 12.7537 - val_loss: 11.3983 - val_mse: 11.3983\n",
            "Epoch 53/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 12.7485 - mse: 12.7485 - val_loss: 10.8952 - val_mse: 10.8952\n",
            "Epoch 54/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 12.5050 - mse: 12.5050 - val_loss: 10.9951 - val_mse: 10.9951\n",
            "Epoch 55/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 12.4613 - mse: 12.4613 - val_loss: 10.7271 - val_mse: 10.7271\n",
            "Epoch 56/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 12.3015 - mse: 12.3015 - val_loss: 10.7130 - val_mse: 10.7130\n",
            "Epoch 57/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 12.2009 - mse: 12.2009 - val_loss: 10.6509 - val_mse: 10.6509\n",
            "Epoch 58/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 12.1541 - mse: 12.1541 - val_loss: 10.4514 - val_mse: 10.4514\n",
            "Epoch 59/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 12.0173 - mse: 12.0173 - val_loss: 10.4954 - val_mse: 10.4954\n",
            "Epoch 60/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 11.8913 - mse: 11.8913 - val_loss: 10.4223 - val_mse: 10.4223\n",
            "Epoch 61/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 11.9092 - mse: 11.9092 - val_loss: 10.4906 - val_mse: 10.4906\n",
            "Epoch 62/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 11.7600 - mse: 11.7600 - val_loss: 10.5363 - val_mse: 10.5363\n",
            "Epoch 63/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 11.6656 - mse: 11.6656 - val_loss: 10.1958 - val_mse: 10.1958\n",
            "Epoch 64/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 11.6200 - mse: 11.6200 - val_loss: 10.2287 - val_mse: 10.2287\n",
            "Epoch 65/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 11.5787 - mse: 11.5787 - val_loss: 10.2923 - val_mse: 10.2923\n",
            "Epoch 66/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 11.4013 - mse: 11.4013 - val_loss: 10.1033 - val_mse: 10.1033\n",
            "Epoch 67/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 11.3731 - mse: 11.3731 - val_loss: 10.0456 - val_mse: 10.0456\n",
            "Epoch 68/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 11.2709 - mse: 11.2709 - val_loss: 10.1540 - val_mse: 10.1540\n",
            "Epoch 69/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 11.2295 - mse: 11.2295 - val_loss: 9.9102 - val_mse: 9.9102\n",
            "Epoch 70/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 11.1353 - mse: 11.1353 - val_loss: 9.9945 - val_mse: 9.9945\n",
            "Epoch 71/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 11.1073 - mse: 11.1073 - val_loss: 9.9897 - val_mse: 9.9897\n",
            "Epoch 72/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 11.0346 - mse: 11.0346 - val_loss: 9.9745 - val_mse: 9.9745\n",
            "Epoch 73/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 10.9105 - mse: 10.9105 - val_loss: 9.7783 - val_mse: 9.7783\n",
            "Epoch 74/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 10.8733 - mse: 10.8733 - val_loss: 9.7277 - val_mse: 9.7277\n",
            "Epoch 75/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 10.8030 - mse: 10.8030 - val_loss: 9.6965 - val_mse: 9.6965\n",
            "Epoch 76/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 10.6962 - mse: 10.6962 - val_loss: 9.5947 - val_mse: 9.5947\n",
            "Epoch 77/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 10.6475 - mse: 10.6475 - val_loss: 9.6335 - val_mse: 9.6335\n",
            "Epoch 78/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 10.5751 - mse: 10.5751 - val_loss: 9.7043 - val_mse: 9.7043\n",
            "Epoch 79/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 10.5264 - mse: 10.5264 - val_loss: 9.4323 - val_mse: 9.4323\n",
            "Epoch 80/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 10.4354 - mse: 10.4354 - val_loss: 9.4525 - val_mse: 9.4525\n",
            "Epoch 81/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 10.4197 - mse: 10.4197 - val_loss: 9.3261 - val_mse: 9.3261\n",
            "Epoch 82/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 10.3323 - mse: 10.3323 - val_loss: 9.1754 - val_mse: 9.1754\n",
            "Epoch 83/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 10.2633 - mse: 10.2633 - val_loss: 9.1747 - val_mse: 9.1747\n",
            "Epoch 84/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 10.3137 - mse: 10.3137 - val_loss: 9.0917 - val_mse: 9.0917\n",
            "Epoch 85/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 10.1237 - mse: 10.1237 - val_loss: 9.1019 - val_mse: 9.1019\n",
            "Epoch 86/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 10.0747 - mse: 10.0747 - val_loss: 8.9416 - val_mse: 8.9416\n",
            "Epoch 87/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 10.0477 - mse: 10.0477 - val_loss: 9.2625 - val_mse: 9.2625\n",
            "Epoch 88/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 10.0804 - mse: 10.0804 - val_loss: 8.8853 - val_mse: 8.8853\n",
            "Epoch 89/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9.9866 - mse: 9.9866 - val_loss: 9.1198 - val_mse: 9.1198\n",
            "Epoch 90/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9.9842 - mse: 9.9842 - val_loss: 8.7469 - val_mse: 8.7469\n",
            "Epoch 91/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 10.0384 - mse: 10.0384 - val_loss: 9.0147 - val_mse: 9.0147\n",
            "Epoch 92/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9.8318 - mse: 9.8318 - val_loss: 8.5942 - val_mse: 8.5942\n",
            "Epoch 93/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9.7704 - mse: 9.7704 - val_loss: 8.8681 - val_mse: 8.8681\n",
            "Epoch 94/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9.6831 - mse: 9.6831 - val_loss: 8.4366 - val_mse: 8.4366\n",
            "Epoch 95/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9.5831 - mse: 9.5831 - val_loss: 8.5699 - val_mse: 8.5699\n",
            "Epoch 96/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 9.5482 - mse: 9.5482 - val_loss: 8.5343 - val_mse: 8.5343\n",
            "Epoch 97/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 9.5029 - mse: 9.5029 - val_loss: 8.4350 - val_mse: 8.4350\n",
            "Epoch 98/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 9.4075 - mse: 9.4075 - val_loss: 8.4203 - val_mse: 8.4203\n",
            "Epoch 99/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 9.3766 - mse: 9.3766 - val_loss: 8.2352 - val_mse: 8.2352\n",
            "Epoch 100/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 9.3138 - mse: 9.3138 - val_loss: 8.3981 - val_mse: 8.3981\n",
            "Epoch 101/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 9.3543 - mse: 9.3543 - val_loss: 8.4027 - val_mse: 8.4027\n",
            "Epoch 102/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 9.2111 - mse: 9.2111 - val_loss: 8.1272 - val_mse: 8.1272\n",
            "Epoch 103/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 9.3030 - mse: 9.3030 - val_loss: 8.3223 - val_mse: 8.3223\n",
            "Epoch 104/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 9.0990 - mse: 9.0990 - val_loss: 8.1632 - val_mse: 8.1632\n",
            "Epoch 105/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 9.1238 - mse: 9.1238 - val_loss: 8.0834 - val_mse: 8.0834\n",
            "Epoch 106/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 9.1603 - mse: 9.1603 - val_loss: 8.1999 - val_mse: 8.1999\n",
            "Epoch 107/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 8.9349 - mse: 8.9349 - val_loss: 7.9617 - val_mse: 7.9617\n",
            "Epoch 108/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 8.9170 - mse: 8.9170 - val_loss: 7.9604 - val_mse: 7.9604\n",
            "Epoch 109/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 9.0154 - mse: 9.0154 - val_loss: 8.0051 - val_mse: 8.0051\n",
            "Epoch 110/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 9.0811 - mse: 9.0811 - val_loss: 7.6759 - val_mse: 7.6759\n",
            "Epoch 111/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 8.7590 - mse: 8.7590 - val_loss: 7.9654 - val_mse: 7.9654\n",
            "Epoch 112/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 8.7218 - mse: 8.7218 - val_loss: 7.6642 - val_mse: 7.6642\n",
            "Epoch 113/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 8.8023 - mse: 8.8023 - val_loss: 7.4891 - val_mse: 7.4891\n",
            "Epoch 114/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 8.7224 - mse: 8.7224 - val_loss: 7.8884 - val_mse: 7.8884\n",
            "Epoch 115/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 8.7306 - mse: 8.7306 - val_loss: 7.4231 - val_mse: 7.4231\n",
            "Epoch 116/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 8.6710 - mse: 8.6710 - val_loss: 7.6678 - val_mse: 7.6678\n",
            "Epoch 117/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 8.5266 - mse: 8.5266 - val_loss: 7.4181 - val_mse: 7.4181\n",
            "Epoch 118/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 8.4907 - mse: 8.4907 - val_loss: 7.6272 - val_mse: 7.6272\n",
            "Epoch 119/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 8.4163 - mse: 8.4163 - val_loss: 7.5773 - val_mse: 7.5773\n",
            "Epoch 120/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 8.3439 - mse: 8.3439 - val_loss: 7.4254 - val_mse: 7.4254\n",
            "Epoch 121/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.3383 - mse: 8.3383 - val_loss: 7.3157 - val_mse: 7.3157\n",
            "Epoch 122/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.3012 - mse: 8.3012 - val_loss: 7.4426 - val_mse: 7.4426\n",
            "Epoch 123/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8.1993 - mse: 8.1993 - val_loss: 7.0974 - val_mse: 7.0974\n",
            "Epoch 124/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 8.2316 - mse: 8.2316 - val_loss: 7.2048 - val_mse: 7.2048\n",
            "Epoch 125/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 8.1124 - mse: 8.1124 - val_loss: 7.1731 - val_mse: 7.1731\n",
            "Epoch 126/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.1133 - mse: 8.1133 - val_loss: 7.0110 - val_mse: 7.0110\n",
            "Epoch 127/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 8.0395 - mse: 8.0395 - val_loss: 7.1515 - val_mse: 7.1515\n",
            "Epoch 128/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.9785 - mse: 7.9785 - val_loss: 7.0011 - val_mse: 7.0011\n",
            "Epoch 129/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 8.0097 - mse: 8.0097 - val_loss: 6.9329 - val_mse: 6.9329\n",
            "Epoch 130/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 7.9137 - mse: 7.9137 - val_loss: 6.9891 - val_mse: 6.9891\n",
            "Epoch 131/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.9052 - mse: 7.9052 - val_loss: 7.0178 - val_mse: 7.0178\n",
            "Epoch 132/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 7.8372 - mse: 7.8372 - val_loss: 6.8063 - val_mse: 6.8063\n",
            "Epoch 133/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.8135 - mse: 7.8135 - val_loss: 6.8847 - val_mse: 6.8847\n",
            "Epoch 134/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.7564 - mse: 7.7564 - val_loss: 6.8902 - val_mse: 6.8902\n",
            "Epoch 135/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.7518 - mse: 7.7518 - val_loss: 6.8045 - val_mse: 6.8045\n",
            "Epoch 136/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 7.7318 - mse: 7.7318 - val_loss: 6.7688 - val_mse: 6.7688\n",
            "Epoch 137/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 7.6003 - mse: 7.6003 - val_loss: 6.6527 - val_mse: 6.6527\n",
            "Epoch 138/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 7.6241 - mse: 7.6241 - val_loss: 6.7268 - val_mse: 6.7268\n",
            "Epoch 139/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 7.5118 - mse: 7.5118 - val_loss: 6.7468 - val_mse: 6.7468\n",
            "Epoch 140/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 7.5696 - mse: 7.5696 - val_loss: 6.6346 - val_mse: 6.6346\n",
            "Epoch 141/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 7.4768 - mse: 7.4768 - val_loss: 6.5625 - val_mse: 6.5625\n",
            "Epoch 142/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 7.4241 - mse: 7.4241 - val_loss: 6.6484 - val_mse: 6.6484\n",
            "Epoch 143/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.4607 - mse: 7.4607 - val_loss: 6.4789 - val_mse: 6.4789\n",
            "Epoch 144/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 7.3826 - mse: 7.3826 - val_loss: 6.4355 - val_mse: 6.4355\n",
            "Epoch 145/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 7.2974 - mse: 7.2974 - val_loss: 6.4924 - val_mse: 6.4924\n",
            "Epoch 146/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.3225 - mse: 7.3225 - val_loss: 6.4762 - val_mse: 6.4762\n",
            "Epoch 147/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 7.2842 - mse: 7.2842 - val_loss: 6.5369 - val_mse: 6.5369\n",
            "Epoch 148/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.2574 - mse: 7.2574 - val_loss: 6.4184 - val_mse: 6.4184\n",
            "Epoch 149/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 7.2775 - mse: 7.2775 - val_loss: 6.5229 - val_mse: 6.5229\n",
            "Epoch 150/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 7.1723 - mse: 7.1723 - val_loss: 6.5108 - val_mse: 6.5108\n",
            "Epoch 151/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.1811 - mse: 7.1811 - val_loss: 6.4861 - val_mse: 6.4861\n",
            "Epoch 152/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.1669 - mse: 7.1669 - val_loss: 6.2118 - val_mse: 6.2118\n",
            "Epoch 153/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 7.0250 - mse: 7.0250 - val_loss: 6.3279 - val_mse: 6.3279\n",
            "Epoch 154/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.9722 - mse: 6.9722 - val_loss: 6.4324 - val_mse: 6.4324\n",
            "Epoch 155/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.9143 - mse: 6.9143 - val_loss: 6.4463 - val_mse: 6.4463\n",
            "Epoch 156/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.9832 - mse: 6.9832 - val_loss: 6.4094 - val_mse: 6.4094\n",
            "Epoch 157/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.8366 - mse: 6.8366 - val_loss: 6.3677 - val_mse: 6.3677\n",
            "Epoch 158/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.8396 - mse: 6.8396 - val_loss: 6.3541 - val_mse: 6.3541\n",
            "Epoch 159/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.9414 - mse: 6.9414 - val_loss: 6.2683 - val_mse: 6.2683\n",
            "Epoch 160/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.7339 - mse: 6.7339 - val_loss: 6.1806 - val_mse: 6.1806\n",
            "Epoch 161/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.7099 - mse: 6.7099 - val_loss: 6.2354 - val_mse: 6.2354\n",
            "Epoch 162/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.7791 - mse: 6.7791 - val_loss: 6.2577 - val_mse: 6.2577\n",
            "Epoch 163/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.7591 - mse: 6.7591 - val_loss: 6.2518 - val_mse: 6.2518\n",
            "Epoch 164/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.9214 - mse: 6.9214 - val_loss: 6.3756 - val_mse: 6.3756\n",
            "Epoch 165/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.9833 - mse: 6.9833 - val_loss: 6.3336 - val_mse: 6.3336\n",
            "Epoch 166/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.5128 - mse: 6.5128 - val_loss: 6.5614 - val_mse: 6.5614\n",
            "Epoch 167/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.5075 - mse: 6.5075 - val_loss: 6.4256 - val_mse: 6.4256\n",
            "Epoch 168/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.5221 - mse: 6.5221 - val_loss: 6.3209 - val_mse: 6.3209\n",
            "Epoch 169/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.4894 - mse: 6.4894 - val_loss: 6.2505 - val_mse: 6.2505\n",
            "Epoch 170/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.4078 - mse: 6.4078 - val_loss: 6.2094 - val_mse: 6.2094\n",
            "Epoch 171/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.3511 - mse: 6.3511 - val_loss: 6.2103 - val_mse: 6.2103\n",
            "Epoch 172/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 6.3227 - mse: 6.3227 - val_loss: 6.3302 - val_mse: 6.3302\n",
            "Epoch 173/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.4172 - mse: 6.4172 - val_loss: 6.1891 - val_mse: 6.1891\n",
            "Epoch 174/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 6.3044 - mse: 6.3044 - val_loss: 6.1772 - val_mse: 6.1772\n",
            "Epoch 175/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.2212 - mse: 6.2212 - val_loss: 6.3068 - val_mse: 6.3068\n",
            "Epoch 176/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.2095 - mse: 6.2095 - val_loss: 6.2835 - val_mse: 6.2835\n",
            "Epoch 177/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 6.1731 - mse: 6.1731 - val_loss: 6.1002 - val_mse: 6.1002\n",
            "Epoch 178/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.2108 - mse: 6.2108 - val_loss: 6.1492 - val_mse: 6.1492\n",
            "Epoch 179/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.1280 - mse: 6.1280 - val_loss: 6.1134 - val_mse: 6.1134\n",
            "Epoch 180/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.1569 - mse: 6.1569 - val_loss: 6.0270 - val_mse: 6.0270\n",
            "Epoch 181/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 6.1015 - mse: 6.1015 - val_loss: 6.1919 - val_mse: 6.1919\n",
            "Epoch 182/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 6.0796 - mse: 6.0796 - val_loss: 6.2380 - val_mse: 6.2380\n",
            "Epoch 183/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 6.0579 - mse: 6.0579 - val_loss: 6.3667 - val_mse: 6.3667\n",
            "Epoch 184/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.0149 - mse: 6.0149 - val_loss: 6.1063 - val_mse: 6.1063\n",
            "Epoch 185/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.9709 - mse: 5.9709 - val_loss: 6.0017 - val_mse: 6.0017\n",
            "Epoch 186/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.9849 - mse: 5.9849 - val_loss: 6.0482 - val_mse: 6.0482\n",
            "Epoch 187/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 6.0591 - mse: 6.0591 - val_loss: 6.0782 - val_mse: 6.0782\n",
            "Epoch 188/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.9281 - mse: 5.9281 - val_loss: 6.1247 - val_mse: 6.1247\n",
            "Epoch 189/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.8394 - mse: 5.8394 - val_loss: 6.1523 - val_mse: 6.1523\n",
            "Epoch 190/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.7905 - mse: 5.7905 - val_loss: 6.1007 - val_mse: 6.1007\n",
            "Epoch 191/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.7783 - mse: 5.7783 - val_loss: 6.2052 - val_mse: 6.2052\n",
            "Epoch 192/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.7869 - mse: 5.7869 - val_loss: 6.3607 - val_mse: 6.3607\n",
            "Epoch 193/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.7465 - mse: 5.7465 - val_loss: 6.1506 - val_mse: 6.1506\n",
            "Epoch 194/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.7688 - mse: 5.7688 - val_loss: 6.0995 - val_mse: 6.0995\n",
            "Epoch 195/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.8894 - mse: 5.8894 - val_loss: 6.2014 - val_mse: 6.2014\n",
            "Epoch 196/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.8524 - mse: 5.8524 - val_loss: 6.3669 - val_mse: 6.3669\n",
            "Epoch 197/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.7047 - mse: 5.7047 - val_loss: 6.2056 - val_mse: 6.2056\n",
            "Epoch 198/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.7307 - mse: 5.7307 - val_loss: 6.1649 - val_mse: 6.1649\n",
            "Epoch 199/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.7204 - mse: 5.7204 - val_loss: 6.0790 - val_mse: 6.0790\n",
            "Epoch 200/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.5766 - mse: 5.5766 - val_loss: 6.2829 - val_mse: 6.2829\n",
            "Epoch 201/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.6206 - mse: 5.6206 - val_loss: 6.2530 - val_mse: 6.2530\n",
            "Epoch 202/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.5010 - mse: 5.5010 - val_loss: 6.1168 - val_mse: 6.1168\n",
            "Epoch 203/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.5461 - mse: 5.5461 - val_loss: 6.2095 - val_mse: 6.2095\n",
            "Epoch 204/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.5863 - mse: 5.5863 - val_loss: 6.1818 - val_mse: 6.1818\n",
            "Epoch 205/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.4961 - mse: 5.4961 - val_loss: 6.3501 - val_mse: 6.3501\n",
            "Epoch 206/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.5106 - mse: 5.5106 - val_loss: 6.3135 - val_mse: 6.3135\n",
            "Epoch 207/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.5095 - mse: 5.5095 - val_loss: 6.1512 - val_mse: 6.1512\n",
            "Epoch 208/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.4502 - mse: 5.4502 - val_loss: 6.3506 - val_mse: 6.3506\n",
            "Epoch 209/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.4186 - mse: 5.4186 - val_loss: 6.3015 - val_mse: 6.3015\n",
            "Epoch 210/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.4672 - mse: 5.4672 - val_loss: 5.9719 - val_mse: 5.9719\n",
            "Epoch 211/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.4466 - mse: 5.4466 - val_loss: 6.4270 - val_mse: 6.4270\n",
            "Epoch 212/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.4320 - mse: 5.4320 - val_loss: 6.4991 - val_mse: 6.4991\n",
            "Epoch 213/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.5183 - mse: 5.5183 - val_loss: 6.2261 - val_mse: 6.2261\n",
            "Epoch 214/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.2189 - mse: 5.2189 - val_loss: 6.0568 - val_mse: 6.0568\n",
            "Epoch 215/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.2780 - mse: 5.2780 - val_loss: 6.0939 - val_mse: 6.0939\n",
            "Epoch 216/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.2889 - mse: 5.2889 - val_loss: 6.2611 - val_mse: 6.2611\n",
            "Epoch 217/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.2648 - mse: 5.2648 - val_loss: 6.3156 - val_mse: 6.3156\n",
            "Epoch 218/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.3846 - mse: 5.3846 - val_loss: 6.1857 - val_mse: 6.1857\n",
            "Epoch 219/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.4203 - mse: 5.4203 - val_loss: 6.0382 - val_mse: 6.0382\n",
            "Epoch 220/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.1348 - mse: 5.1348 - val_loss: 6.1440 - val_mse: 6.1440\n",
            "Epoch 221/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.1148 - mse: 5.1148 - val_loss: 6.2307 - val_mse: 6.2307\n",
            "Epoch 222/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.1141 - mse: 5.1141 - val_loss: 6.1808 - val_mse: 6.1808\n",
            "Epoch 223/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 5.1127 - mse: 5.1127 - val_loss: 6.1377 - val_mse: 6.1377\n",
            "Epoch 224/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.1569 - mse: 5.1569 - val_loss: 6.1189 - val_mse: 6.1189\n",
            "Epoch 225/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.0922 - mse: 5.0922 - val_loss: 5.9100 - val_mse: 5.9100\n",
            "Epoch 226/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.0415 - mse: 5.0415 - val_loss: 6.1552 - val_mse: 6.1552\n",
            "Epoch 227/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.1909 - mse: 5.1909 - val_loss: 6.1821 - val_mse: 6.1821\n",
            "Epoch 228/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 5.2003 - mse: 5.2003 - val_loss: 6.1011 - val_mse: 6.1011\n",
            "Epoch 229/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 5.1183 - mse: 5.1183 - val_loss: 6.3029 - val_mse: 6.3029\n",
            "Epoch 230/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4.9093 - mse: 4.9093 - val_loss: 6.2656 - val_mse: 6.2656\n",
            "Epoch 231/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4.9491 - mse: 4.9491 - val_loss: 6.1047 - val_mse: 6.1047\n",
            "Epoch 232/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.9683 - mse: 4.9683 - val_loss: 6.2431 - val_mse: 6.2431\n",
            "Epoch 233/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.9447 - mse: 4.9447 - val_loss: 6.2478 - val_mse: 6.2478\n",
            "Epoch 234/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.9952 - mse: 4.9952 - val_loss: 6.3766 - val_mse: 6.3766\n",
            "Epoch 235/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 4.9416 - mse: 4.9416 - val_loss: 6.3603 - val_mse: 6.3603\n",
            "Epoch 236/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 4.8817 - mse: 4.8817 - val_loss: 6.4820 - val_mse: 6.4820\n",
            "Epoch 237/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.8353 - mse: 4.8353 - val_loss: 5.8971 - val_mse: 5.8971\n",
            "Epoch 238/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.8835 - mse: 4.8835 - val_loss: 6.3369 - val_mse: 6.3369\n",
            "Epoch 239/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.1131 - mse: 5.1131 - val_loss: 6.4342 - val_mse: 6.4342\n",
            "Epoch 240/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.7119 - mse: 4.7119 - val_loss: 6.0504 - val_mse: 6.0504\n",
            "Epoch 241/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.8930 - mse: 4.8930 - val_loss: 6.2567 - val_mse: 6.2567\n",
            "Epoch 242/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 4.8127 - mse: 4.8127 - val_loss: 6.4892 - val_mse: 6.4892\n",
            "Epoch 243/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.7059 - mse: 4.7059 - val_loss: 6.4302 - val_mse: 6.4302\n",
            "Epoch 244/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.8460 - mse: 4.8460 - val_loss: 6.1951 - val_mse: 6.1951\n",
            "Epoch 245/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 4.7482 - mse: 4.7482 - val_loss: 6.4622 - val_mse: 6.4622\n",
            "Epoch 246/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 4.6988 - mse: 4.6988 - val_loss: 6.2117 - val_mse: 6.2117\n",
            "Epoch 247/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.6950 - mse: 4.6950 - val_loss: 6.2878 - val_mse: 6.2878\n",
            "Epoch 248/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.6415 - mse: 4.6415 - val_loss: 6.2914 - val_mse: 6.2914\n",
            "Epoch 249/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.6867 - mse: 4.6867 - val_loss: 6.3083 - val_mse: 6.3083\n",
            "Epoch 250/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 5.0004 - mse: 5.0004 - val_loss: 7.0566 - val_mse: 7.0566\n",
            "Epoch 251/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 4.8056 - mse: 4.8056 - val_loss: 6.0964 - val_mse: 6.0964\n",
            "Epoch 252/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 4.6747 - mse: 4.6747 - val_loss: 6.3961 - val_mse: 6.3961\n",
            "Epoch 253/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 4.5447 - mse: 4.5447 - val_loss: 6.3197 - val_mse: 6.3197\n",
            "Epoch 254/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 4.5874 - mse: 4.5874 - val_loss: 6.3314 - val_mse: 6.3314\n",
            "Epoch 255/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4.5114 - mse: 4.5114 - val_loss: 6.3640 - val_mse: 6.3640\n",
            "Epoch 256/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4.5558 - mse: 4.5558 - val_loss: 6.1694 - val_mse: 6.1694\n",
            "Epoch 257/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.5694 - mse: 4.5694 - val_loss: 6.4187 - val_mse: 6.4187\n",
            "Epoch 258/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4.4962 - mse: 4.4962 - val_loss: 6.2150 - val_mse: 6.2150\n",
            "Epoch 259/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4.4419 - mse: 4.4419 - val_loss: 6.5041 - val_mse: 6.5041\n",
            "Epoch 260/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4.4322 - mse: 4.4322 - val_loss: 6.3455 - val_mse: 6.3455\n",
            "Epoch 261/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4.5348 - mse: 4.5348 - val_loss: 6.3381 - val_mse: 6.3381\n",
            "Epoch 262/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4.4850 - mse: 4.4850 - val_loss: 6.5065 - val_mse: 6.5065\n",
            "Epoch 263/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.4428 - mse: 4.4428 - val_loss: 6.7010 - val_mse: 6.7010\n",
            "Epoch 264/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4.3809 - mse: 4.3809 - val_loss: 6.3480 - val_mse: 6.3480\n",
            "Epoch 265/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.4180 - mse: 4.4180 - val_loss: 6.5335 - val_mse: 6.5335\n",
            "Epoch 266/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4.3557 - mse: 4.3557 - val_loss: 6.3523 - val_mse: 6.3523\n",
            "Epoch 267/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4.3871 - mse: 4.3871 - val_loss: 6.4458 - val_mse: 6.4458\n",
            "Epoch 268/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.2990 - mse: 4.2990 - val_loss: 6.5071 - val_mse: 6.5071\n",
            "Epoch 269/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4.3426 - mse: 4.3426 - val_loss: 6.5408 - val_mse: 6.5408\n",
            "Epoch 270/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.3262 - mse: 4.3262 - val_loss: 6.3100 - val_mse: 6.3100\n",
            "Epoch 271/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 4.3074 - mse: 4.3074 - val_loss: 6.5632 - val_mse: 6.5632\n",
            "Epoch 272/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.3575 - mse: 4.3575 - val_loss: 6.5675 - val_mse: 6.5675\n",
            "Epoch 273/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.2888 - mse: 4.2888 - val_loss: 6.2608 - val_mse: 6.2608\n",
            "Epoch 274/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4.2530 - mse: 4.2530 - val_loss: 6.6702 - val_mse: 6.6702\n",
            "Epoch 275/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.2351 - mse: 4.2351 - val_loss: 6.4860 - val_mse: 6.4860\n",
            "Epoch 276/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.2529 - mse: 4.2529 - val_loss: 6.5750 - val_mse: 6.5750\n",
            "Epoch 277/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.3397 - mse: 4.3397 - val_loss: 6.5510 - val_mse: 6.5510\n",
            "Epoch 278/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4.3699 - mse: 4.3699 - val_loss: 6.5106 - val_mse: 6.5106\n",
            "Epoch 279/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4.2395 - mse: 4.2395 - val_loss: 6.9392 - val_mse: 6.9392\n",
            "Epoch 280/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.1955 - mse: 4.1955 - val_loss: 6.7303 - val_mse: 6.7303\n",
            "Epoch 281/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4.2537 - mse: 4.2537 - val_loss: 6.6981 - val_mse: 6.6981\n",
            "Epoch 282/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4.2480 - mse: 4.2480 - val_loss: 6.6284 - val_mse: 6.6284\n",
            "Epoch 283/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.1314 - mse: 4.1314 - val_loss: 6.4827 - val_mse: 6.4827\n",
            "Epoch 284/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.1398 - mse: 4.1398 - val_loss: 6.6305 - val_mse: 6.6305\n",
            "Epoch 285/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4.1290 - mse: 4.1290 - val_loss: 6.5087 - val_mse: 6.5087\n",
            "Epoch 286/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.1581 - mse: 4.1581 - val_loss: 6.6776 - val_mse: 6.6776\n",
            "Epoch 287/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.1648 - mse: 4.1648 - val_loss: 6.5632 - val_mse: 6.5632\n",
            "Epoch 288/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4.1903 - mse: 4.1903 - val_loss: 6.7492 - val_mse: 6.7492\n",
            "Epoch 289/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.0535 - mse: 4.0535 - val_loss: 6.5765 - val_mse: 6.5765\n",
            "Epoch 290/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4.0620 - mse: 4.0620 - val_loss: 6.6964 - val_mse: 6.6964\n",
            "Epoch 291/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4.1456 - mse: 4.1456 - val_loss: 6.6175 - val_mse: 6.6175\n",
            "Epoch 292/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.2424 - mse: 4.2424 - val_loss: 6.8698 - val_mse: 6.8698\n",
            "Epoch 293/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4.1262 - mse: 4.1262 - val_loss: 6.6980 - val_mse: 6.6980\n",
            "Epoch 294/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4.0330 - mse: 4.0330 - val_loss: 6.7440 - val_mse: 6.7440\n",
            "Epoch 295/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.9911 - mse: 3.9911 - val_loss: 6.7646 - val_mse: 6.7646\n",
            "Epoch 296/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4.0124 - mse: 4.0124 - val_loss: 6.6325 - val_mse: 6.6325\n",
            "Epoch 297/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.1853 - mse: 4.1853 - val_loss: 6.8262 - val_mse: 6.8262\n",
            "Epoch 298/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 4.0267 - mse: 4.0267 - val_loss: 6.7680 - val_mse: 6.7680\n",
            "Epoch 299/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.9919 - mse: 3.9919 - val_loss: 6.8517 - val_mse: 6.8517\n",
            "Epoch 300/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 3.9805 - mse: 3.9805 - val_loss: 6.7785 - val_mse: 6.7785\n",
            "Epoch 301/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.9387 - mse: 3.9387 - val_loss: 6.7181 - val_mse: 6.7181\n",
            "Epoch 302/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.9727 - mse: 3.9727 - val_loss: 6.7411 - val_mse: 6.7411\n",
            "Epoch 303/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.9241 - mse: 3.9241 - val_loss: 6.8894 - val_mse: 6.8894\n",
            "Epoch 304/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.9390 - mse: 3.9390 - val_loss: 6.8178 - val_mse: 6.8178\n",
            "Epoch 305/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.9188 - mse: 3.9188 - val_loss: 6.8521 - val_mse: 6.8521\n",
            "Epoch 306/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.9214 - mse: 3.9214 - val_loss: 7.0196 - val_mse: 7.0196\n",
            "Epoch 307/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.8923 - mse: 3.8923 - val_loss: 6.7258 - val_mse: 6.7258\n",
            "Epoch 308/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 4.0295 - mse: 4.0295 - val_loss: 6.8402 - val_mse: 6.8402\n",
            "Epoch 309/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.8837 - mse: 3.8837 - val_loss: 6.8932 - val_mse: 6.8932\n",
            "Epoch 310/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.8886 - mse: 3.8886 - val_loss: 6.6646 - val_mse: 6.6646\n",
            "Epoch 311/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.9647 - mse: 3.9647 - val_loss: 7.1588 - val_mse: 7.1588\n",
            "Epoch 312/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.9802 - mse: 3.9802 - val_loss: 6.8335 - val_mse: 6.8335\n",
            "Epoch 313/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.9309 - mse: 3.9309 - val_loss: 6.7639 - val_mse: 6.7639\n",
            "Epoch 314/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.8175 - mse: 3.8175 - val_loss: 6.8739 - val_mse: 6.8739\n",
            "Epoch 315/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.8262 - mse: 3.8262 - val_loss: 7.2218 - val_mse: 7.2218\n",
            "Epoch 316/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.8809 - mse: 3.8809 - val_loss: 6.9346 - val_mse: 6.9346\n",
            "Epoch 317/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.8250 - mse: 3.8250 - val_loss: 6.7002 - val_mse: 6.7002\n",
            "Epoch 318/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.8652 - mse: 3.8652 - val_loss: 7.0439 - val_mse: 7.0439\n",
            "Epoch 319/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.8436 - mse: 3.8436 - val_loss: 6.7139 - val_mse: 6.7139\n",
            "Epoch 320/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.7584 - mse: 3.7584 - val_loss: 7.0650 - val_mse: 7.0650\n",
            "Epoch 321/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.7756 - mse: 3.7756 - val_loss: 6.9548 - val_mse: 6.9548\n",
            "Epoch 322/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.7381 - mse: 3.7381 - val_loss: 7.4273 - val_mse: 7.4273\n",
            "Epoch 323/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 4.0266 - mse: 4.0266 - val_loss: 6.9129 - val_mse: 6.9129\n",
            "Epoch 324/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.6442 - mse: 3.6442 - val_loss: 7.3294 - val_mse: 7.3294\n",
            "Epoch 325/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.7208 - mse: 3.7208 - val_loss: 6.9440 - val_mse: 6.9440\n",
            "Epoch 326/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.7145 - mse: 3.7145 - val_loss: 6.8628 - val_mse: 6.8628\n",
            "Epoch 327/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.6879 - mse: 3.6879 - val_loss: 6.9966 - val_mse: 6.9966\n",
            "Epoch 328/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.7137 - mse: 3.7137 - val_loss: 6.9799 - val_mse: 6.9799\n",
            "Epoch 329/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.6479 - mse: 3.6479 - val_loss: 7.0009 - val_mse: 7.0009\n",
            "Epoch 330/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.7070 - mse: 3.7070 - val_loss: 7.1077 - val_mse: 7.1077\n",
            "Epoch 331/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.7509 - mse: 3.7509 - val_loss: 6.6598 - val_mse: 6.6598\n",
            "Epoch 332/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.8165 - mse: 3.8165 - val_loss: 7.1216 - val_mse: 7.1216\n",
            "Epoch 333/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.6474 - mse: 3.6474 - val_loss: 6.9110 - val_mse: 6.9110\n",
            "Epoch 334/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.8067 - mse: 3.8067 - val_loss: 7.3416 - val_mse: 7.3416\n",
            "Epoch 335/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.6789 - mse: 3.6789 - val_loss: 6.8718 - val_mse: 6.8718\n",
            "Epoch 336/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.6867 - mse: 3.6867 - val_loss: 6.8806 - val_mse: 6.8806\n",
            "Epoch 337/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.6406 - mse: 3.6406 - val_loss: 7.0283 - val_mse: 7.0283\n",
            "Epoch 338/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.6945 - mse: 3.6945 - val_loss: 6.9182 - val_mse: 6.9182\n",
            "Epoch 339/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.7040 - mse: 3.7040 - val_loss: 7.0569 - val_mse: 7.0569\n",
            "Epoch 340/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.5673 - mse: 3.5673 - val_loss: 6.8856 - val_mse: 6.8856\n",
            "Epoch 341/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.6299 - mse: 3.6299 - val_loss: 6.8009 - val_mse: 6.8009\n",
            "Epoch 342/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.5867 - mse: 3.5867 - val_loss: 6.7716 - val_mse: 6.7716\n",
            "Epoch 343/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.5702 - mse: 3.5702 - val_loss: 7.0365 - val_mse: 7.0365\n",
            "Epoch 344/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.5411 - mse: 3.5411 - val_loss: 6.8541 - val_mse: 6.8541\n",
            "Epoch 345/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.5722 - mse: 3.5722 - val_loss: 6.8028 - val_mse: 6.8028\n",
            "Epoch 346/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.5541 - mse: 3.5541 - val_loss: 6.8831 - val_mse: 6.8831\n",
            "Epoch 347/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.5275 - mse: 3.5275 - val_loss: 6.9080 - val_mse: 6.9080\n",
            "Epoch 348/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.5232 - mse: 3.5232 - val_loss: 7.2186 - val_mse: 7.2186\n",
            "Epoch 349/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.6177 - mse: 3.6177 - val_loss: 6.8495 - val_mse: 6.8495\n",
            "Epoch 350/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.7062 - mse: 3.7062 - val_loss: 6.7807 - val_mse: 6.7807\n",
            "Epoch 351/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.5985 - mse: 3.5985 - val_loss: 7.0499 - val_mse: 7.0499\n",
            "Epoch 352/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.4549 - mse: 3.4549 - val_loss: 7.0972 - val_mse: 7.0972\n",
            "Epoch 353/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.6024 - mse: 3.6024 - val_loss: 7.0156 - val_mse: 7.0156\n",
            "Epoch 354/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.4888 - mse: 3.4888 - val_loss: 7.1697 - val_mse: 7.1697\n",
            "Epoch 355/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.5429 - mse: 3.5429 - val_loss: 7.5413 - val_mse: 7.5413\n",
            "Epoch 356/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.5333 - mse: 3.5333 - val_loss: 7.0079 - val_mse: 7.0079\n",
            "Epoch 357/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.5746 - mse: 3.5746 - val_loss: 7.1667 - val_mse: 7.1667\n",
            "Epoch 358/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.5776 - mse: 3.5776 - val_loss: 7.0616 - val_mse: 7.0616\n",
            "Epoch 359/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.4521 - mse: 3.4521 - val_loss: 7.0715 - val_mse: 7.0715\n",
            "Epoch 360/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.5533 - mse: 3.5533 - val_loss: 7.3516 - val_mse: 7.3516\n",
            "Epoch 361/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.4370 - mse: 3.4370 - val_loss: 7.1827 - val_mse: 7.1827\n",
            "Epoch 362/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.5277 - mse: 3.5277 - val_loss: 7.0419 - val_mse: 7.0419\n",
            "Epoch 363/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.4355 - mse: 3.4355 - val_loss: 7.1250 - val_mse: 7.1250\n",
            "Epoch 364/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.3942 - mse: 3.3942 - val_loss: 6.9484 - val_mse: 6.9484\n",
            "Epoch 365/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 3.3658 - mse: 3.3658 - val_loss: 7.0743 - val_mse: 7.0743\n",
            "Epoch 366/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3.3965 - mse: 3.3965 - val_loss: 6.8941 - val_mse: 6.8941\n",
            "Epoch 367/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3.3852 - mse: 3.3852 - val_loss: 7.0045 - val_mse: 7.0045\n",
            "Epoch 368/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 3.3562 - mse: 3.3562 - val_loss: 6.8769 - val_mse: 6.8769\n",
            "Epoch 369/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3.3839 - mse: 3.3839 - val_loss: 7.0304 - val_mse: 7.0304\n",
            "Epoch 370/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3.3878 - mse: 3.3878 - val_loss: 7.0721 - val_mse: 7.0721\n",
            "Epoch 371/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 3.3754 - mse: 3.3754 - val_loss: 6.8760 - val_mse: 6.8760\n",
            "Epoch 372/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.3304 - mse: 3.3304 - val_loss: 7.0762 - val_mse: 7.0762\n",
            "Epoch 373/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 3.3738 - mse: 3.3738 - val_loss: 7.1226 - val_mse: 7.1226\n",
            "Epoch 374/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3.3748 - mse: 3.3748 - val_loss: 6.9381 - val_mse: 6.9381\n",
            "Epoch 375/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3.3547 - mse: 3.3547 - val_loss: 7.1768 - val_mse: 7.1768\n",
            "Epoch 376/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.3838 - mse: 3.3838 - val_loss: 7.1340 - val_mse: 7.1340\n",
            "Epoch 377/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3.3490 - mse: 3.3490 - val_loss: 7.1962 - val_mse: 7.1962\n",
            "Epoch 378/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3.4508 - mse: 3.4508 - val_loss: 6.9592 - val_mse: 6.9592\n",
            "Epoch 379/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 3.4263 - mse: 3.4263 - val_loss: 6.8772 - val_mse: 6.8772\n",
            "Epoch 380/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 3.3937 - mse: 3.3937 - val_loss: 7.2885 - val_mse: 7.2885\n",
            "Epoch 381/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3.4381 - mse: 3.4381 - val_loss: 7.0765 - val_mse: 7.0765\n",
            "Epoch 382/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 3.3858 - mse: 3.3858 - val_loss: 6.7935 - val_mse: 6.7935\n",
            "Epoch 383/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 3.3117 - mse: 3.3117 - val_loss: 7.2984 - val_mse: 7.2984\n",
            "Epoch 384/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.3281 - mse: 3.3281 - val_loss: 6.9297 - val_mse: 6.9297\n",
            "Epoch 385/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 3.3667 - mse: 3.3667 - val_loss: 7.3908 - val_mse: 7.3908\n",
            "Epoch 386/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.3700 - mse: 3.3700 - val_loss: 7.2523 - val_mse: 7.2523\n",
            "Epoch 387/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.2930 - mse: 3.2930 - val_loss: 6.8257 - val_mse: 6.8257\n",
            "Epoch 388/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.3991 - mse: 3.3991 - val_loss: 7.6636 - val_mse: 7.6636\n",
            "Epoch 389/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.3366 - mse: 3.3366 - val_loss: 6.8313 - val_mse: 6.8313\n",
            "Epoch 390/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.2535 - mse: 3.2535 - val_loss: 6.8847 - val_mse: 6.8847\n",
            "Epoch 391/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.2501 - mse: 3.2501 - val_loss: 7.0520 - val_mse: 7.0520\n",
            "Epoch 392/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.2621 - mse: 3.2621 - val_loss: 6.9314 - val_mse: 6.9314\n",
            "Epoch 393/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.2577 - mse: 3.2577 - val_loss: 7.1671 - val_mse: 7.1671\n",
            "Epoch 394/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 3.2253 - mse: 3.2253 - val_loss: 7.2333 - val_mse: 7.2333\n",
            "Epoch 395/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.1919 - mse: 3.1919 - val_loss: 7.0976 - val_mse: 7.0976\n",
            "Epoch 396/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.2405 - mse: 3.2405 - val_loss: 6.9912 - val_mse: 6.9912\n",
            "Epoch 397/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.1778 - mse: 3.1778 - val_loss: 7.3204 - val_mse: 7.3204\n",
            "Epoch 398/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.2036 - mse: 3.2036 - val_loss: 7.0191 - val_mse: 7.0191\n",
            "Epoch 399/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.2172 - mse: 3.2172 - val_loss: 7.4535 - val_mse: 7.4535\n",
            "Epoch 400/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.2195 - mse: 3.2195 - val_loss: 7.1136 - val_mse: 7.1136\n",
            "Epoch 401/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.2142 - mse: 3.2142 - val_loss: 6.9582 - val_mse: 6.9582\n",
            "Epoch 402/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.1687 - mse: 3.1687 - val_loss: 7.1950 - val_mse: 7.1950\n",
            "Epoch 403/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.1250 - mse: 3.1250 - val_loss: 7.1904 - val_mse: 7.1904\n",
            "Epoch 404/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.1256 - mse: 3.1256 - val_loss: 7.3056 - val_mse: 7.3056\n",
            "Epoch 405/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 3.2449 - mse: 3.2449 - val_loss: 7.1497 - val_mse: 7.1497\n",
            "Epoch 406/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.1468 - mse: 3.1468 - val_loss: 7.4037 - val_mse: 7.4037\n",
            "Epoch 407/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.2722 - mse: 3.2722 - val_loss: 7.1419 - val_mse: 7.1419\n",
            "Epoch 408/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.3148 - mse: 3.3148 - val_loss: 6.9082 - val_mse: 6.9082\n",
            "Epoch 409/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.1447 - mse: 3.1447 - val_loss: 7.3440 - val_mse: 7.3440\n",
            "Epoch 410/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.1233 - mse: 3.1233 - val_loss: 7.0095 - val_mse: 7.0095\n",
            "Epoch 411/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.1882 - mse: 3.1882 - val_loss: 7.4180 - val_mse: 7.4180\n",
            "Epoch 412/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.1054 - mse: 3.1054 - val_loss: 7.1245 - val_mse: 7.1245\n",
            "Epoch 413/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.2024 - mse: 3.2024 - val_loss: 7.0903 - val_mse: 7.0903\n",
            "Epoch 414/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.0806 - mse: 3.0806 - val_loss: 7.1526 - val_mse: 7.1526\n",
            "Epoch 415/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.1696 - mse: 3.1696 - val_loss: 7.1151 - val_mse: 7.1151\n",
            "Epoch 416/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.0591 - mse: 3.0591 - val_loss: 7.2199 - val_mse: 7.2199\n",
            "Epoch 417/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.1172 - mse: 3.1172 - val_loss: 7.4663 - val_mse: 7.4663\n",
            "Epoch 418/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.1494 - mse: 3.1494 - val_loss: 7.1158 - val_mse: 7.1158\n",
            "Epoch 419/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.1455 - mse: 3.1455 - val_loss: 7.6104 - val_mse: 7.6104\n",
            "Epoch 420/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.2025 - mse: 3.2025 - val_loss: 7.3730 - val_mse: 7.3730\n",
            "Epoch 421/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.0891 - mse: 3.0891 - val_loss: 7.0125 - val_mse: 7.0125\n",
            "Epoch 422/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.0927 - mse: 3.0927 - val_loss: 7.3212 - val_mse: 7.3212\n",
            "Epoch 423/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.0737 - mse: 3.0737 - val_loss: 7.3224 - val_mse: 7.3224\n",
            "Epoch 424/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.0381 - mse: 3.0381 - val_loss: 7.0573 - val_mse: 7.0573\n",
            "Epoch 425/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.1112 - mse: 3.1112 - val_loss: 7.0730 - val_mse: 7.0730\n",
            "Epoch 426/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.1322 - mse: 3.1322 - val_loss: 7.3626 - val_mse: 7.3626\n",
            "Epoch 427/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2.9991 - mse: 2.9991 - val_loss: 6.8998 - val_mse: 6.8998\n",
            "Epoch 428/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.1091 - mse: 3.1091 - val_loss: 6.9746 - val_mse: 6.9746\n",
            "Epoch 429/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.0677 - mse: 3.0677 - val_loss: 6.9617 - val_mse: 6.9617\n",
            "Epoch 430/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 3.0554 - mse: 3.0554 - val_loss: 7.0794 - val_mse: 7.0794\n",
            "Epoch 431/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.1101 - mse: 3.1101 - val_loss: 7.6430 - val_mse: 7.6430\n",
            "Epoch 432/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.1689 - mse: 3.1689 - val_loss: 7.3447 - val_mse: 7.3447\n",
            "Epoch 433/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.0548 - mse: 3.0548 - val_loss: 7.0444 - val_mse: 7.0444\n",
            "Epoch 434/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.9741 - mse: 2.9741 - val_loss: 7.2434 - val_mse: 7.2434\n",
            "Epoch 435/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.9914 - mse: 2.9914 - val_loss: 7.0445 - val_mse: 7.0445\n",
            "Epoch 436/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.0215 - mse: 3.0215 - val_loss: 6.9744 - val_mse: 6.9744\n",
            "Epoch 437/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.1365 - mse: 3.1365 - val_loss: 7.4375 - val_mse: 7.4375\n",
            "Epoch 438/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.9500 - mse: 2.9500 - val_loss: 6.9945 - val_mse: 6.9945\n",
            "Epoch 439/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.0146 - mse: 3.0146 - val_loss: 7.1112 - val_mse: 7.1112\n",
            "Epoch 440/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.0710 - mse: 3.0710 - val_loss: 7.2130 - val_mse: 7.2130\n",
            "Epoch 441/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.0044 - mse: 3.0044 - val_loss: 7.4109 - val_mse: 7.4109\n",
            "Epoch 442/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2.9555 - mse: 2.9555 - val_loss: 6.9919 - val_mse: 6.9919\n",
            "Epoch 443/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.0697 - mse: 3.0697 - val_loss: 7.2034 - val_mse: 7.2034\n",
            "Epoch 444/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 3.0306 - mse: 3.0306 - val_loss: 7.4697 - val_mse: 7.4697\n",
            "Epoch 445/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2.9203 - mse: 2.9203 - val_loss: 7.0247 - val_mse: 7.0247\n",
            "Epoch 446/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.9129 - mse: 2.9129 - val_loss: 7.2785 - val_mse: 7.2785\n",
            "Epoch 447/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.8933 - mse: 2.8933 - val_loss: 6.9596 - val_mse: 6.9596\n",
            "Epoch 448/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.0093 - mse: 3.0093 - val_loss: 7.2349 - val_mse: 7.2349\n",
            "Epoch 449/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.9701 - mse: 2.9701 - val_loss: 7.1588 - val_mse: 7.1588\n",
            "Epoch 450/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.9840 - mse: 2.9840 - val_loss: 7.0326 - val_mse: 7.0326\n",
            "Epoch 451/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.9711 - mse: 2.9711 - val_loss: 7.0522 - val_mse: 7.0522\n",
            "Epoch 452/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.9063 - mse: 2.9063 - val_loss: 7.2139 - val_mse: 7.2139\n",
            "Epoch 453/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.9194 - mse: 2.9194 - val_loss: 7.5205 - val_mse: 7.5205\n",
            "Epoch 454/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2.9266 - mse: 2.9266 - val_loss: 7.2563 - val_mse: 7.2563\n",
            "Epoch 455/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.9659 - mse: 2.9659 - val_loss: 7.0539 - val_mse: 7.0539\n",
            "Epoch 456/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.9015 - mse: 2.9015 - val_loss: 7.0802 - val_mse: 7.0802\n",
            "Epoch 457/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.9101 - mse: 2.9101 - val_loss: 6.8414 - val_mse: 6.8414\n",
            "Epoch 458/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.9174 - mse: 2.9174 - val_loss: 7.4586 - val_mse: 7.4586\n",
            "Epoch 459/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2.8661 - mse: 2.8661 - val_loss: 7.0442 - val_mse: 7.0442\n",
            "Epoch 460/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.9339 - mse: 2.9339 - val_loss: 7.0363 - val_mse: 7.0363\n",
            "Epoch 461/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2.9078 - mse: 2.9078 - val_loss: 6.8840 - val_mse: 6.8840\n",
            "Epoch 462/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.8391 - mse: 2.8391 - val_loss: 7.1123 - val_mse: 7.1123\n",
            "Epoch 463/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2.9794 - mse: 2.9794 - val_loss: 7.3683 - val_mse: 7.3683\n",
            "Epoch 464/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.0605 - mse: 3.0605 - val_loss: 7.2999 - val_mse: 7.2999\n",
            "Epoch 465/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.9450 - mse: 2.9450 - val_loss: 7.1325 - val_mse: 7.1325\n",
            "Epoch 466/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.8261 - mse: 2.8261 - val_loss: 7.0873 - val_mse: 7.0873\n",
            "Epoch 467/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.8490 - mse: 2.8490 - val_loss: 7.1475 - val_mse: 7.1475\n",
            "Epoch 468/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.8454 - mse: 2.8454 - val_loss: 7.1179 - val_mse: 7.1179\n",
            "Epoch 469/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.8519 - mse: 2.8519 - val_loss: 7.0347 - val_mse: 7.0347\n",
            "Epoch 470/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.9475 - mse: 2.9475 - val_loss: 7.1438 - val_mse: 7.1438\n",
            "Epoch 471/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2.8914 - mse: 2.8914 - val_loss: 7.4396 - val_mse: 7.4396\n",
            "Epoch 472/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2.9620 - mse: 2.9620 - val_loss: 7.3945 - val_mse: 7.3945\n",
            "Epoch 473/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2.8772 - mse: 2.8772 - val_loss: 7.1105 - val_mse: 7.1105\n",
            "Epoch 474/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 2.7783 - mse: 2.7783 - val_loss: 7.3801 - val_mse: 7.3801\n",
            "Epoch 475/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.8693 - mse: 2.8693 - val_loss: 6.7906 - val_mse: 6.7906\n",
            "Epoch 476/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.8775 - mse: 2.8775 - val_loss: 7.2458 - val_mse: 7.2458\n",
            "Epoch 477/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2.8061 - mse: 2.8061 - val_loss: 7.0443 - val_mse: 7.0443\n",
            "Epoch 478/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.7994 - mse: 2.7994 - val_loss: 7.2038 - val_mse: 7.2038\n",
            "Epoch 479/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2.8641 - mse: 2.8641 - val_loss: 7.0539 - val_mse: 7.0539\n",
            "Epoch 480/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2.7559 - mse: 2.7559 - val_loss: 7.2722 - val_mse: 7.2722\n",
            "Epoch 481/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2.8405 - mse: 2.8405 - val_loss: 7.0584 - val_mse: 7.0584\n",
            "Epoch 482/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.8504 - mse: 2.8504 - val_loss: 6.9382 - val_mse: 6.9382\n",
            "Epoch 483/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 3.0694 - mse: 3.0694 - val_loss: 7.5646 - val_mse: 7.5646\n",
            "Epoch 484/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.7277 - mse: 2.7277 - val_loss: 6.9834 - val_mse: 6.9834\n",
            "Epoch 485/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.7128 - mse: 2.7128 - val_loss: 7.6868 - val_mse: 7.6868\n",
            "Epoch 486/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.8395 - mse: 2.8395 - val_loss: 7.2313 - val_mse: 7.2313\n",
            "Epoch 487/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.8340 - mse: 2.8340 - val_loss: 7.0450 - val_mse: 7.0450\n",
            "Epoch 488/500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 3.0406 - mse: 3.0406 - val_loss: 7.4019 - val_mse: 7.4019\n",
            "Epoch 489/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2.7989 - mse: 2.7989 - val_loss: 7.3199 - val_mse: 7.3199\n",
            "Epoch 490/500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.7166 - mse: 2.7166 - val_loss: 6.9562 - val_mse: 6.9562\n",
            "Epoch 491/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.8778 - mse: 2.8778 - val_loss: 7.2409 - val_mse: 7.2409\n",
            "Epoch 492/500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.8106 - mse: 2.8106 - val_loss: 7.5377 - val_mse: 7.5377\n",
            "Epoch 493/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2.8162 - mse: 2.8162 - val_loss: 7.2823 - val_mse: 7.2823\n",
            "Epoch 494/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 2.7206 - mse: 2.7206 - val_loss: 7.2303 - val_mse: 7.2303\n",
            "Epoch 495/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.7838 - mse: 2.7838 - val_loss: 6.8027 - val_mse: 6.8027\n",
            "Epoch 496/500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 2.7789 - mse: 2.7789 - val_loss: 7.2540 - val_mse: 7.2540\n",
            "Epoch 497/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2.7983 - mse: 2.7983 - val_loss: 7.3274 - val_mse: 7.3274\n",
            "Epoch 498/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.7169 - mse: 2.7169 - val_loss: 7.0086 - val_mse: 7.0086\n",
            "Epoch 499/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2.6890 - mse: 2.6890 - val_loss: 6.9155 - val_mse: 6.9155\n",
            "Epoch 500/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2.7315 - mse: 2.7315 - val_loss: 7.3093 - val_mse: 7.3093\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f41a00fba00>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEFaa0VQaKef"
      },
      "source": [
        "## Question 1\n",
        "\n",
        "Now that you know how MSE works, you need to plot the behavior of MSE for the synthetic errors given.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zc5OFsCmadXE"
      },
      "source": [
        "### Answer 1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "gAVdDITm-Bxr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8RF_LUDbdo2",
        "outputId": "4c95972a-7938-4c80-e53c-3090e85f11ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "#original code\n",
        "  #errors = np.arange(-5, 6)\n",
        "  #n = len(errors)\n",
        "\n",
        "actual_outputs = np.arange(-5, 6)\n",
        "n = len(actual_outputs)\n",
        "estimated_outputs = np.zeros(n)\n",
        "\n",
        "mse = (actual_outputs - estimated_outputs)**2\n",
        "#Different code\n",
        "  #mse = (errors)**2\n",
        "\n",
        "plt.plot(actual_outputs, mse, c='#ED4F46', marker='o')\n",
        "plt.grid()\n",
        "plt.xlabel('Difference between actual and estimated ouputs')\n",
        "plt.ylabel('Mean Squared Errors')\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aShHwxvw6hml"
      },
      "source": [
        "## Mean Absolute Error [MAE]\n",
        "\n",
        "Mean absolute error, on the other hand, is measured as the average of sum of absolute differences between predictions and actual observations. \n",
        "\n",
        "Like MSE, this as well measures the magnitude of error without considering their direction. \n",
        "\n",
        "Unlike MSE, MAE needs more complicated tools such as linear programming to compute the gradients. Plus MAE is more robust to outliers since it does not make use of square.\n",
        "\n",
        "Let's assume there are $n$ data samples, for $i^{th}$ sample; the actual output is $y_i$ and $\\hat{y}_i$ is the estimated output from the regression model. \n",
        "\n",
        "We first take the absolute difference between the original and estimated output with $|y_i - \\hat{y}_i|2$. Then we take sum of the absolute differences for all the samples. And finally divide it by the total count of samples, which is $n$. \n",
        "\n",
        "$$MSE = \\frac{\\sum_{i=1}^{n}|y_i - \\hat{y}_i|}{n}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MI9_GEL86hmn",
        "outputId": "f5423f9c-8c98-4f62-cad2-0a68633b3e23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = keras.Sequential([\n",
        "        tf.keras.layers.Dense(100, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(50, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(20, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='mae',\n",
        "              metrics=['mae'])\n",
        "\n",
        "model.fit(train_features, train_labels, epochs=500, validation_split = 0.1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "12/12 [==============================] - 2s 28ms/step - loss: 21.6445 - mae: 21.6445 - val_loss: 19.8064 - val_mae: 19.8064\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 19.8385 - mae: 19.8385 - val_loss: 17.5726 - val_mae: 17.5726\n",
            "Epoch 3/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 16.7596 - mae: 16.7596 - val_loss: 14.0213 - val_mae: 14.0213\n",
            "Epoch 4/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 12.4242 - mae: 12.4242 - val_loss: 8.3778 - val_mae: 8.3778\n",
            "Epoch 5/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 7.6372 - mae: 7.6372 - val_loss: 5.4331 - val_mae: 5.4331\n",
            "Epoch 6/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 5.6233 - mae: 5.6233 - val_loss: 4.1166 - val_mae: 4.1166\n",
            "Epoch 7/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 4.0280 - mae: 4.0280 - val_loss: 3.3738 - val_mae: 3.3738\n",
            "Epoch 8/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 3.3183 - mae: 3.3183 - val_loss: 3.2582 - val_mae: 3.2582\n",
            "Epoch 9/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 3.0925 - mae: 3.0925 - val_loss: 3.1395 - val_mae: 3.1395\n",
            "Epoch 10/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2.9293 - mae: 2.9293 - val_loss: 2.9095 - val_mae: 2.9095\n",
            "Epoch 11/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.7668 - mae: 2.7668 - val_loss: 2.7316 - val_mae: 2.7316\n",
            "Epoch 12/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2.6371 - mae: 2.6371 - val_loss: 2.7857 - val_mae: 2.7857\n",
            "Epoch 13/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2.5481 - mae: 2.5481 - val_loss: 2.6103 - val_mae: 2.6103\n",
            "Epoch 14/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.4732 - mae: 2.4732 - val_loss: 2.5879 - val_mae: 2.5879\n",
            "Epoch 15/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 2.4360 - mae: 2.4360 - val_loss: 2.5344 - val_mae: 2.5344\n",
            "Epoch 16/500\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 2.3981 - mae: 2.3981 - val_loss: 2.4765 - val_mae: 2.4765\n",
            "Epoch 17/500\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 2.3447 - mae: 2.3447 - val_loss: 2.4874 - val_mae: 2.4874\n",
            "Epoch 18/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 2.3126 - mae: 2.3126 - val_loss: 2.3199 - val_mae: 2.3199\n",
            "Epoch 19/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.2536 - mae: 2.2536 - val_loss: 2.4505 - val_mae: 2.4505\n",
            "Epoch 20/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.2282 - mae: 2.2282 - val_loss: 2.4236 - val_mae: 2.4236\n",
            "Epoch 21/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.3080 - mae: 2.3080 - val_loss: 2.3994 - val_mae: 2.3994\n",
            "Epoch 22/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2.2658 - mae: 2.2658 - val_loss: 2.3426 - val_mae: 2.3426\n",
            "Epoch 23/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 2.1657 - mae: 2.1657 - val_loss: 2.4197 - val_mae: 2.4197\n",
            "Epoch 24/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.2166 - mae: 2.2166 - val_loss: 2.3269 - val_mae: 2.3269\n",
            "Epoch 25/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.1047 - mae: 2.1047 - val_loss: 2.3317 - val_mae: 2.3317\n",
            "Epoch 26/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.0958 - mae: 2.0958 - val_loss: 2.3832 - val_mae: 2.3832\n",
            "Epoch 27/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 2.1490 - mae: 2.1490 - val_loss: 2.3160 - val_mae: 2.3160\n",
            "Epoch 28/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.0715 - mae: 2.0715 - val_loss: 2.2014 - val_mae: 2.2014\n",
            "Epoch 29/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.0219 - mae: 2.0219 - val_loss: 2.3044 - val_mae: 2.3044\n",
            "Epoch 30/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.9794 - mae: 1.9794 - val_loss: 2.2979 - val_mae: 2.2979\n",
            "Epoch 31/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 2.0874 - mae: 2.0874 - val_loss: 2.2719 - val_mae: 2.2719\n",
            "Epoch 32/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.9663 - mae: 1.9663 - val_loss: 2.2287 - val_mae: 2.2287\n",
            "Epoch 33/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.9335 - mae: 1.9335 - val_loss: 2.3231 - val_mae: 2.3231\n",
            "Epoch 34/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.9468 - mae: 1.9468 - val_loss: 2.2119 - val_mae: 2.2119\n",
            "Epoch 35/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.9406 - mae: 1.9406 - val_loss: 2.2977 - val_mae: 2.2977\n",
            "Epoch 36/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.9409 - mae: 1.9409 - val_loss: 2.3231 - val_mae: 2.3231\n",
            "Epoch 37/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.9471 - mae: 1.9471 - val_loss: 2.2405 - val_mae: 2.2405\n",
            "Epoch 38/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.9528 - mae: 1.9528 - val_loss: 2.3190 - val_mae: 2.3190\n",
            "Epoch 39/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.9119 - mae: 1.9119 - val_loss: 2.2664 - val_mae: 2.2664\n",
            "Epoch 40/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.9338 - mae: 1.9338 - val_loss: 2.2557 - val_mae: 2.2557\n",
            "Epoch 41/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.8611 - mae: 1.8611 - val_loss: 2.2350 - val_mae: 2.2350\n",
            "Epoch 42/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.8149 - mae: 1.8149 - val_loss: 2.2444 - val_mae: 2.2444\n",
            "Epoch 43/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.7898 - mae: 1.7898 - val_loss: 2.2490 - val_mae: 2.2490\n",
            "Epoch 44/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.7951 - mae: 1.7951 - val_loss: 2.1535 - val_mae: 2.1535\n",
            "Epoch 45/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.7708 - mae: 1.7708 - val_loss: 2.2485 - val_mae: 2.2485\n",
            "Epoch 46/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.8401 - mae: 1.8401 - val_loss: 2.2004 - val_mae: 2.2004\n",
            "Epoch 47/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.7584 - mae: 1.7584 - val_loss: 2.2372 - val_mae: 2.2372\n",
            "Epoch 48/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.7373 - mae: 1.7373 - val_loss: 2.2261 - val_mae: 2.2261\n",
            "Epoch 49/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.8016 - mae: 1.8016 - val_loss: 2.1570 - val_mae: 2.1570\n",
            "Epoch 50/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.7307 - mae: 1.7307 - val_loss: 2.1901 - val_mae: 2.1901\n",
            "Epoch 51/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.7317 - mae: 1.7317 - val_loss: 2.1073 - val_mae: 2.1073\n",
            "Epoch 52/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 1.6786 - mae: 1.6786 - val_loss: 2.2205 - val_mae: 2.2205\n",
            "Epoch 53/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.6942 - mae: 1.6942 - val_loss: 2.2303 - val_mae: 2.2303\n",
            "Epoch 54/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.7010 - mae: 1.7010 - val_loss: 2.1712 - val_mae: 2.1712\n",
            "Epoch 55/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.6559 - mae: 1.6559 - val_loss: 2.1324 - val_mae: 2.1324\n",
            "Epoch 56/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.6251 - mae: 1.6251 - val_loss: 2.1769 - val_mae: 2.1769\n",
            "Epoch 57/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.6096 - mae: 1.6096 - val_loss: 2.1051 - val_mae: 2.1051\n",
            "Epoch 58/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.6789 - mae: 1.6789 - val_loss: 2.4145 - val_mae: 2.4145\n",
            "Epoch 59/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.7698 - mae: 1.7698 - val_loss: 2.1730 - val_mae: 2.1730\n",
            "Epoch 60/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.6941 - mae: 1.6941 - val_loss: 2.2693 - val_mae: 2.2693\n",
            "Epoch 61/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.6548 - mae: 1.6548 - val_loss: 2.1598 - val_mae: 2.1598\n",
            "Epoch 62/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.6279 - mae: 1.6279 - val_loss: 2.1123 - val_mae: 2.1123\n",
            "Epoch 63/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.5991 - mae: 1.5991 - val_loss: 2.0443 - val_mae: 2.0443\n",
            "Epoch 64/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5701 - mae: 1.5701 - val_loss: 2.0955 - val_mae: 2.0955\n",
            "Epoch 65/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.5617 - mae: 1.5617 - val_loss: 2.0370 - val_mae: 2.0370\n",
            "Epoch 66/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5551 - mae: 1.5551 - val_loss: 2.0584 - val_mae: 2.0584\n",
            "Epoch 67/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.6021 - mae: 1.6021 - val_loss: 2.1147 - val_mae: 2.1147\n",
            "Epoch 68/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.6149 - mae: 1.6149 - val_loss: 2.2055 - val_mae: 2.2055\n",
            "Epoch 69/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.5958 - mae: 1.5958 - val_loss: 2.0289 - val_mae: 2.0289\n",
            "Epoch 70/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.5387 - mae: 1.5387 - val_loss: 2.0665 - val_mae: 2.0665\n",
            "Epoch 71/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.4973 - mae: 1.4973 - val_loss: 2.1580 - val_mae: 2.1580\n",
            "Epoch 72/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.5273 - mae: 1.5273 - val_loss: 2.0351 - val_mae: 2.0351\n",
            "Epoch 73/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.4964 - mae: 1.4964 - val_loss: 2.0139 - val_mae: 2.0139\n",
            "Epoch 74/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4981 - mae: 1.4981 - val_loss: 1.9834 - val_mae: 1.9834\n",
            "Epoch 75/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5455 - mae: 1.5455 - val_loss: 2.0483 - val_mae: 2.0483\n",
            "Epoch 76/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.5297 - mae: 1.5297 - val_loss: 1.9646 - val_mae: 1.9646\n",
            "Epoch 77/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.5967 - mae: 1.5967 - val_loss: 2.1622 - val_mae: 2.1622\n",
            "Epoch 78/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.5092 - mae: 1.5092 - val_loss: 2.0507 - val_mae: 2.0507\n",
            "Epoch 79/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4629 - mae: 1.4629 - val_loss: 2.0375 - val_mae: 2.0375\n",
            "Epoch 80/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4896 - mae: 1.4896 - val_loss: 2.0565 - val_mae: 2.0565\n",
            "Epoch 81/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.4792 - mae: 1.4792 - val_loss: 1.9658 - val_mae: 1.9658\n",
            "Epoch 82/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.4484 - mae: 1.4484 - val_loss: 2.0071 - val_mae: 2.0071\n",
            "Epoch 83/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4724 - mae: 1.4724 - val_loss: 2.0088 - val_mae: 2.0088\n",
            "Epoch 84/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4461 - mae: 1.4461 - val_loss: 2.0174 - val_mae: 2.0174\n",
            "Epoch 85/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.4930 - mae: 1.4930 - val_loss: 2.0388 - val_mae: 2.0388\n",
            "Epoch 86/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5043 - mae: 1.5043 - val_loss: 2.0884 - val_mae: 2.0884\n",
            "Epoch 87/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.5053 - mae: 1.5053 - val_loss: 2.0764 - val_mae: 2.0764\n",
            "Epoch 88/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4687 - mae: 1.4687 - val_loss: 1.8970 - val_mae: 1.8970\n",
            "Epoch 89/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.4114 - mae: 1.4114 - val_loss: 1.9408 - val_mae: 1.9408\n",
            "Epoch 90/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4071 - mae: 1.4071 - val_loss: 1.9070 - val_mae: 1.9070\n",
            "Epoch 91/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4343 - mae: 1.4343 - val_loss: 1.9699 - val_mae: 1.9699\n",
            "Epoch 92/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3820 - mae: 1.3820 - val_loss: 1.9546 - val_mae: 1.9546\n",
            "Epoch 93/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3907 - mae: 1.3907 - val_loss: 1.9371 - val_mae: 1.9371\n",
            "Epoch 94/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.3608 - mae: 1.3608 - val_loss: 1.9336 - val_mae: 1.9336\n",
            "Epoch 95/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.3896 - mae: 1.3896 - val_loss: 1.9464 - val_mae: 1.9464\n",
            "Epoch 96/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4151 - mae: 1.4151 - val_loss: 1.8932 - val_mae: 1.8932\n",
            "Epoch 97/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.3735 - mae: 1.3735 - val_loss: 1.9126 - val_mae: 1.9126\n",
            "Epoch 98/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.3689 - mae: 1.3689 - val_loss: 2.0318 - val_mae: 2.0318\n",
            "Epoch 99/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4793 - mae: 1.4793 - val_loss: 1.8373 - val_mae: 1.8373\n",
            "Epoch 100/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.4381 - mae: 1.4381 - val_loss: 1.8886 - val_mae: 1.8886\n",
            "Epoch 101/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3195 - mae: 1.3195 - val_loss: 1.8973 - val_mae: 1.8973\n",
            "Epoch 102/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.3425 - mae: 1.3425 - val_loss: 1.9428 - val_mae: 1.9428\n",
            "Epoch 103/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.4366 - mae: 1.4366 - val_loss: 1.9220 - val_mae: 1.9220\n",
            "Epoch 104/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3451 - mae: 1.3451 - val_loss: 1.8415 - val_mae: 1.8415\n",
            "Epoch 105/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.3714 - mae: 1.3714 - val_loss: 1.8277 - val_mae: 1.8277\n",
            "Epoch 106/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.4374 - mae: 1.4374 - val_loss: 2.0765 - val_mae: 2.0765\n",
            "Epoch 107/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.4360 - mae: 1.4360 - val_loss: 1.9075 - val_mae: 1.9075\n",
            "Epoch 108/500\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.3848 - mae: 1.3848 - val_loss: 1.8937 - val_mae: 1.8937\n",
            "Epoch 109/500\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.3649 - mae: 1.3649 - val_loss: 1.9849 - val_mae: 1.9849\n",
            "Epoch 110/500\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.4025 - mae: 1.4025 - val_loss: 1.8868 - val_mae: 1.8868\n",
            "Epoch 111/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.3928 - mae: 1.3928 - val_loss: 1.7860 - val_mae: 1.7860\n",
            "Epoch 112/500\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 1.3532 - mae: 1.3532 - val_loss: 1.9001 - val_mae: 1.9001\n",
            "Epoch 113/500\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 1.3841 - mae: 1.3841 - val_loss: 1.8120 - val_mae: 1.8120\n",
            "Epoch 114/500\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 1.3600 - mae: 1.3600 - val_loss: 1.8128 - val_mae: 1.8128\n",
            "Epoch 115/500\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 1.2606 - mae: 1.2606 - val_loss: 1.8260 - val_mae: 1.8260\n",
            "Epoch 116/500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 1.2930 - mae: 1.2930 - val_loss: 1.8283 - val_mae: 1.8283\n",
            "Epoch 117/500\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 1.3072 - mae: 1.3072 - val_loss: 1.8696 - val_mae: 1.8696\n",
            "Epoch 118/500\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 1.3277 - mae: 1.3277 - val_loss: 1.9199 - val_mae: 1.9199\n",
            "Epoch 119/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.3169 - mae: 1.3169 - val_loss: 1.8599 - val_mae: 1.8599\n",
            "Epoch 120/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.2972 - mae: 1.2972 - val_loss: 1.8699 - val_mae: 1.8699\n",
            "Epoch 121/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.2769 - mae: 1.2769 - val_loss: 1.8181 - val_mae: 1.8181\n",
            "Epoch 122/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2600 - mae: 1.2600 - val_loss: 1.8578 - val_mae: 1.8578\n",
            "Epoch 123/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3255 - mae: 1.3255 - val_loss: 1.7776 - val_mae: 1.7776\n",
            "Epoch 124/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.3230 - mae: 1.3230 - val_loss: 1.8257 - val_mae: 1.8257\n",
            "Epoch 125/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.2232 - mae: 1.2232 - val_loss: 1.8844 - val_mae: 1.8844\n",
            "Epoch 126/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.2312 - mae: 1.2312 - val_loss: 1.7962 - val_mae: 1.7962\n",
            "Epoch 127/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2393 - mae: 1.2393 - val_loss: 1.7992 - val_mae: 1.7992\n",
            "Epoch 128/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.2367 - mae: 1.2367 - val_loss: 1.7313 - val_mae: 1.7313\n",
            "Epoch 129/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2382 - mae: 1.2382 - val_loss: 1.8729 - val_mae: 1.8729\n",
            "Epoch 130/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.2447 - mae: 1.2447 - val_loss: 1.7941 - val_mae: 1.7941\n",
            "Epoch 131/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.2171 - mae: 1.2171 - val_loss: 1.8145 - val_mae: 1.8145\n",
            "Epoch 132/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2509 - mae: 1.2509 - val_loss: 1.7844 - val_mae: 1.7844\n",
            "Epoch 133/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2546 - mae: 1.2546 - val_loss: 1.7854 - val_mae: 1.7854\n",
            "Epoch 134/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.2721 - mae: 1.2721 - val_loss: 1.8325 - val_mae: 1.8325\n",
            "Epoch 135/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2588 - mae: 1.2588 - val_loss: 1.8080 - val_mae: 1.8080\n",
            "Epoch 136/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1729 - mae: 1.1729 - val_loss: 1.7735 - val_mae: 1.7735\n",
            "Epoch 137/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.1991 - mae: 1.1991 - val_loss: 1.7126 - val_mae: 1.7126\n",
            "Epoch 138/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.2211 - mae: 1.2211 - val_loss: 1.7649 - val_mae: 1.7649\n",
            "Epoch 139/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2181 - mae: 1.2181 - val_loss: 1.7180 - val_mae: 1.7180\n",
            "Epoch 140/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.1834 - mae: 1.1834 - val_loss: 1.7567 - val_mae: 1.7567\n",
            "Epoch 141/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2140 - mae: 1.2140 - val_loss: 1.7460 - val_mae: 1.7460\n",
            "Epoch 142/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.1696 - mae: 1.1696 - val_loss: 1.8558 - val_mae: 1.8558\n",
            "Epoch 143/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1973 - mae: 1.1973 - val_loss: 1.7331 - val_mae: 1.7331\n",
            "Epoch 144/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1783 - mae: 1.1783 - val_loss: 1.8033 - val_mae: 1.8033\n",
            "Epoch 145/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1423 - mae: 1.1423 - val_loss: 1.7701 - val_mae: 1.7701\n",
            "Epoch 146/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1778 - mae: 1.1778 - val_loss: 1.7840 - val_mae: 1.7840\n",
            "Epoch 147/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.2686 - mae: 1.2686 - val_loss: 1.8347 - val_mae: 1.8347\n",
            "Epoch 148/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.2593 - mae: 1.2593 - val_loss: 1.9467 - val_mae: 1.9467\n",
            "Epoch 149/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.2944 - mae: 1.2944 - val_loss: 1.8588 - val_mae: 1.8588\n",
            "Epoch 150/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.2055 - mae: 1.2055 - val_loss: 1.8037 - val_mae: 1.8037\n",
            "Epoch 151/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.0914 - mae: 1.0914 - val_loss: 1.7884 - val_mae: 1.7884\n",
            "Epoch 152/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1110 - mae: 1.1110 - val_loss: 1.7922 - val_mae: 1.7922\n",
            "Epoch 153/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1410 - mae: 1.1410 - val_loss: 1.7581 - val_mae: 1.7581\n",
            "Epoch 154/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1986 - mae: 1.1986 - val_loss: 1.7645 - val_mae: 1.7645\n",
            "Epoch 155/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.1884 - mae: 1.1884 - val_loss: 1.8620 - val_mae: 1.8620\n",
            "Epoch 156/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1084 - mae: 1.1084 - val_loss: 1.7963 - val_mae: 1.7963\n",
            "Epoch 157/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.1104 - mae: 1.1104 - val_loss: 1.7638 - val_mae: 1.7638\n",
            "Epoch 158/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1604 - mae: 1.1604 - val_loss: 1.7734 - val_mae: 1.7734\n",
            "Epoch 159/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.1102 - mae: 1.1102 - val_loss: 1.8191 - val_mae: 1.8191\n",
            "Epoch 160/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.1843 - mae: 1.1843 - val_loss: 1.7900 - val_mae: 1.7900\n",
            "Epoch 161/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.0888 - mae: 1.0888 - val_loss: 1.7995 - val_mae: 1.7995\n",
            "Epoch 162/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.0947 - mae: 1.0947 - val_loss: 1.7812 - val_mae: 1.7812\n",
            "Epoch 163/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.1174 - mae: 1.1174 - val_loss: 1.8298 - val_mae: 1.8298\n",
            "Epoch 164/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.0872 - mae: 1.0872 - val_loss: 1.8024 - val_mae: 1.8024\n",
            "Epoch 165/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.0606 - mae: 1.0606 - val_loss: 1.7874 - val_mae: 1.7874\n",
            "Epoch 166/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.0789 - mae: 1.0789 - val_loss: 1.7464 - val_mae: 1.7464\n",
            "Epoch 167/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.1295 - mae: 1.1295 - val_loss: 1.8856 - val_mae: 1.8856\n",
            "Epoch 168/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.1434 - mae: 1.1434 - val_loss: 1.7803 - val_mae: 1.7803\n",
            "Epoch 169/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.0937 - mae: 1.0937 - val_loss: 1.7327 - val_mae: 1.7327\n",
            "Epoch 170/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.0557 - mae: 1.0557 - val_loss: 1.7453 - val_mae: 1.7453\n",
            "Epoch 171/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.0931 - mae: 1.0931 - val_loss: 1.7371 - val_mae: 1.7371\n",
            "Epoch 172/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.0467 - mae: 1.0467 - val_loss: 1.7911 - val_mae: 1.7911\n",
            "Epoch 173/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.0593 - mae: 1.0593 - val_loss: 1.7539 - val_mae: 1.7539\n",
            "Epoch 174/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.0584 - mae: 1.0584 - val_loss: 1.7735 - val_mae: 1.7735\n",
            "Epoch 175/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.0390 - mae: 1.0390 - val_loss: 1.8754 - val_mae: 1.8754\n",
            "Epoch 176/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.1079 - mae: 1.1079 - val_loss: 1.8579 - val_mae: 1.8579\n",
            "Epoch 177/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.0942 - mae: 1.0942 - val_loss: 1.7155 - val_mae: 1.7155\n",
            "Epoch 178/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.0862 - mae: 1.0862 - val_loss: 1.8544 - val_mae: 1.8544\n",
            "Epoch 179/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.0569 - mae: 1.0569 - val_loss: 1.7451 - val_mae: 1.7451\n",
            "Epoch 180/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 1.0875 - mae: 1.0875 - val_loss: 1.7785 - val_mae: 1.7785\n",
            "Epoch 181/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 1.0183 - mae: 1.0183 - val_loss: 1.8396 - val_mae: 1.8396\n",
            "Epoch 182/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.0257 - mae: 1.0257 - val_loss: 1.7918 - val_mae: 1.7918\n",
            "Epoch 183/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.0280 - mae: 1.0280 - val_loss: 1.8059 - val_mae: 1.8059\n",
            "Epoch 184/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.1226 - mae: 1.1226 - val_loss: 1.7466 - val_mae: 1.7466\n",
            "Epoch 185/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.0904 - mae: 1.0904 - val_loss: 1.7626 - val_mae: 1.7626\n",
            "Epoch 186/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.0289 - mae: 1.0289 - val_loss: 1.8311 - val_mae: 1.8311\n",
            "Epoch 187/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.0089 - mae: 1.0089 - val_loss: 1.7996 - val_mae: 1.7996\n",
            "Epoch 188/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.0099 - mae: 1.0099 - val_loss: 1.8242 - val_mae: 1.8242\n",
            "Epoch 189/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9693 - mae: 0.9693 - val_loss: 1.8019 - val_mae: 1.8019\n",
            "Epoch 190/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9816 - mae: 0.9816 - val_loss: 1.8097 - val_mae: 1.8097\n",
            "Epoch 191/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9721 - mae: 0.9721 - val_loss: 1.8301 - val_mae: 1.8301\n",
            "Epoch 192/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9796 - mae: 0.9796 - val_loss: 1.7544 - val_mae: 1.7544\n",
            "Epoch 193/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9494 - mae: 0.9494 - val_loss: 1.7790 - val_mae: 1.7790\n",
            "Epoch 194/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9921 - mae: 0.9921 - val_loss: 1.8602 - val_mae: 1.8602\n",
            "Epoch 195/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 1.0466 - mae: 1.0466 - val_loss: 1.8078 - val_mae: 1.8078\n",
            "Epoch 196/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.0305 - mae: 1.0305 - val_loss: 1.8122 - val_mae: 1.8122\n",
            "Epoch 197/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9830 - mae: 0.9830 - val_loss: 1.8193 - val_mae: 1.8193\n",
            "Epoch 198/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9518 - mae: 0.9518 - val_loss: 1.7797 - val_mae: 1.7797\n",
            "Epoch 199/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9277 - mae: 0.9277 - val_loss: 1.7930 - val_mae: 1.7930\n",
            "Epoch 200/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.0054 - mae: 1.0054 - val_loss: 1.7967 - val_mae: 1.7967\n",
            "Epoch 201/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9753 - mae: 0.9753 - val_loss: 1.8313 - val_mae: 1.8313\n",
            "Epoch 202/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 1.0498 - mae: 1.0498 - val_loss: 1.8239 - val_mae: 1.8239\n",
            "Epoch 203/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9706 - mae: 0.9706 - val_loss: 1.7906 - val_mae: 1.7906\n",
            "Epoch 204/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9779 - mae: 0.9779 - val_loss: 1.8090 - val_mae: 1.8090\n",
            "Epoch 205/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9872 - mae: 0.9872 - val_loss: 1.7929 - val_mae: 1.7929\n",
            "Epoch 206/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9343 - mae: 0.9343 - val_loss: 1.8615 - val_mae: 1.8615\n",
            "Epoch 207/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9595 - mae: 0.9595 - val_loss: 1.8707 - val_mae: 1.8707\n",
            "Epoch 208/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9469 - mae: 0.9469 - val_loss: 1.7854 - val_mae: 1.7854\n",
            "Epoch 209/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9034 - mae: 0.9034 - val_loss: 1.8125 - val_mae: 1.8125\n",
            "Epoch 210/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9792 - mae: 0.9792 - val_loss: 1.7812 - val_mae: 1.7812\n",
            "Epoch 211/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9328 - mae: 0.9328 - val_loss: 1.7708 - val_mae: 1.7708\n",
            "Epoch 212/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.9154 - mae: 0.9154 - val_loss: 1.7729 - val_mae: 1.7729\n",
            "Epoch 213/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9377 - mae: 0.9377 - val_loss: 1.7883 - val_mae: 1.7883\n",
            "Epoch 214/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9985 - mae: 0.9985 - val_loss: 1.8261 - val_mae: 1.8261\n",
            "Epoch 215/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9895 - mae: 0.9895 - val_loss: 1.7936 - val_mae: 1.7936\n",
            "Epoch 216/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8792 - mae: 0.8792 - val_loss: 1.7754 - val_mae: 1.7754\n",
            "Epoch 217/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8838 - mae: 0.8838 - val_loss: 1.7589 - val_mae: 1.7589\n",
            "Epoch 218/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9262 - mae: 0.9262 - val_loss: 1.7177 - val_mae: 1.7177\n",
            "Epoch 219/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9109 - mae: 0.9109 - val_loss: 1.7603 - val_mae: 1.7603\n",
            "Epoch 220/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9301 - mae: 0.9301 - val_loss: 1.7926 - val_mae: 1.7926\n",
            "Epoch 221/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8940 - mae: 0.8940 - val_loss: 1.7179 - val_mae: 1.7179\n",
            "Epoch 222/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.8890 - mae: 0.8890 - val_loss: 1.8077 - val_mae: 1.8077\n",
            "Epoch 223/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9417 - mae: 0.9417 - val_loss: 1.7910 - val_mae: 1.7910\n",
            "Epoch 224/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9345 - mae: 0.9345 - val_loss: 1.7306 - val_mae: 1.7306\n",
            "Epoch 225/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9131 - mae: 0.9131 - val_loss: 1.8491 - val_mae: 1.8491\n",
            "Epoch 226/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8997 - mae: 0.8997 - val_loss: 1.7601 - val_mae: 1.7601\n",
            "Epoch 227/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.8533 - mae: 0.8533 - val_loss: 1.7245 - val_mae: 1.7245\n",
            "Epoch 228/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8460 - mae: 0.8460 - val_loss: 1.8196 - val_mae: 1.8196\n",
            "Epoch 229/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8302 - mae: 0.8302 - val_loss: 1.7015 - val_mae: 1.7015\n",
            "Epoch 230/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8816 - mae: 0.8816 - val_loss: 1.7675 - val_mae: 1.7675\n",
            "Epoch 231/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.9094 - mae: 0.9094 - val_loss: 1.7622 - val_mae: 1.7622\n",
            "Epoch 232/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8635 - mae: 0.8635 - val_loss: 1.7331 - val_mae: 1.7331\n",
            "Epoch 233/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8657 - mae: 0.8657 - val_loss: 1.7966 - val_mae: 1.7966\n",
            "Epoch 234/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8636 - mae: 0.8636 - val_loss: 1.8227 - val_mae: 1.8227\n",
            "Epoch 235/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8228 - mae: 0.8228 - val_loss: 1.7545 - val_mae: 1.7545\n",
            "Epoch 236/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.8381 - mae: 0.8381 - val_loss: 1.8285 - val_mae: 1.8285\n",
            "Epoch 237/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8849 - mae: 0.8849 - val_loss: 1.7721 - val_mae: 1.7721\n",
            "Epoch 238/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8848 - mae: 0.8848 - val_loss: 1.7438 - val_mae: 1.7438\n",
            "Epoch 239/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9508 - mae: 0.9508 - val_loss: 1.8587 - val_mae: 1.8587\n",
            "Epoch 240/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8803 - mae: 0.8803 - val_loss: 1.7889 - val_mae: 1.7889\n",
            "Epoch 241/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8806 - mae: 0.8806 - val_loss: 1.7765 - val_mae: 1.7765\n",
            "Epoch 242/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.8707 - mae: 0.8707 - val_loss: 1.7621 - val_mae: 1.7621\n",
            "Epoch 243/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8553 - mae: 0.8553 - val_loss: 1.6807 - val_mae: 1.6807\n",
            "Epoch 244/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8643 - mae: 0.8643 - val_loss: 1.7872 - val_mae: 1.7872\n",
            "Epoch 245/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8322 - mae: 0.8322 - val_loss: 1.7194 - val_mae: 1.7194\n",
            "Epoch 246/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.8755 - mae: 0.8755 - val_loss: 1.8300 - val_mae: 1.8300\n",
            "Epoch 247/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8894 - mae: 0.8894 - val_loss: 1.7166 - val_mae: 1.7166\n",
            "Epoch 248/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.9438 - mae: 0.9438 - val_loss: 1.9083 - val_mae: 1.9083\n",
            "Epoch 249/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.9538 - mae: 0.9538 - val_loss: 1.7728 - val_mae: 1.7728\n",
            "Epoch 250/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8910 - mae: 0.8910 - val_loss: 1.8168 - val_mae: 1.8168\n",
            "Epoch 251/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.8164 - mae: 0.8164 - val_loss: 1.7436 - val_mae: 1.7436\n",
            "Epoch 252/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8551 - mae: 0.8551 - val_loss: 1.7527 - val_mae: 1.7527\n",
            "Epoch 253/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8335 - mae: 0.8335 - val_loss: 1.7832 - val_mae: 1.7832\n",
            "Epoch 254/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.8244 - mae: 0.8244 - val_loss: 1.7747 - val_mae: 1.7747\n",
            "Epoch 255/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8127 - mae: 0.8127 - val_loss: 1.7533 - val_mae: 1.7533\n",
            "Epoch 256/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7985 - mae: 0.7985 - val_loss: 1.8369 - val_mae: 1.8369\n",
            "Epoch 257/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.8129 - mae: 0.8129 - val_loss: 1.7150 - val_mae: 1.7150\n",
            "Epoch 258/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8330 - mae: 0.8330 - val_loss: 1.8155 - val_mae: 1.8155\n",
            "Epoch 259/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8125 - mae: 0.8125 - val_loss: 1.7081 - val_mae: 1.7081\n",
            "Epoch 260/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.8016 - mae: 0.8016 - val_loss: 1.8099 - val_mae: 1.8099\n",
            "Epoch 261/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8337 - mae: 0.8337 - val_loss: 1.7385 - val_mae: 1.7385\n",
            "Epoch 262/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8137 - mae: 0.8137 - val_loss: 1.8332 - val_mae: 1.8332\n",
            "Epoch 263/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.8219 - mae: 0.8219 - val_loss: 1.6994 - val_mae: 1.6994\n",
            "Epoch 264/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.8251 - mae: 0.8251 - val_loss: 1.7926 - val_mae: 1.7926\n",
            "Epoch 265/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.8013 - mae: 0.8013 - val_loss: 1.7639 - val_mae: 1.7639\n",
            "Epoch 266/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7912 - mae: 0.7912 - val_loss: 1.7823 - val_mae: 1.7823\n",
            "Epoch 267/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8013 - mae: 0.8013 - val_loss: 1.7258 - val_mae: 1.7258\n",
            "Epoch 268/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8103 - mae: 0.8103 - val_loss: 1.8058 - val_mae: 1.8058\n",
            "Epoch 269/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.8503 - mae: 0.8503 - val_loss: 1.7525 - val_mae: 1.7525\n",
            "Epoch 270/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8648 - mae: 0.8648 - val_loss: 1.7872 - val_mae: 1.7872\n",
            "Epoch 271/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7891 - mae: 0.7891 - val_loss: 1.8417 - val_mae: 1.8417\n",
            "Epoch 272/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.8056 - mae: 0.8056 - val_loss: 1.7736 - val_mae: 1.7736\n",
            "Epoch 273/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8239 - mae: 0.8239 - val_loss: 1.8295 - val_mae: 1.8295\n",
            "Epoch 274/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7648 - mae: 0.7648 - val_loss: 1.7291 - val_mae: 1.7291\n",
            "Epoch 275/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7828 - mae: 0.7828 - val_loss: 1.7497 - val_mae: 1.7497\n",
            "Epoch 276/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7599 - mae: 0.7599 - val_loss: 1.7651 - val_mae: 1.7651\n",
            "Epoch 277/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7844 - mae: 0.7844 - val_loss: 1.7502 - val_mae: 1.7502\n",
            "Epoch 278/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8172 - mae: 0.8172 - val_loss: 1.7807 - val_mae: 1.7807\n",
            "Epoch 279/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8365 - mae: 0.8365 - val_loss: 1.7764 - val_mae: 1.7764\n",
            "Epoch 280/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8325 - mae: 0.8325 - val_loss: 1.8225 - val_mae: 1.8225\n",
            "Epoch 281/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8769 - mae: 0.8769 - val_loss: 1.8124 - val_mae: 1.8124\n",
            "Epoch 282/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8468 - mae: 0.8468 - val_loss: 1.7733 - val_mae: 1.7733\n",
            "Epoch 283/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7920 - mae: 0.7920 - val_loss: 1.7585 - val_mae: 1.7585\n",
            "Epoch 284/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8077 - mae: 0.8077 - val_loss: 1.7646 - val_mae: 1.7646\n",
            "Epoch 285/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7663 - mae: 0.7663 - val_loss: 1.7773 - val_mae: 1.7773\n",
            "Epoch 286/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7553 - mae: 0.7553 - val_loss: 1.7625 - val_mae: 1.7625\n",
            "Epoch 287/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7839 - mae: 0.7839 - val_loss: 1.8431 - val_mae: 1.8431\n",
            "Epoch 288/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7744 - mae: 0.7744 - val_loss: 1.7417 - val_mae: 1.7417\n",
            "Epoch 289/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.7367 - mae: 0.7367 - val_loss: 1.7538 - val_mae: 1.7538\n",
            "Epoch 290/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7250 - mae: 0.7250 - val_loss: 1.7755 - val_mae: 1.7755\n",
            "Epoch 291/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.7864 - mae: 0.7864 - val_loss: 1.8173 - val_mae: 1.8173\n",
            "Epoch 292/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.8261 - mae: 0.8261 - val_loss: 1.7396 - val_mae: 1.7396\n",
            "Epoch 293/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.8101 - mae: 0.8101 - val_loss: 1.8063 - val_mae: 1.8063\n",
            "Epoch 294/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.8237 - mae: 0.8237 - val_loss: 1.7569 - val_mae: 1.7569\n",
            "Epoch 295/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.7755 - mae: 0.7755 - val_loss: 1.7529 - val_mae: 1.7529\n",
            "Epoch 296/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.8172 - mae: 0.8172 - val_loss: 1.8394 - val_mae: 1.8394\n",
            "Epoch 297/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.8202 - mae: 0.8202 - val_loss: 1.7874 - val_mae: 1.7874\n",
            "Epoch 298/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.8078 - mae: 0.8078 - val_loss: 1.7561 - val_mae: 1.7561\n",
            "Epoch 299/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.7831 - mae: 0.7831 - val_loss: 1.7306 - val_mae: 1.7306\n",
            "Epoch 300/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.7890 - mae: 0.7890 - val_loss: 1.7273 - val_mae: 1.7273\n",
            "Epoch 301/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.7959 - mae: 0.7959 - val_loss: 1.7717 - val_mae: 1.7717\n",
            "Epoch 302/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.7731 - mae: 0.7731 - val_loss: 1.7155 - val_mae: 1.7155\n",
            "Epoch 303/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.7450 - mae: 0.7450 - val_loss: 1.7419 - val_mae: 1.7419\n",
            "Epoch 304/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.7505 - mae: 0.7505 - val_loss: 1.7319 - val_mae: 1.7319\n",
            "Epoch 305/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.7384 - mae: 0.7384 - val_loss: 1.7359 - val_mae: 1.7359\n",
            "Epoch 306/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.6978 - mae: 0.6978 - val_loss: 1.7816 - val_mae: 1.7816\n",
            "Epoch 307/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.7610 - mae: 0.7610 - val_loss: 1.7270 - val_mae: 1.7270\n",
            "Epoch 308/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.7725 - mae: 0.7725 - val_loss: 1.7589 - val_mae: 1.7589\n",
            "Epoch 309/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.8244 - mae: 0.8244 - val_loss: 1.7659 - val_mae: 1.7659\n",
            "Epoch 310/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.7503 - mae: 0.7503 - val_loss: 1.8079 - val_mae: 1.8079\n",
            "Epoch 311/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.8278 - mae: 0.8278 - val_loss: 1.7965 - val_mae: 1.7965\n",
            "Epoch 312/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.8069 - mae: 0.8069 - val_loss: 1.7664 - val_mae: 1.7664\n",
            "Epoch 313/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.7329 - mae: 0.7329 - val_loss: 1.7792 - val_mae: 1.7792\n",
            "Epoch 314/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.7185 - mae: 0.7185 - val_loss: 1.8097 - val_mae: 1.8097\n",
            "Epoch 315/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.7703 - mae: 0.7703 - val_loss: 1.7726 - val_mae: 1.7726\n",
            "Epoch 316/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7746 - mae: 0.7746 - val_loss: 1.7656 - val_mae: 1.7656\n",
            "Epoch 317/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.8619 - mae: 0.8619 - val_loss: 1.7844 - val_mae: 1.7844\n",
            "Epoch 318/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8519 - mae: 0.8519 - val_loss: 1.7630 - val_mae: 1.7630\n",
            "Epoch 319/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.8270 - mae: 0.8270 - val_loss: 1.7462 - val_mae: 1.7462\n",
            "Epoch 320/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7646 - mae: 0.7646 - val_loss: 1.7700 - val_mae: 1.7700\n",
            "Epoch 321/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7753 - mae: 0.7753 - val_loss: 1.8175 - val_mae: 1.8175\n",
            "Epoch 322/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7602 - mae: 0.7602 - val_loss: 1.7577 - val_mae: 1.7577\n",
            "Epoch 323/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7745 - mae: 0.7745 - val_loss: 1.8097 - val_mae: 1.8097\n",
            "Epoch 324/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7173 - mae: 0.7173 - val_loss: 1.7556 - val_mae: 1.7556\n",
            "Epoch 325/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7689 - mae: 0.7689 - val_loss: 1.7313 - val_mae: 1.7313\n",
            "Epoch 326/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7489 - mae: 0.7489 - val_loss: 1.7890 - val_mae: 1.7890\n",
            "Epoch 327/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7081 - mae: 0.7081 - val_loss: 1.7332 - val_mae: 1.7332\n",
            "Epoch 328/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.8022 - mae: 0.8022 - val_loss: 1.7652 - val_mae: 1.7652\n",
            "Epoch 329/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7357 - mae: 0.7357 - val_loss: 1.7661 - val_mae: 1.7661\n",
            "Epoch 330/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7471 - mae: 0.7471 - val_loss: 1.8253 - val_mae: 1.8253\n",
            "Epoch 331/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7025 - mae: 0.7025 - val_loss: 1.7834 - val_mae: 1.7834\n",
            "Epoch 332/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6973 - mae: 0.6973 - val_loss: 1.7982 - val_mae: 1.7982\n",
            "Epoch 333/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.7264 - mae: 0.7264 - val_loss: 1.8307 - val_mae: 1.8307\n",
            "Epoch 334/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7421 - mae: 0.7421 - val_loss: 1.7904 - val_mae: 1.7904\n",
            "Epoch 335/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7883 - mae: 0.7883 - val_loss: 1.7588 - val_mae: 1.7588\n",
            "Epoch 336/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7481 - mae: 0.7481 - val_loss: 1.7852 - val_mae: 1.7852\n",
            "Epoch 337/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7211 - mae: 0.7211 - val_loss: 1.7857 - val_mae: 1.7857\n",
            "Epoch 338/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7217 - mae: 0.7217 - val_loss: 1.7364 - val_mae: 1.7364\n",
            "Epoch 339/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7297 - mae: 0.7297 - val_loss: 1.8319 - val_mae: 1.8319\n",
            "Epoch 340/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6953 - mae: 0.6953 - val_loss: 1.7610 - val_mae: 1.7610\n",
            "Epoch 341/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7091 - mae: 0.7091 - val_loss: 1.8059 - val_mae: 1.8059\n",
            "Epoch 342/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7956 - mae: 0.7956 - val_loss: 1.7587 - val_mae: 1.7587\n",
            "Epoch 343/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.7438 - mae: 0.7438 - val_loss: 1.7352 - val_mae: 1.7352\n",
            "Epoch 344/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7075 - mae: 0.7075 - val_loss: 1.7726 - val_mae: 1.7726\n",
            "Epoch 345/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7217 - mae: 0.7217 - val_loss: 1.6952 - val_mae: 1.6952\n",
            "Epoch 346/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7891 - mae: 0.7891 - val_loss: 1.7665 - val_mae: 1.7665\n",
            "Epoch 347/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7115 - mae: 0.7115 - val_loss: 1.7627 - val_mae: 1.7627\n",
            "Epoch 348/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6652 - mae: 0.6652 - val_loss: 1.7570 - val_mae: 1.7570\n",
            "Epoch 349/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6971 - mae: 0.6971 - val_loss: 1.8024 - val_mae: 1.8024\n",
            "Epoch 350/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6833 - mae: 0.6833 - val_loss: 1.7289 - val_mae: 1.7289\n",
            "Epoch 351/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6329 - mae: 0.6329 - val_loss: 1.7548 - val_mae: 1.7548\n",
            "Epoch 352/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6967 - mae: 0.6967 - val_loss: 1.8266 - val_mae: 1.8266\n",
            "Epoch 353/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.7085 - mae: 0.7085 - val_loss: 1.6891 - val_mae: 1.6891\n",
            "Epoch 354/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7333 - mae: 0.7333 - val_loss: 1.8258 - val_mae: 1.8258\n",
            "Epoch 355/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7452 - mae: 0.7452 - val_loss: 1.7885 - val_mae: 1.7885\n",
            "Epoch 356/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.8138 - mae: 0.8138 - val_loss: 1.7457 - val_mae: 1.7457\n",
            "Epoch 357/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7546 - mae: 0.7546 - val_loss: 1.7627 - val_mae: 1.7627\n",
            "Epoch 358/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7605 - mae: 0.7605 - val_loss: 1.6995 - val_mae: 1.6995\n",
            "Epoch 359/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7211 - mae: 0.7211 - val_loss: 1.8147 - val_mae: 1.8147\n",
            "Epoch 360/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7498 - mae: 0.7498 - val_loss: 1.7500 - val_mae: 1.7500\n",
            "Epoch 361/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7668 - mae: 0.7668 - val_loss: 1.7683 - val_mae: 1.7683\n",
            "Epoch 362/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7045 - mae: 0.7045 - val_loss: 1.7547 - val_mae: 1.7547\n",
            "Epoch 363/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7565 - mae: 0.7565 - val_loss: 1.7968 - val_mae: 1.7968\n",
            "Epoch 364/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.8270 - mae: 0.8270 - val_loss: 1.8826 - val_mae: 1.8826\n",
            "Epoch 365/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.7396 - mae: 0.7396 - val_loss: 1.7581 - val_mae: 1.7581\n",
            "Epoch 366/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7836 - mae: 0.7836 - val_loss: 1.8271 - val_mae: 1.8271\n",
            "Epoch 367/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7166 - mae: 0.7166 - val_loss: 1.8064 - val_mae: 1.8064\n",
            "Epoch 368/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.6930 - mae: 0.6930 - val_loss: 1.8092 - val_mae: 1.8092\n",
            "Epoch 369/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6527 - mae: 0.6527 - val_loss: 1.7316 - val_mae: 1.7316\n",
            "Epoch 370/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7244 - mae: 0.7244 - val_loss: 1.7819 - val_mae: 1.7819\n",
            "Epoch 371/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6846 - mae: 0.6846 - val_loss: 1.8049 - val_mae: 1.8049\n",
            "Epoch 372/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6878 - mae: 0.6878 - val_loss: 1.7636 - val_mae: 1.7636\n",
            "Epoch 373/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6768 - mae: 0.6768 - val_loss: 1.7117 - val_mae: 1.7117\n",
            "Epoch 374/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6399 - mae: 0.6399 - val_loss: 1.7682 - val_mae: 1.7682\n",
            "Epoch 375/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6932 - mae: 0.6932 - val_loss: 1.7096 - val_mae: 1.7096\n",
            "Epoch 376/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6666 - mae: 0.6666 - val_loss: 1.7216 - val_mae: 1.7216\n",
            "Epoch 377/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6422 - mae: 0.6422 - val_loss: 1.6742 - val_mae: 1.6742\n",
            "Epoch 378/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6899 - mae: 0.6899 - val_loss: 1.7440 - val_mae: 1.7440\n",
            "Epoch 379/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6375 - mae: 0.6375 - val_loss: 1.7666 - val_mae: 1.7666\n",
            "Epoch 380/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6481 - mae: 0.6481 - val_loss: 1.7624 - val_mae: 1.7624\n",
            "Epoch 381/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6802 - mae: 0.6802 - val_loss: 1.7566 - val_mae: 1.7566\n",
            "Epoch 382/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6497 - mae: 0.6497 - val_loss: 1.8168 - val_mae: 1.8168\n",
            "Epoch 383/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7066 - mae: 0.7066 - val_loss: 1.7519 - val_mae: 1.7519\n",
            "Epoch 384/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.7342 - mae: 0.7342 - val_loss: 1.7718 - val_mae: 1.7718\n",
            "Epoch 385/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6622 - mae: 0.6622 - val_loss: 1.6947 - val_mae: 1.6947\n",
            "Epoch 386/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6590 - mae: 0.6590 - val_loss: 1.7328 - val_mae: 1.7328\n",
            "Epoch 387/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6898 - mae: 0.6898 - val_loss: 1.7357 - val_mae: 1.7357\n",
            "Epoch 388/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7647 - mae: 0.7647 - val_loss: 1.7426 - val_mae: 1.7426\n",
            "Epoch 389/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6949 - mae: 0.6949 - val_loss: 1.7810 - val_mae: 1.7810\n",
            "Epoch 390/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7614 - mae: 0.7614 - val_loss: 1.6967 - val_mae: 1.6967\n",
            "Epoch 391/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6491 - mae: 0.6491 - val_loss: 1.7431 - val_mae: 1.7431\n",
            "Epoch 392/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6256 - mae: 0.6256 - val_loss: 1.7254 - val_mae: 1.7254\n",
            "Epoch 393/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6458 - mae: 0.6458 - val_loss: 1.7582 - val_mae: 1.7582\n",
            "Epoch 394/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7400 - mae: 0.7400 - val_loss: 1.7046 - val_mae: 1.7046\n",
            "Epoch 395/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6202 - mae: 0.6202 - val_loss: 1.7169 - val_mae: 1.7169\n",
            "Epoch 396/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6148 - mae: 0.6148 - val_loss: 1.7270 - val_mae: 1.7270\n",
            "Epoch 397/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6153 - mae: 0.6153 - val_loss: 1.7938 - val_mae: 1.7938\n",
            "Epoch 398/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6238 - mae: 0.6238 - val_loss: 1.7138 - val_mae: 1.7138\n",
            "Epoch 399/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6338 - mae: 0.6338 - val_loss: 1.7883 - val_mae: 1.7883\n",
            "Epoch 400/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7336 - mae: 0.7336 - val_loss: 1.7527 - val_mae: 1.7527\n",
            "Epoch 401/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6995 - mae: 0.6995 - val_loss: 1.7572 - val_mae: 1.7572\n",
            "Epoch 402/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.7257 - mae: 0.7257 - val_loss: 1.6664 - val_mae: 1.6664\n",
            "Epoch 403/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6924 - mae: 0.6924 - val_loss: 1.8029 - val_mae: 1.8029\n",
            "Epoch 404/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6950 - mae: 0.6950 - val_loss: 1.7014 - val_mae: 1.7014\n",
            "Epoch 405/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6747 - mae: 0.6747 - val_loss: 1.8090 - val_mae: 1.8090\n",
            "Epoch 406/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6768 - mae: 0.6768 - val_loss: 1.6961 - val_mae: 1.6961\n",
            "Epoch 407/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.6600 - mae: 0.6600 - val_loss: 1.7019 - val_mae: 1.7019\n",
            "Epoch 408/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.6178 - mae: 0.6178 - val_loss: 1.7392 - val_mae: 1.7392\n",
            "Epoch 409/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6298 - mae: 0.6298 - val_loss: 1.7436 - val_mae: 1.7436\n",
            "Epoch 410/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6847 - mae: 0.6847 - val_loss: 1.8254 - val_mae: 1.8254\n",
            "Epoch 411/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.7619 - mae: 0.7619 - val_loss: 1.7436 - val_mae: 1.7436\n",
            "Epoch 412/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6652 - mae: 0.6652 - val_loss: 1.7864 - val_mae: 1.7864\n",
            "Epoch 413/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6563 - mae: 0.6563 - val_loss: 1.7301 - val_mae: 1.7301\n",
            "Epoch 414/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6526 - mae: 0.6526 - val_loss: 1.7069 - val_mae: 1.7069\n",
            "Epoch 415/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6193 - mae: 0.6193 - val_loss: 1.7340 - val_mae: 1.7340\n",
            "Epoch 416/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6750 - mae: 0.6750 - val_loss: 1.7283 - val_mae: 1.7283\n",
            "Epoch 417/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6334 - mae: 0.6334 - val_loss: 1.7298 - val_mae: 1.7298\n",
            "Epoch 418/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6452 - mae: 0.6452 - val_loss: 1.7145 - val_mae: 1.7145\n",
            "Epoch 419/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.6440 - mae: 0.6440 - val_loss: 1.7065 - val_mae: 1.7065\n",
            "Epoch 420/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.6148 - mae: 0.6148 - val_loss: 1.6889 - val_mae: 1.6889\n",
            "Epoch 421/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.6466 - mae: 0.6466 - val_loss: 1.7736 - val_mae: 1.7736\n",
            "Epoch 422/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.6829 - mae: 0.6829 - val_loss: 1.7604 - val_mae: 1.7604\n",
            "Epoch 423/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.6135 - mae: 0.6135 - val_loss: 1.7954 - val_mae: 1.7954\n",
            "Epoch 424/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.6523 - mae: 0.6523 - val_loss: 1.7753 - val_mae: 1.7753\n",
            "Epoch 425/500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6438 - mae: 0.6438 - val_loss: 1.7671 - val_mae: 1.7671\n",
            "Epoch 426/500\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 0.6871 - mae: 0.6871 - val_loss: 1.8003 - val_mae: 1.8003\n",
            "Epoch 427/500\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.6617 - mae: 0.6617 - val_loss: 1.8096 - val_mae: 1.8096\n",
            "Epoch 428/500\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.6200 - mae: 0.6200 - val_loss: 1.7267 - val_mae: 1.7267\n",
            "Epoch 429/500\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.6175 - mae: 0.6175 - val_loss: 1.7432 - val_mae: 1.7432\n",
            "Epoch 430/500\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 0.6073 - mae: 0.6073 - val_loss: 1.7638 - val_mae: 1.7638\n",
            "Epoch 431/500\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.6081 - mae: 0.6081 - val_loss: 1.7197 - val_mae: 1.7197\n",
            "Epoch 432/500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.6404 - mae: 0.6404 - val_loss: 1.7565 - val_mae: 1.7565\n",
            "Epoch 433/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.6434 - mae: 0.6434 - val_loss: 1.7370 - val_mae: 1.7370\n",
            "Epoch 434/500\n",
            "12/12 [==============================] - 0s 17ms/step - loss: 0.6140 - mae: 0.6140 - val_loss: 1.7889 - val_mae: 1.7889\n",
            "Epoch 435/500\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 0.6601 - mae: 0.6601 - val_loss: 1.7231 - val_mae: 1.7231\n",
            "Epoch 436/500\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.7932 - mae: 0.7932 - val_loss: 1.7620 - val_mae: 1.7620\n",
            "Epoch 437/500\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.6545 - mae: 0.6545 - val_loss: 1.6839 - val_mae: 1.6839\n",
            "Epoch 438/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5820 - mae: 0.5820 - val_loss: 1.7371 - val_mae: 1.7371\n",
            "Epoch 439/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6703 - mae: 0.6703 - val_loss: 1.7383 - val_mae: 1.7383\n",
            "Epoch 440/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.6010 - mae: 0.6010 - val_loss: 1.7190 - val_mae: 1.7190\n",
            "Epoch 441/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6511 - mae: 0.6511 - val_loss: 1.7742 - val_mae: 1.7742\n",
            "Epoch 442/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.6394 - mae: 0.6394 - val_loss: 1.6949 - val_mae: 1.6949\n",
            "Epoch 443/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.6289 - mae: 0.6289 - val_loss: 1.6696 - val_mae: 1.6696\n",
            "Epoch 444/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.6443 - mae: 0.6443 - val_loss: 1.7344 - val_mae: 1.7344\n",
            "Epoch 445/500\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.6294 - mae: 0.6294 - val_loss: 1.6807 - val_mae: 1.6807\n",
            "Epoch 446/500\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 0.6114 - mae: 0.6114 - val_loss: 1.7344 - val_mae: 1.7344\n",
            "Epoch 447/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.6172 - mae: 0.6172 - val_loss: 1.7005 - val_mae: 1.7005\n",
            "Epoch 448/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6146 - mae: 0.6146 - val_loss: 1.7256 - val_mae: 1.7256\n",
            "Epoch 449/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6267 - mae: 0.6267 - val_loss: 1.7261 - val_mae: 1.7261\n",
            "Epoch 450/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.6231 - mae: 0.6231 - val_loss: 1.7338 - val_mae: 1.7338\n",
            "Epoch 451/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.6547 - mae: 0.6547 - val_loss: 1.7513 - val_mae: 1.7513\n",
            "Epoch 452/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6395 - mae: 0.6395 - val_loss: 1.7569 - val_mae: 1.7569\n",
            "Epoch 453/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.6042 - mae: 0.6042 - val_loss: 1.7561 - val_mae: 1.7561\n",
            "Epoch 454/500\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.5854 - mae: 0.5854 - val_loss: 1.7026 - val_mae: 1.7026\n",
            "Epoch 455/500\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 0.5962 - mae: 0.5962 - val_loss: 1.6931 - val_mae: 1.6931\n",
            "Epoch 456/500\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 0.5853 - mae: 0.5853 - val_loss: 1.7479 - val_mae: 1.7479\n",
            "Epoch 457/500\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.5998 - mae: 0.5998 - val_loss: 1.7350 - val_mae: 1.7350\n",
            "Epoch 458/500\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.6107 - mae: 0.6107 - val_loss: 1.7988 - val_mae: 1.7988\n",
            "Epoch 459/500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.7333 - mae: 0.7333 - val_loss: 1.6978 - val_mae: 1.6978\n",
            "Epoch 460/500\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 0.6025 - mae: 0.6025 - val_loss: 1.6839 - val_mae: 1.6839\n",
            "Epoch 461/500\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 0.5778 - mae: 0.5778 - val_loss: 1.6985 - val_mae: 1.6985\n",
            "Epoch 462/500\n",
            "12/12 [==============================] - 0s 15ms/step - loss: 0.5534 - mae: 0.5534 - val_loss: 1.7398 - val_mae: 1.7398\n",
            "Epoch 463/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5567 - mae: 0.5567 - val_loss: 1.7512 - val_mae: 1.7512\n",
            "Epoch 464/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5523 - mae: 0.5523 - val_loss: 1.6825 - val_mae: 1.6825\n",
            "Epoch 465/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5812 - mae: 0.5812 - val_loss: 1.6964 - val_mae: 1.6964\n",
            "Epoch 466/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5758 - mae: 0.5758 - val_loss: 1.7360 - val_mae: 1.7360\n",
            "Epoch 467/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5601 - mae: 0.5601 - val_loss: 1.7454 - val_mae: 1.7454\n",
            "Epoch 468/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6148 - mae: 0.6148 - val_loss: 1.7992 - val_mae: 1.7992\n",
            "Epoch 469/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6430 - mae: 0.6430 - val_loss: 1.6992 - val_mae: 1.6992\n",
            "Epoch 470/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6246 - mae: 0.6246 - val_loss: 1.7400 - val_mae: 1.7400\n",
            "Epoch 471/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6051 - mae: 0.6051 - val_loss: 1.7581 - val_mae: 1.7581\n",
            "Epoch 472/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5905 - mae: 0.5905 - val_loss: 1.7232 - val_mae: 1.7232\n",
            "Epoch 473/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5648 - mae: 0.5648 - val_loss: 1.7885 - val_mae: 1.7885\n",
            "Epoch 474/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6197 - mae: 0.6197 - val_loss: 1.7726 - val_mae: 1.7726\n",
            "Epoch 475/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5855 - mae: 0.5855 - val_loss: 1.6778 - val_mae: 1.6778\n",
            "Epoch 476/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.5660 - mae: 0.5660 - val_loss: 1.7597 - val_mae: 1.7597\n",
            "Epoch 477/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6119 - mae: 0.6119 - val_loss: 1.6397 - val_mae: 1.6397\n",
            "Epoch 478/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6046 - mae: 0.6046 - val_loss: 1.7509 - val_mae: 1.7509\n",
            "Epoch 479/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.5771 - mae: 0.5771 - val_loss: 1.7635 - val_mae: 1.7635\n",
            "Epoch 480/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5517 - mae: 0.5517 - val_loss: 1.6974 - val_mae: 1.6974\n",
            "Epoch 481/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6041 - mae: 0.6041 - val_loss: 1.7076 - val_mae: 1.7076\n",
            "Epoch 482/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6555 - mae: 0.6555 - val_loss: 1.7082 - val_mae: 1.7082\n",
            "Epoch 483/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.6214 - mae: 0.6214 - val_loss: 1.7112 - val_mae: 1.7112\n",
            "Epoch 484/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5557 - mae: 0.5557 - val_loss: 1.7428 - val_mae: 1.7428\n",
            "Epoch 485/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5279 - mae: 0.5279 - val_loss: 1.7456 - val_mae: 1.7456\n",
            "Epoch 486/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5865 - mae: 0.5865 - val_loss: 1.7540 - val_mae: 1.7540\n",
            "Epoch 487/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5538 - mae: 0.5538 - val_loss: 1.6944 - val_mae: 1.6944\n",
            "Epoch 488/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5509 - mae: 0.5509 - val_loss: 1.7408 - val_mae: 1.7408\n",
            "Epoch 489/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5453 - mae: 0.5453 - val_loss: 1.7601 - val_mae: 1.7601\n",
            "Epoch 490/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5915 - mae: 0.5915 - val_loss: 1.7822 - val_mae: 1.7822\n",
            "Epoch 491/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.6667 - mae: 0.6667 - val_loss: 1.8402 - val_mae: 1.8402\n",
            "Epoch 492/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.6494 - mae: 0.6494 - val_loss: 1.7994 - val_mae: 1.7994\n",
            "Epoch 493/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5995 - mae: 0.5995 - val_loss: 1.7368 - val_mae: 1.7368\n",
            "Epoch 494/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5914 - mae: 0.5914 - val_loss: 1.8067 - val_mae: 1.8067\n",
            "Epoch 495/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5652 - mae: 0.5652 - val_loss: 1.7390 - val_mae: 1.7390\n",
            "Epoch 496/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5619 - mae: 0.5619 - val_loss: 1.7552 - val_mae: 1.7552\n",
            "Epoch 497/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.6202 - mae: 0.6202 - val_loss: 1.6554 - val_mae: 1.6554\n",
            "Epoch 498/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5333 - mae: 0.5333 - val_loss: 1.7659 - val_mae: 1.7659\n",
            "Epoch 499/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.5393 - mae: 0.5393 - val_loss: 1.7193 - val_mae: 1.7193\n",
            "Epoch 500/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.5871 - mae: 0.5871 - val_loss: 1.7089 - val_mae: 1.7089\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4139997fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IEl3-k3bn7N"
      },
      "source": [
        "## Question 2\n",
        "\n",
        "Now that you know how MAE works, you need to plot the behavior of MAE for the synthetic errors given.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYyGYH4zbn7N"
      },
      "source": [
        "### Answer 2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "dr1OLhDu-dWs"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wK1qdGtBbn7N",
        "outputId": "032fef38-207d-41fb-c52d-1cab7e829ced",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "#errors = np.arange(-5, 6)\n",
        "#n = len(errors)\n",
        "\n",
        "actual_outputs = np.arange(-5, 6)\n",
        "n = len(actual_outputs)\n",
        "estimated_outputs = np.zeros(n)\n",
        "\n",
        "mae = abs(actual_outputs - estimated_outputs)\n",
        "        #The abs() function returns the absolute value of the specified number.\n",
        "\n",
        "plt.plot(actual_outputs, mae, c='#0095B6', marker='o')\n",
        "plt.grid()\n",
        "plt.xlabel('Difference between actual and estimated ouputs')\n",
        "plt.ylabel('Mean Absolute Errors')\n",
        "plt.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIFJ88ER6s7w"
      },
      "source": [
        "## Mean Squared Logarithmic Error [MSLE]\n",
        "\n",
        "MSLE is just like MSE, but we have to take $log$ of the actual and estimated outputs because squaring and averaging. \n",
        "\n",
        "The introduction of the logarithm makes MSLE only care about the relative difference between the true and the predicted value, or in other words, it only cares about the percentual difference between them.\n",
        "\n",
        "This means that MSLE will treat small differences between small true and predicted values approximately the same as big differences between large true and predicted values.\n",
        "\n",
        "We can use MSLE when we don't want large errors to be significantly more penalized than small ones, in those cases where the range of the target value is large.\n",
        "\n",
        "*Example*: You want to predict future house prices, and your dataset includes homes that are orders of magnitude different in price. The price is a continuous value, and therefore, we want to do regression. MSLE can here be used as the loss function.\n",
        "\n",
        "$$MSLE = \\frac{\\sum_{i=1}^{n}(\\log(y_i+1) - \\log(\\hat{y}_i+1))^2}{n}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBkzaP9R7KnB",
        "outputId": "b1052c0a-3f7c-4002-b5d4-04e1deacc58e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = keras.Sequential([\n",
        "        tf.keras.layers.Dense(100, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(50, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(20, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss=tf.keras.losses.MeanSquaredLogarithmicError(),\n",
        "              metrics=['mean_squared_logarithmic_error'])\n",
        "\n",
        "model.fit(train_features, train_labels, epochs=500, validation_split = 0.1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "12/12 [==============================] - 2s 18ms/step - loss: 6.5613 - mean_squared_logarithmic_error: 6.5613 - val_loss: 4.4585 - val_mean_squared_logarithmic_error: 4.4585\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 3.5081 - mean_squared_logarithmic_error: 3.5081 - val_loss: 2.4602 - val_mean_squared_logarithmic_error: 2.4602\n",
            "Epoch 3/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.9339 - mean_squared_logarithmic_error: 1.9339 - val_loss: 1.3213 - val_mean_squared_logarithmic_error: 1.3213\n",
            "Epoch 4/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 1.0507 - mean_squared_logarithmic_error: 1.0507 - val_loss: 0.7018 - val_mean_squared_logarithmic_error: 0.7018\n",
            "Epoch 5/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.5752 - mean_squared_logarithmic_error: 0.5752 - val_loss: 0.3948 - val_mean_squared_logarithmic_error: 0.3948\n",
            "Epoch 6/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.3393 - mean_squared_logarithmic_error: 0.3393 - val_loss: 0.2468 - val_mean_squared_logarithmic_error: 0.2468\n",
            "Epoch 7/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2267 - mean_squared_logarithmic_error: 0.2267 - val_loss: 0.1760 - val_mean_squared_logarithmic_error: 0.1760\n",
            "Epoch 8/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1686 - mean_squared_logarithmic_error: 0.1686 - val_loss: 0.1412 - val_mean_squared_logarithmic_error: 0.1412\n",
            "Epoch 9/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1375 - mean_squared_logarithmic_error: 0.1375 - val_loss: 0.1209 - val_mean_squared_logarithmic_error: 0.1209\n",
            "Epoch 10/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1201 - mean_squared_logarithmic_error: 0.1201 - val_loss: 0.1066 - val_mean_squared_logarithmic_error: 0.1066\n",
            "Epoch 11/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1062 - mean_squared_logarithmic_error: 0.1062 - val_loss: 0.0952 - val_mean_squared_logarithmic_error: 0.0952\n",
            "Epoch 12/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0962 - mean_squared_logarithmic_error: 0.0962 - val_loss: 0.0856 - val_mean_squared_logarithmic_error: 0.0856\n",
            "Epoch 13/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0873 - mean_squared_logarithmic_error: 0.0873 - val_loss: 0.0782 - val_mean_squared_logarithmic_error: 0.0782\n",
            "Epoch 14/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0802 - mean_squared_logarithmic_error: 0.0802 - val_loss: 0.0710 - val_mean_squared_logarithmic_error: 0.0710\n",
            "Epoch 15/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0736 - mean_squared_logarithmic_error: 0.0736 - val_loss: 0.0648 - val_mean_squared_logarithmic_error: 0.0648\n",
            "Epoch 16/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0681 - mean_squared_logarithmic_error: 0.0681 - val_loss: 0.0595 - val_mean_squared_logarithmic_error: 0.0595\n",
            "Epoch 17/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0632 - mean_squared_logarithmic_error: 0.0632 - val_loss: 0.0541 - val_mean_squared_logarithmic_error: 0.0541\n",
            "Epoch 18/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0585 - mean_squared_logarithmic_error: 0.0585 - val_loss: 0.0500 - val_mean_squared_logarithmic_error: 0.0500\n",
            "Epoch 19/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0547 - mean_squared_logarithmic_error: 0.0547 - val_loss: 0.0460 - val_mean_squared_logarithmic_error: 0.0460\n",
            "Epoch 20/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0512 - mean_squared_logarithmic_error: 0.0512 - val_loss: 0.0428 - val_mean_squared_logarithmic_error: 0.0428\n",
            "Epoch 21/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0481 - mean_squared_logarithmic_error: 0.0481 - val_loss: 0.0397 - val_mean_squared_logarithmic_error: 0.0397\n",
            "Epoch 22/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0453 - mean_squared_logarithmic_error: 0.0453 - val_loss: 0.0371 - val_mean_squared_logarithmic_error: 0.0371\n",
            "Epoch 23/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0430 - mean_squared_logarithmic_error: 0.0430 - val_loss: 0.0348 - val_mean_squared_logarithmic_error: 0.0348\n",
            "Epoch 24/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0408 - mean_squared_logarithmic_error: 0.0408 - val_loss: 0.0330 - val_mean_squared_logarithmic_error: 0.0330\n",
            "Epoch 25/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0389 - mean_squared_logarithmic_error: 0.0389 - val_loss: 0.0313 - val_mean_squared_logarithmic_error: 0.0313\n",
            "Epoch 26/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0373 - mean_squared_logarithmic_error: 0.0373 - val_loss: 0.0299 - val_mean_squared_logarithmic_error: 0.0299\n",
            "Epoch 27/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0359 - mean_squared_logarithmic_error: 0.0359 - val_loss: 0.0284 - val_mean_squared_logarithmic_error: 0.0284\n",
            "Epoch 28/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0345 - mean_squared_logarithmic_error: 0.0345 - val_loss: 0.0274 - val_mean_squared_logarithmic_error: 0.0274\n",
            "Epoch 29/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0335 - mean_squared_logarithmic_error: 0.0335 - val_loss: 0.0269 - val_mean_squared_logarithmic_error: 0.0269\n",
            "Epoch 30/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0326 - mean_squared_logarithmic_error: 0.0326 - val_loss: 0.0260 - val_mean_squared_logarithmic_error: 0.0260\n",
            "Epoch 31/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0318 - mean_squared_logarithmic_error: 0.0318 - val_loss: 0.0253 - val_mean_squared_logarithmic_error: 0.0253\n",
            "Epoch 32/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0310 - mean_squared_logarithmic_error: 0.0310 - val_loss: 0.0246 - val_mean_squared_logarithmic_error: 0.0246\n",
            "Epoch 33/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0302 - mean_squared_logarithmic_error: 0.0302 - val_loss: 0.0242 - val_mean_squared_logarithmic_error: 0.0242\n",
            "Epoch 34/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0297 - mean_squared_logarithmic_error: 0.0297 - val_loss: 0.0237 - val_mean_squared_logarithmic_error: 0.0237\n",
            "Epoch 35/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0291 - mean_squared_logarithmic_error: 0.0291 - val_loss: 0.0231 - val_mean_squared_logarithmic_error: 0.0231\n",
            "Epoch 36/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0288 - mean_squared_logarithmic_error: 0.0288 - val_loss: 0.0226 - val_mean_squared_logarithmic_error: 0.0226\n",
            "Epoch 37/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0281 - mean_squared_logarithmic_error: 0.0281 - val_loss: 0.0228 - val_mean_squared_logarithmic_error: 0.0228\n",
            "Epoch 38/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0277 - mean_squared_logarithmic_error: 0.0277 - val_loss: 0.0226 - val_mean_squared_logarithmic_error: 0.0226\n",
            "Epoch 39/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0273 - mean_squared_logarithmic_error: 0.0273 - val_loss: 0.0223 - val_mean_squared_logarithmic_error: 0.0223\n",
            "Epoch 40/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0269 - mean_squared_logarithmic_error: 0.0269 - val_loss: 0.0221 - val_mean_squared_logarithmic_error: 0.0221\n",
            "Epoch 41/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0266 - mean_squared_logarithmic_error: 0.0266 - val_loss: 0.0218 - val_mean_squared_logarithmic_error: 0.0218\n",
            "Epoch 42/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0264 - mean_squared_logarithmic_error: 0.0264 - val_loss: 0.0218 - val_mean_squared_logarithmic_error: 0.0218\n",
            "Epoch 43/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0260 - mean_squared_logarithmic_error: 0.0260 - val_loss: 0.0214 - val_mean_squared_logarithmic_error: 0.0214\n",
            "Epoch 44/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0256 - mean_squared_logarithmic_error: 0.0256 - val_loss: 0.0213 - val_mean_squared_logarithmic_error: 0.0213\n",
            "Epoch 45/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0254 - mean_squared_logarithmic_error: 0.0254 - val_loss: 0.0215 - val_mean_squared_logarithmic_error: 0.0215\n",
            "Epoch 46/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0251 - mean_squared_logarithmic_error: 0.0251 - val_loss: 0.0216 - val_mean_squared_logarithmic_error: 0.0216\n",
            "Epoch 47/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0248 - mean_squared_logarithmic_error: 0.0248 - val_loss: 0.0214 - val_mean_squared_logarithmic_error: 0.0214\n",
            "Epoch 48/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0246 - mean_squared_logarithmic_error: 0.0246 - val_loss: 0.0209 - val_mean_squared_logarithmic_error: 0.0209\n",
            "Epoch 49/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0243 - mean_squared_logarithmic_error: 0.0243 - val_loss: 0.0206 - val_mean_squared_logarithmic_error: 0.0206\n",
            "Epoch 50/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0242 - mean_squared_logarithmic_error: 0.0242 - val_loss: 0.0209 - val_mean_squared_logarithmic_error: 0.0209\n",
            "Epoch 51/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0240 - mean_squared_logarithmic_error: 0.0240 - val_loss: 0.0208 - val_mean_squared_logarithmic_error: 0.0208\n",
            "Epoch 52/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0237 - mean_squared_logarithmic_error: 0.0237 - val_loss: 0.0205 - val_mean_squared_logarithmic_error: 0.0205\n",
            "Epoch 53/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0235 - mean_squared_logarithmic_error: 0.0235 - val_loss: 0.0203 - val_mean_squared_logarithmic_error: 0.0203\n",
            "Epoch 54/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0232 - mean_squared_logarithmic_error: 0.0232 - val_loss: 0.0204 - val_mean_squared_logarithmic_error: 0.0204\n",
            "Epoch 55/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0231 - mean_squared_logarithmic_error: 0.0231 - val_loss: 0.0203 - val_mean_squared_logarithmic_error: 0.0203\n",
            "Epoch 56/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0229 - mean_squared_logarithmic_error: 0.0229 - val_loss: 0.0201 - val_mean_squared_logarithmic_error: 0.0201\n",
            "Epoch 57/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0227 - mean_squared_logarithmic_error: 0.0227 - val_loss: 0.0198 - val_mean_squared_logarithmic_error: 0.0198\n",
            "Epoch 58/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0226 - mean_squared_logarithmic_error: 0.0226 - val_loss: 0.0201 - val_mean_squared_logarithmic_error: 0.0201\n",
            "Epoch 59/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0223 - mean_squared_logarithmic_error: 0.0223 - val_loss: 0.0197 - val_mean_squared_logarithmic_error: 0.0197\n",
            "Epoch 60/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0221 - mean_squared_logarithmic_error: 0.0221 - val_loss: 0.0193 - val_mean_squared_logarithmic_error: 0.0193\n",
            "Epoch 61/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0220 - mean_squared_logarithmic_error: 0.0220 - val_loss: 0.0193 - val_mean_squared_logarithmic_error: 0.0193\n",
            "Epoch 62/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0218 - mean_squared_logarithmic_error: 0.0218 - val_loss: 0.0192 - val_mean_squared_logarithmic_error: 0.0192\n",
            "Epoch 63/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0219 - mean_squared_logarithmic_error: 0.0219 - val_loss: 0.0198 - val_mean_squared_logarithmic_error: 0.0198\n",
            "Epoch 64/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0216 - mean_squared_logarithmic_error: 0.0216 - val_loss: 0.0187 - val_mean_squared_logarithmic_error: 0.0187\n",
            "Epoch 65/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0214 - mean_squared_logarithmic_error: 0.0214 - val_loss: 0.0186 - val_mean_squared_logarithmic_error: 0.0186\n",
            "Epoch 66/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0212 - mean_squared_logarithmic_error: 0.0212 - val_loss: 0.0191 - val_mean_squared_logarithmic_error: 0.0191\n",
            "Epoch 67/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0214 - mean_squared_logarithmic_error: 0.0214 - val_loss: 0.0184 - val_mean_squared_logarithmic_error: 0.0184\n",
            "Epoch 68/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0209 - mean_squared_logarithmic_error: 0.0209 - val_loss: 0.0190 - val_mean_squared_logarithmic_error: 0.0190\n",
            "Epoch 69/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0208 - mean_squared_logarithmic_error: 0.0208 - val_loss: 0.0187 - val_mean_squared_logarithmic_error: 0.0187\n",
            "Epoch 70/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0206 - mean_squared_logarithmic_error: 0.0206 - val_loss: 0.0185 - val_mean_squared_logarithmic_error: 0.0185\n",
            "Epoch 71/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0206 - mean_squared_logarithmic_error: 0.0206 - val_loss: 0.0183 - val_mean_squared_logarithmic_error: 0.0183\n",
            "Epoch 72/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0204 - mean_squared_logarithmic_error: 0.0204 - val_loss: 0.0187 - val_mean_squared_logarithmic_error: 0.0187\n",
            "Epoch 73/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0203 - mean_squared_logarithmic_error: 0.0203 - val_loss: 0.0184 - val_mean_squared_logarithmic_error: 0.0184\n",
            "Epoch 74/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0202 - mean_squared_logarithmic_error: 0.0202 - val_loss: 0.0189 - val_mean_squared_logarithmic_error: 0.0189\n",
            "Epoch 75/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0200 - mean_squared_logarithmic_error: 0.0200 - val_loss: 0.0183 - val_mean_squared_logarithmic_error: 0.0183\n",
            "Epoch 76/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0199 - mean_squared_logarithmic_error: 0.0199 - val_loss: 0.0181 - val_mean_squared_logarithmic_error: 0.0181\n",
            "Epoch 77/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0199 - mean_squared_logarithmic_error: 0.0199 - val_loss: 0.0184 - val_mean_squared_logarithmic_error: 0.0184\n",
            "Epoch 78/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0199 - mean_squared_logarithmic_error: 0.0199 - val_loss: 0.0176 - val_mean_squared_logarithmic_error: 0.0176\n",
            "Epoch 79/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0198 - mean_squared_logarithmic_error: 0.0198 - val_loss: 0.0186 - val_mean_squared_logarithmic_error: 0.0186\n",
            "Epoch 80/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0196 - mean_squared_logarithmic_error: 0.0196 - val_loss: 0.0181 - val_mean_squared_logarithmic_error: 0.0181\n",
            "Epoch 81/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0196 - mean_squared_logarithmic_error: 0.0196 - val_loss: 0.0176 - val_mean_squared_logarithmic_error: 0.0176\n",
            "Epoch 82/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0195 - mean_squared_logarithmic_error: 0.0195 - val_loss: 0.0183 - val_mean_squared_logarithmic_error: 0.0183\n",
            "Epoch 83/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0193 - mean_squared_logarithmic_error: 0.0193 - val_loss: 0.0178 - val_mean_squared_logarithmic_error: 0.0178\n",
            "Epoch 84/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0192 - mean_squared_logarithmic_error: 0.0192 - val_loss: 0.0181 - val_mean_squared_logarithmic_error: 0.0181\n",
            "Epoch 85/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0189 - mean_squared_logarithmic_error: 0.0189 - val_loss: 0.0175 - val_mean_squared_logarithmic_error: 0.0175\n",
            "Epoch 86/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0190 - mean_squared_logarithmic_error: 0.0190 - val_loss: 0.0179 - val_mean_squared_logarithmic_error: 0.0179\n",
            "Epoch 87/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0188 - mean_squared_logarithmic_error: 0.0188 - val_loss: 0.0177 - val_mean_squared_logarithmic_error: 0.0177\n",
            "Epoch 88/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0187 - mean_squared_logarithmic_error: 0.0187 - val_loss: 0.0176 - val_mean_squared_logarithmic_error: 0.0176\n",
            "Epoch 89/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0186 - mean_squared_logarithmic_error: 0.0186 - val_loss: 0.0173 - val_mean_squared_logarithmic_error: 0.0173\n",
            "Epoch 90/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0186 - mean_squared_logarithmic_error: 0.0186 - val_loss: 0.0173 - val_mean_squared_logarithmic_error: 0.0173\n",
            "Epoch 91/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0184 - mean_squared_logarithmic_error: 0.0184 - val_loss: 0.0175 - val_mean_squared_logarithmic_error: 0.0175\n",
            "Epoch 92/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0183 - mean_squared_logarithmic_error: 0.0183 - val_loss: 0.0175 - val_mean_squared_logarithmic_error: 0.0175\n",
            "Epoch 93/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0183 - mean_squared_logarithmic_error: 0.0183 - val_loss: 0.0172 - val_mean_squared_logarithmic_error: 0.0172\n",
            "Epoch 94/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0182 - mean_squared_logarithmic_error: 0.0182 - val_loss: 0.0176 - val_mean_squared_logarithmic_error: 0.0176\n",
            "Epoch 95/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0182 - mean_squared_logarithmic_error: 0.0182 - val_loss: 0.0174 - val_mean_squared_logarithmic_error: 0.0174\n",
            "Epoch 96/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0180 - mean_squared_logarithmic_error: 0.0180 - val_loss: 0.0180 - val_mean_squared_logarithmic_error: 0.0180\n",
            "Epoch 97/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0180 - mean_squared_logarithmic_error: 0.0180 - val_loss: 0.0178 - val_mean_squared_logarithmic_error: 0.0178\n",
            "Epoch 98/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0179 - mean_squared_logarithmic_error: 0.0179 - val_loss: 0.0177 - val_mean_squared_logarithmic_error: 0.0177\n",
            "Epoch 99/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0179 - mean_squared_logarithmic_error: 0.0179 - val_loss: 0.0176 - val_mean_squared_logarithmic_error: 0.0176\n",
            "Epoch 100/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0177 - mean_squared_logarithmic_error: 0.0177 - val_loss: 0.0174 - val_mean_squared_logarithmic_error: 0.0174\n",
            "Epoch 101/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0176 - mean_squared_logarithmic_error: 0.0176 - val_loss: 0.0175 - val_mean_squared_logarithmic_error: 0.0175\n",
            "Epoch 102/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0176 - mean_squared_logarithmic_error: 0.0176 - val_loss: 0.0177 - val_mean_squared_logarithmic_error: 0.0177\n",
            "Epoch 103/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0176 - mean_squared_logarithmic_error: 0.0176 - val_loss: 0.0176 - val_mean_squared_logarithmic_error: 0.0176\n",
            "Epoch 104/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0174 - mean_squared_logarithmic_error: 0.0174 - val_loss: 0.0173 - val_mean_squared_logarithmic_error: 0.0173\n",
            "Epoch 105/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0175 - mean_squared_logarithmic_error: 0.0175 - val_loss: 0.0171 - val_mean_squared_logarithmic_error: 0.0171\n",
            "Epoch 106/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0172 - mean_squared_logarithmic_error: 0.0172 - val_loss: 0.0177 - val_mean_squared_logarithmic_error: 0.0177\n",
            "Epoch 107/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0173 - mean_squared_logarithmic_error: 0.0173 - val_loss: 0.0176 - val_mean_squared_logarithmic_error: 0.0176\n",
            "Epoch 108/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0172 - mean_squared_logarithmic_error: 0.0172 - val_loss: 0.0174 - val_mean_squared_logarithmic_error: 0.0174\n",
            "Epoch 109/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0170 - mean_squared_logarithmic_error: 0.0170 - val_loss: 0.0180 - val_mean_squared_logarithmic_error: 0.0180\n",
            "Epoch 110/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0170 - mean_squared_logarithmic_error: 0.0170 - val_loss: 0.0177 - val_mean_squared_logarithmic_error: 0.0177\n",
            "Epoch 111/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0170 - mean_squared_logarithmic_error: 0.0170 - val_loss: 0.0173 - val_mean_squared_logarithmic_error: 0.0173\n",
            "Epoch 112/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0171 - mean_squared_logarithmic_error: 0.0171 - val_loss: 0.0179 - val_mean_squared_logarithmic_error: 0.0179\n",
            "Epoch 113/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0169 - mean_squared_logarithmic_error: 0.0169 - val_loss: 0.0168 - val_mean_squared_logarithmic_error: 0.0168\n",
            "Epoch 114/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0167 - mean_squared_logarithmic_error: 0.0167 - val_loss: 0.0172 - val_mean_squared_logarithmic_error: 0.0172\n",
            "Epoch 115/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0166 - mean_squared_logarithmic_error: 0.0166 - val_loss: 0.0176 - val_mean_squared_logarithmic_error: 0.0176\n",
            "Epoch 116/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0166 - mean_squared_logarithmic_error: 0.0166 - val_loss: 0.0174 - val_mean_squared_logarithmic_error: 0.0174\n",
            "Epoch 117/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0166 - mean_squared_logarithmic_error: 0.0166 - val_loss: 0.0170 - val_mean_squared_logarithmic_error: 0.0170\n",
            "Epoch 118/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0164 - mean_squared_logarithmic_error: 0.0164 - val_loss: 0.0172 - val_mean_squared_logarithmic_error: 0.0172\n",
            "Epoch 119/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0164 - mean_squared_logarithmic_error: 0.0164 - val_loss: 0.0174 - val_mean_squared_logarithmic_error: 0.0174\n",
            "Epoch 120/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0163 - mean_squared_logarithmic_error: 0.0163 - val_loss: 0.0179 - val_mean_squared_logarithmic_error: 0.0179\n",
            "Epoch 121/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0163 - mean_squared_logarithmic_error: 0.0163 - val_loss: 0.0175 - val_mean_squared_logarithmic_error: 0.0175\n",
            "Epoch 122/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0162 - mean_squared_logarithmic_error: 0.0162 - val_loss: 0.0176 - val_mean_squared_logarithmic_error: 0.0176\n",
            "Epoch 123/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0162 - mean_squared_logarithmic_error: 0.0162 - val_loss: 0.0180 - val_mean_squared_logarithmic_error: 0.0180\n",
            "Epoch 124/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0161 - mean_squared_logarithmic_error: 0.0161 - val_loss: 0.0176 - val_mean_squared_logarithmic_error: 0.0176\n",
            "Epoch 125/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0162 - mean_squared_logarithmic_error: 0.0162 - val_loss: 0.0176 - val_mean_squared_logarithmic_error: 0.0176\n",
            "Epoch 126/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0161 - mean_squared_logarithmic_error: 0.0161 - val_loss: 0.0168 - val_mean_squared_logarithmic_error: 0.0168\n",
            "Epoch 127/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0160 - mean_squared_logarithmic_error: 0.0160 - val_loss: 0.0173 - val_mean_squared_logarithmic_error: 0.0173\n",
            "Epoch 128/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0163 - mean_squared_logarithmic_error: 0.0163 - val_loss: 0.0176 - val_mean_squared_logarithmic_error: 0.0176\n",
            "Epoch 129/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0163 - mean_squared_logarithmic_error: 0.0163 - val_loss: 0.0170 - val_mean_squared_logarithmic_error: 0.0170\n",
            "Epoch 130/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0157 - mean_squared_logarithmic_error: 0.0157 - val_loss: 0.0175 - val_mean_squared_logarithmic_error: 0.0175\n",
            "Epoch 131/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0157 - mean_squared_logarithmic_error: 0.0157 - val_loss: 0.0179 - val_mean_squared_logarithmic_error: 0.0179\n",
            "Epoch 132/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0155 - mean_squared_logarithmic_error: 0.0155 - val_loss: 0.0166 - val_mean_squared_logarithmic_error: 0.0166\n",
            "Epoch 133/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0157 - mean_squared_logarithmic_error: 0.0157 - val_loss: 0.0167 - val_mean_squared_logarithmic_error: 0.0167\n",
            "Epoch 134/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0156 - mean_squared_logarithmic_error: 0.0156 - val_loss: 0.0171 - val_mean_squared_logarithmic_error: 0.0171\n",
            "Epoch 135/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0155 - mean_squared_logarithmic_error: 0.0155 - val_loss: 0.0167 - val_mean_squared_logarithmic_error: 0.0167\n",
            "Epoch 136/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0154 - mean_squared_logarithmic_error: 0.0154 - val_loss: 0.0172 - val_mean_squared_logarithmic_error: 0.0172\n",
            "Epoch 137/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0154 - mean_squared_logarithmic_error: 0.0154 - val_loss: 0.0173 - val_mean_squared_logarithmic_error: 0.0173\n",
            "Epoch 138/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0153 - mean_squared_logarithmic_error: 0.0153 - val_loss: 0.0175 - val_mean_squared_logarithmic_error: 0.0175\n",
            "Epoch 139/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0153 - mean_squared_logarithmic_error: 0.0153 - val_loss: 0.0170 - val_mean_squared_logarithmic_error: 0.0170\n",
            "Epoch 140/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0155 - mean_squared_logarithmic_error: 0.0155 - val_loss: 0.0176 - val_mean_squared_logarithmic_error: 0.0176\n",
            "Epoch 141/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0155 - mean_squared_logarithmic_error: 0.0155 - val_loss: 0.0163 - val_mean_squared_logarithmic_error: 0.0163\n",
            "Epoch 142/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0153 - mean_squared_logarithmic_error: 0.0153 - val_loss: 0.0168 - val_mean_squared_logarithmic_error: 0.0168\n",
            "Epoch 143/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0152 - mean_squared_logarithmic_error: 0.0152 - val_loss: 0.0163 - val_mean_squared_logarithmic_error: 0.0163\n",
            "Epoch 144/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0149 - mean_squared_logarithmic_error: 0.0149 - val_loss: 0.0169 - val_mean_squared_logarithmic_error: 0.0169\n",
            "Epoch 145/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0150 - mean_squared_logarithmic_error: 0.0150 - val_loss: 0.0174 - val_mean_squared_logarithmic_error: 0.0174\n",
            "Epoch 146/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0152 - mean_squared_logarithmic_error: 0.0152 - val_loss: 0.0170 - val_mean_squared_logarithmic_error: 0.0170\n",
            "Epoch 147/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0150 - mean_squared_logarithmic_error: 0.0150 - val_loss: 0.0180 - val_mean_squared_logarithmic_error: 0.0180\n",
            "Epoch 148/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0149 - mean_squared_logarithmic_error: 0.0149 - val_loss: 0.0170 - val_mean_squared_logarithmic_error: 0.0170\n",
            "Epoch 149/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0147 - mean_squared_logarithmic_error: 0.0147 - val_loss: 0.0168 - val_mean_squared_logarithmic_error: 0.0168\n",
            "Epoch 150/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0147 - mean_squared_logarithmic_error: 0.0147 - val_loss: 0.0171 - val_mean_squared_logarithmic_error: 0.0171\n",
            "Epoch 151/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0148 - mean_squared_logarithmic_error: 0.0148 - val_loss: 0.0168 - val_mean_squared_logarithmic_error: 0.0168\n",
            "Epoch 152/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0147 - mean_squared_logarithmic_error: 0.0147 - val_loss: 0.0179 - val_mean_squared_logarithmic_error: 0.0179\n",
            "Epoch 153/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0149 - mean_squared_logarithmic_error: 0.0149 - val_loss: 0.0165 - val_mean_squared_logarithmic_error: 0.0165\n",
            "Epoch 154/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0146 - mean_squared_logarithmic_error: 0.0146 - val_loss: 0.0173 - val_mean_squared_logarithmic_error: 0.0173\n",
            "Epoch 155/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0148 - mean_squared_logarithmic_error: 0.0148 - val_loss: 0.0163 - val_mean_squared_logarithmic_error: 0.0163\n",
            "Epoch 156/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0154 - mean_squared_logarithmic_error: 0.0154 - val_loss: 0.0168 - val_mean_squared_logarithmic_error: 0.0168\n",
            "Epoch 157/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0141 - mean_squared_logarithmic_error: 0.0141 - val_loss: 0.0164 - val_mean_squared_logarithmic_error: 0.0164\n",
            "Epoch 158/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0143 - mean_squared_logarithmic_error: 0.0143 - val_loss: 0.0172 - val_mean_squared_logarithmic_error: 0.0172\n",
            "Epoch 159/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0142 - mean_squared_logarithmic_error: 0.0142 - val_loss: 0.0173 - val_mean_squared_logarithmic_error: 0.0173\n",
            "Epoch 160/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0141 - mean_squared_logarithmic_error: 0.0141 - val_loss: 0.0168 - val_mean_squared_logarithmic_error: 0.0168\n",
            "Epoch 161/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0142 - mean_squared_logarithmic_error: 0.0142 - val_loss: 0.0167 - val_mean_squared_logarithmic_error: 0.0167\n",
            "Epoch 162/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0139 - mean_squared_logarithmic_error: 0.0139 - val_loss: 0.0170 - val_mean_squared_logarithmic_error: 0.0170\n",
            "Epoch 163/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0139 - mean_squared_logarithmic_error: 0.0139 - val_loss: 0.0171 - val_mean_squared_logarithmic_error: 0.0171\n",
            "Epoch 164/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0140 - mean_squared_logarithmic_error: 0.0140 - val_loss: 0.0168 - val_mean_squared_logarithmic_error: 0.0168\n",
            "Epoch 165/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0142 - mean_squared_logarithmic_error: 0.0142 - val_loss: 0.0172 - val_mean_squared_logarithmic_error: 0.0172\n",
            "Epoch 166/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0139 - mean_squared_logarithmic_error: 0.0139 - val_loss: 0.0170 - val_mean_squared_logarithmic_error: 0.0170\n",
            "Epoch 167/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0139 - mean_squared_logarithmic_error: 0.0139 - val_loss: 0.0170 - val_mean_squared_logarithmic_error: 0.0170\n",
            "Epoch 168/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0136 - mean_squared_logarithmic_error: 0.0136 - val_loss: 0.0166 - val_mean_squared_logarithmic_error: 0.0166\n",
            "Epoch 169/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0137 - mean_squared_logarithmic_error: 0.0137 - val_loss: 0.0170 - val_mean_squared_logarithmic_error: 0.0170\n",
            "Epoch 170/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0137 - mean_squared_logarithmic_error: 0.0137 - val_loss: 0.0170 - val_mean_squared_logarithmic_error: 0.0170\n",
            "Epoch 171/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0137 - mean_squared_logarithmic_error: 0.0137 - val_loss: 0.0169 - val_mean_squared_logarithmic_error: 0.0169\n",
            "Epoch 172/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0136 - mean_squared_logarithmic_error: 0.0136 - val_loss: 0.0166 - val_mean_squared_logarithmic_error: 0.0166\n",
            "Epoch 173/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0135 - mean_squared_logarithmic_error: 0.0135 - val_loss: 0.0167 - val_mean_squared_logarithmic_error: 0.0167\n",
            "Epoch 174/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0135 - mean_squared_logarithmic_error: 0.0135 - val_loss: 0.0171 - val_mean_squared_logarithmic_error: 0.0171\n",
            "Epoch 175/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0134 - mean_squared_logarithmic_error: 0.0134 - val_loss: 0.0163 - val_mean_squared_logarithmic_error: 0.0163\n",
            "Epoch 176/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0134 - mean_squared_logarithmic_error: 0.0134 - val_loss: 0.0168 - val_mean_squared_logarithmic_error: 0.0168\n",
            "Epoch 177/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0137 - mean_squared_logarithmic_error: 0.0137 - val_loss: 0.0164 - val_mean_squared_logarithmic_error: 0.0164\n",
            "Epoch 178/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0133 - mean_squared_logarithmic_error: 0.0133 - val_loss: 0.0167 - val_mean_squared_logarithmic_error: 0.0167\n",
            "Epoch 179/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0131 - mean_squared_logarithmic_error: 0.0131 - val_loss: 0.0175 - val_mean_squared_logarithmic_error: 0.0175\n",
            "Epoch 180/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0132 - mean_squared_logarithmic_error: 0.0132 - val_loss: 0.0167 - val_mean_squared_logarithmic_error: 0.0167\n",
            "Epoch 181/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0135 - mean_squared_logarithmic_error: 0.0135 - val_loss: 0.0168 - val_mean_squared_logarithmic_error: 0.0168\n",
            "Epoch 182/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0130 - mean_squared_logarithmic_error: 0.0130 - val_loss: 0.0166 - val_mean_squared_logarithmic_error: 0.0166\n",
            "Epoch 183/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0130 - mean_squared_logarithmic_error: 0.0130 - val_loss: 0.0168 - val_mean_squared_logarithmic_error: 0.0168\n",
            "Epoch 184/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0129 - mean_squared_logarithmic_error: 0.0129 - val_loss: 0.0169 - val_mean_squared_logarithmic_error: 0.0169\n",
            "Epoch 185/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0130 - mean_squared_logarithmic_error: 0.0130 - val_loss: 0.0171 - val_mean_squared_logarithmic_error: 0.0171\n",
            "Epoch 186/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0129 - mean_squared_logarithmic_error: 0.0129 - val_loss: 0.0163 - val_mean_squared_logarithmic_error: 0.0163\n",
            "Epoch 187/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0129 - mean_squared_logarithmic_error: 0.0129 - val_loss: 0.0170 - val_mean_squared_logarithmic_error: 0.0170\n",
            "Epoch 188/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0132 - mean_squared_logarithmic_error: 0.0132 - val_loss: 0.0168 - val_mean_squared_logarithmic_error: 0.0168\n",
            "Epoch 189/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0128 - mean_squared_logarithmic_error: 0.0128 - val_loss: 0.0163 - val_mean_squared_logarithmic_error: 0.0163\n",
            "Epoch 190/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0130 - mean_squared_logarithmic_error: 0.0130 - val_loss: 0.0168 - val_mean_squared_logarithmic_error: 0.0168\n",
            "Epoch 191/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0128 - mean_squared_logarithmic_error: 0.0128 - val_loss: 0.0163 - val_mean_squared_logarithmic_error: 0.0163\n",
            "Epoch 192/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0128 - mean_squared_logarithmic_error: 0.0128 - val_loss: 0.0163 - val_mean_squared_logarithmic_error: 0.0163\n",
            "Epoch 193/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0125 - mean_squared_logarithmic_error: 0.0125 - val_loss: 0.0161 - val_mean_squared_logarithmic_error: 0.0161\n",
            "Epoch 194/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0127 - mean_squared_logarithmic_error: 0.0127 - val_loss: 0.0175 - val_mean_squared_logarithmic_error: 0.0175\n",
            "Epoch 195/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0126 - mean_squared_logarithmic_error: 0.0126 - val_loss: 0.0164 - val_mean_squared_logarithmic_error: 0.0164\n",
            "Epoch 196/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0124 - mean_squared_logarithmic_error: 0.0124 - val_loss: 0.0164 - val_mean_squared_logarithmic_error: 0.0164\n",
            "Epoch 197/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0124 - mean_squared_logarithmic_error: 0.0124 - val_loss: 0.0164 - val_mean_squared_logarithmic_error: 0.0164\n",
            "Epoch 198/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0124 - mean_squared_logarithmic_error: 0.0124 - val_loss: 0.0159 - val_mean_squared_logarithmic_error: 0.0159\n",
            "Epoch 199/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0124 - mean_squared_logarithmic_error: 0.0124 - val_loss: 0.0162 - val_mean_squared_logarithmic_error: 0.0162\n",
            "Epoch 200/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0122 - mean_squared_logarithmic_error: 0.0122 - val_loss: 0.0169 - val_mean_squared_logarithmic_error: 0.0169\n",
            "Epoch 201/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0123 - mean_squared_logarithmic_error: 0.0123 - val_loss: 0.0164 - val_mean_squared_logarithmic_error: 0.0164\n",
            "Epoch 202/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0121 - mean_squared_logarithmic_error: 0.0121 - val_loss: 0.0161 - val_mean_squared_logarithmic_error: 0.0161\n",
            "Epoch 203/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0124 - mean_squared_logarithmic_error: 0.0124 - val_loss: 0.0167 - val_mean_squared_logarithmic_error: 0.0167\n",
            "Epoch 204/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0124 - mean_squared_logarithmic_error: 0.0124 - val_loss: 0.0163 - val_mean_squared_logarithmic_error: 0.0163\n",
            "Epoch 205/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0123 - mean_squared_logarithmic_error: 0.0123 - val_loss: 0.0171 - val_mean_squared_logarithmic_error: 0.0171\n",
            "Epoch 206/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0122 - mean_squared_logarithmic_error: 0.0122 - val_loss: 0.0162 - val_mean_squared_logarithmic_error: 0.0162\n",
            "Epoch 207/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0121 - mean_squared_logarithmic_error: 0.0121 - val_loss: 0.0170 - val_mean_squared_logarithmic_error: 0.0170\n",
            "Epoch 208/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0120 - mean_squared_logarithmic_error: 0.0120 - val_loss: 0.0163 - val_mean_squared_logarithmic_error: 0.0163\n",
            "Epoch 209/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0118 - mean_squared_logarithmic_error: 0.0118 - val_loss: 0.0161 - val_mean_squared_logarithmic_error: 0.0161\n",
            "Epoch 210/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0121 - mean_squared_logarithmic_error: 0.0121 - val_loss: 0.0171 - val_mean_squared_logarithmic_error: 0.0171\n",
            "Epoch 211/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0120 - mean_squared_logarithmic_error: 0.0120 - val_loss: 0.0160 - val_mean_squared_logarithmic_error: 0.0160\n",
            "Epoch 212/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0121 - mean_squared_logarithmic_error: 0.0121 - val_loss: 0.0165 - val_mean_squared_logarithmic_error: 0.0165\n",
            "Epoch 213/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0128 - mean_squared_logarithmic_error: 0.0128 - val_loss: 0.0164 - val_mean_squared_logarithmic_error: 0.0164\n",
            "Epoch 214/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0119 - mean_squared_logarithmic_error: 0.0119 - val_loss: 0.0166 - val_mean_squared_logarithmic_error: 0.0166\n",
            "Epoch 215/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0117 - mean_squared_logarithmic_error: 0.0117 - val_loss: 0.0165 - val_mean_squared_logarithmic_error: 0.0165\n",
            "Epoch 216/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0116 - mean_squared_logarithmic_error: 0.0116 - val_loss: 0.0167 - val_mean_squared_logarithmic_error: 0.0167\n",
            "Epoch 217/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0115 - mean_squared_logarithmic_error: 0.0115 - val_loss: 0.0161 - val_mean_squared_logarithmic_error: 0.0161\n",
            "Epoch 218/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0115 - mean_squared_logarithmic_error: 0.0115 - val_loss: 0.0159 - val_mean_squared_logarithmic_error: 0.0159\n",
            "Epoch 219/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0113 - mean_squared_logarithmic_error: 0.0113 - val_loss: 0.0159 - val_mean_squared_logarithmic_error: 0.0159\n",
            "Epoch 220/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0114 - mean_squared_logarithmic_error: 0.0114 - val_loss: 0.0164 - val_mean_squared_logarithmic_error: 0.0164\n",
            "Epoch 221/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0113 - mean_squared_logarithmic_error: 0.0113 - val_loss: 0.0165 - val_mean_squared_logarithmic_error: 0.0165\n",
            "Epoch 222/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0114 - mean_squared_logarithmic_error: 0.0114 - val_loss: 0.0166 - val_mean_squared_logarithmic_error: 0.0166\n",
            "Epoch 223/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0112 - mean_squared_logarithmic_error: 0.0112 - val_loss: 0.0157 - val_mean_squared_logarithmic_error: 0.0157\n",
            "Epoch 224/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0115 - mean_squared_logarithmic_error: 0.0115 - val_loss: 0.0164 - val_mean_squared_logarithmic_error: 0.0164\n",
            "Epoch 225/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0112 - mean_squared_logarithmic_error: 0.0112 - val_loss: 0.0164 - val_mean_squared_logarithmic_error: 0.0164\n",
            "Epoch 226/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0111 - mean_squared_logarithmic_error: 0.0111 - val_loss: 0.0163 - val_mean_squared_logarithmic_error: 0.0163\n",
            "Epoch 227/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0110 - mean_squared_logarithmic_error: 0.0110 - val_loss: 0.0164 - val_mean_squared_logarithmic_error: 0.0164\n",
            "Epoch 228/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0112 - mean_squared_logarithmic_error: 0.0112 - val_loss: 0.0157 - val_mean_squared_logarithmic_error: 0.0157\n",
            "Epoch 229/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0111 - mean_squared_logarithmic_error: 0.0111 - val_loss: 0.0166 - val_mean_squared_logarithmic_error: 0.0166\n",
            "Epoch 230/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0111 - mean_squared_logarithmic_error: 0.0111 - val_loss: 0.0161 - val_mean_squared_logarithmic_error: 0.0161\n",
            "Epoch 231/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0110 - mean_squared_logarithmic_error: 0.0110 - val_loss: 0.0167 - val_mean_squared_logarithmic_error: 0.0167\n",
            "Epoch 232/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0109 - mean_squared_logarithmic_error: 0.0109 - val_loss: 0.0164 - val_mean_squared_logarithmic_error: 0.0164\n",
            "Epoch 233/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0109 - mean_squared_logarithmic_error: 0.0109 - val_loss: 0.0163 - val_mean_squared_logarithmic_error: 0.0163\n",
            "Epoch 234/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0109 - mean_squared_logarithmic_error: 0.0109 - val_loss: 0.0166 - val_mean_squared_logarithmic_error: 0.0166\n",
            "Epoch 235/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0110 - mean_squared_logarithmic_error: 0.0110 - val_loss: 0.0163 - val_mean_squared_logarithmic_error: 0.0163\n",
            "Epoch 236/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0108 - mean_squared_logarithmic_error: 0.0108 - val_loss: 0.0168 - val_mean_squared_logarithmic_error: 0.0168\n",
            "Epoch 237/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0110 - mean_squared_logarithmic_error: 0.0110 - val_loss: 0.0158 - val_mean_squared_logarithmic_error: 0.0158\n",
            "Epoch 238/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0108 - mean_squared_logarithmic_error: 0.0108 - val_loss: 0.0167 - val_mean_squared_logarithmic_error: 0.0167\n",
            "Epoch 239/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0106 - mean_squared_logarithmic_error: 0.0106 - val_loss: 0.0168 - val_mean_squared_logarithmic_error: 0.0168\n",
            "Epoch 240/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0106 - mean_squared_logarithmic_error: 0.0106 - val_loss: 0.0162 - val_mean_squared_logarithmic_error: 0.0162\n",
            "Epoch 241/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0106 - mean_squared_logarithmic_error: 0.0106 - val_loss: 0.0165 - val_mean_squared_logarithmic_error: 0.0165\n",
            "Epoch 242/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0108 - mean_squared_logarithmic_error: 0.0108 - val_loss: 0.0164 - val_mean_squared_logarithmic_error: 0.0164\n",
            "Epoch 243/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0113 - mean_squared_logarithmic_error: 0.0113 - val_loss: 0.0173 - val_mean_squared_logarithmic_error: 0.0173\n",
            "Epoch 244/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0111 - mean_squared_logarithmic_error: 0.0111 - val_loss: 0.0157 - val_mean_squared_logarithmic_error: 0.0157\n",
            "Epoch 245/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0106 - mean_squared_logarithmic_error: 0.0106 - val_loss: 0.0164 - val_mean_squared_logarithmic_error: 0.0164\n",
            "Epoch 246/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0107 - mean_squared_logarithmic_error: 0.0107 - val_loss: 0.0163 - val_mean_squared_logarithmic_error: 0.0163\n",
            "Epoch 247/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0105 - mean_squared_logarithmic_error: 0.0105 - val_loss: 0.0161 - val_mean_squared_logarithmic_error: 0.0161\n",
            "Epoch 248/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0103 - mean_squared_logarithmic_error: 0.0103 - val_loss: 0.0163 - val_mean_squared_logarithmic_error: 0.0163\n",
            "Epoch 249/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0103 - mean_squared_logarithmic_error: 0.0103 - val_loss: 0.0160 - val_mean_squared_logarithmic_error: 0.0160\n",
            "Epoch 250/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0102 - mean_squared_logarithmic_error: 0.0102 - val_loss: 0.0163 - val_mean_squared_logarithmic_error: 0.0163\n",
            "Epoch 251/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0102 - mean_squared_logarithmic_error: 0.0102 - val_loss: 0.0158 - val_mean_squared_logarithmic_error: 0.0158\n",
            "Epoch 252/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0100 - mean_squared_logarithmic_error: 0.0100 - val_loss: 0.0164 - val_mean_squared_logarithmic_error: 0.0164\n",
            "Epoch 253/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0100 - mean_squared_logarithmic_error: 0.0100 - val_loss: 0.0162 - val_mean_squared_logarithmic_error: 0.0162\n",
            "Epoch 254/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0100 - mean_squared_logarithmic_error: 0.0100 - val_loss: 0.0168 - val_mean_squared_logarithmic_error: 0.0168\n",
            "Epoch 255/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0100 - mean_squared_logarithmic_error: 0.0100 - val_loss: 0.0161 - val_mean_squared_logarithmic_error: 0.0161\n",
            "Epoch 256/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0100 - mean_squared_logarithmic_error: 0.0100 - val_loss: 0.0169 - val_mean_squared_logarithmic_error: 0.0169\n",
            "Epoch 257/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0100 - mean_squared_logarithmic_error: 0.0100 - val_loss: 0.0159 - val_mean_squared_logarithmic_error: 0.0159\n",
            "Epoch 258/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0101 - mean_squared_logarithmic_error: 0.0101 - val_loss: 0.0164 - val_mean_squared_logarithmic_error: 0.0164\n",
            "Epoch 259/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0102 - mean_squared_logarithmic_error: 0.0102 - val_loss: 0.0156 - val_mean_squared_logarithmic_error: 0.0156\n",
            "Epoch 260/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0099 - mean_squared_logarithmic_error: 0.0099 - val_loss: 0.0165 - val_mean_squared_logarithmic_error: 0.0165\n",
            "Epoch 261/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0099 - mean_squared_logarithmic_error: 0.0099 - val_loss: 0.0168 - val_mean_squared_logarithmic_error: 0.0168\n",
            "Epoch 262/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0097 - mean_squared_logarithmic_error: 0.0097 - val_loss: 0.0154 - val_mean_squared_logarithmic_error: 0.0154\n",
            "Epoch 263/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0098 - mean_squared_logarithmic_error: 0.0098 - val_loss: 0.0168 - val_mean_squared_logarithmic_error: 0.0168\n",
            "Epoch 264/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0096 - mean_squared_logarithmic_error: 0.0096 - val_loss: 0.0151 - val_mean_squared_logarithmic_error: 0.0151\n",
            "Epoch 265/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0099 - mean_squared_logarithmic_error: 0.0099 - val_loss: 0.0167 - val_mean_squared_logarithmic_error: 0.0167\n",
            "Epoch 266/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0099 - mean_squared_logarithmic_error: 0.0099 - val_loss: 0.0155 - val_mean_squared_logarithmic_error: 0.0155\n",
            "Epoch 267/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0098 - mean_squared_logarithmic_error: 0.0098 - val_loss: 0.0157 - val_mean_squared_logarithmic_error: 0.0157\n",
            "Epoch 268/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0094 - mean_squared_logarithmic_error: 0.0094 - val_loss: 0.0159 - val_mean_squared_logarithmic_error: 0.0159\n",
            "Epoch 269/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0094 - mean_squared_logarithmic_error: 0.0094 - val_loss: 0.0167 - val_mean_squared_logarithmic_error: 0.0167\n",
            "Epoch 270/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0094 - mean_squared_logarithmic_error: 0.0094 - val_loss: 0.0159 - val_mean_squared_logarithmic_error: 0.0159\n",
            "Epoch 271/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0094 - mean_squared_logarithmic_error: 0.0094 - val_loss: 0.0165 - val_mean_squared_logarithmic_error: 0.0165\n",
            "Epoch 272/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0092 - mean_squared_logarithmic_error: 0.0092 - val_loss: 0.0159 - val_mean_squared_logarithmic_error: 0.0159\n",
            "Epoch 273/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0093 - mean_squared_logarithmic_error: 0.0093 - val_loss: 0.0163 - val_mean_squared_logarithmic_error: 0.0163\n",
            "Epoch 274/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0100 - mean_squared_logarithmic_error: 0.0100 - val_loss: 0.0152 - val_mean_squared_logarithmic_error: 0.0152\n",
            "Epoch 275/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0096 - mean_squared_logarithmic_error: 0.0096 - val_loss: 0.0179 - val_mean_squared_logarithmic_error: 0.0179\n",
            "Epoch 276/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0093 - mean_squared_logarithmic_error: 0.0093 - val_loss: 0.0154 - val_mean_squared_logarithmic_error: 0.0154\n",
            "Epoch 277/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0101 - mean_squared_logarithmic_error: 0.0101 - val_loss: 0.0166 - val_mean_squared_logarithmic_error: 0.0166\n",
            "Epoch 278/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0095 - mean_squared_logarithmic_error: 0.0095 - val_loss: 0.0156 - val_mean_squared_logarithmic_error: 0.0156\n",
            "Epoch 279/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0090 - mean_squared_logarithmic_error: 0.0090 - val_loss: 0.0158 - val_mean_squared_logarithmic_error: 0.0158\n",
            "Epoch 280/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0090 - mean_squared_logarithmic_error: 0.0090 - val_loss: 0.0151 - val_mean_squared_logarithmic_error: 0.0151\n",
            "Epoch 281/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0094 - mean_squared_logarithmic_error: 0.0094 - val_loss: 0.0168 - val_mean_squared_logarithmic_error: 0.0168\n",
            "Epoch 282/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0090 - mean_squared_logarithmic_error: 0.0090 - val_loss: 0.0157 - val_mean_squared_logarithmic_error: 0.0157\n",
            "Epoch 283/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0093 - mean_squared_logarithmic_error: 0.0093 - val_loss: 0.0160 - val_mean_squared_logarithmic_error: 0.0160\n",
            "Epoch 284/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0088 - mean_squared_logarithmic_error: 0.0088 - val_loss: 0.0159 - val_mean_squared_logarithmic_error: 0.0159\n",
            "Epoch 285/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0088 - mean_squared_logarithmic_error: 0.0088 - val_loss: 0.0155 - val_mean_squared_logarithmic_error: 0.0155\n",
            "Epoch 286/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0086 - mean_squared_logarithmic_error: 0.0086 - val_loss: 0.0157 - val_mean_squared_logarithmic_error: 0.0157\n",
            "Epoch 287/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0086 - mean_squared_logarithmic_error: 0.0086 - val_loss: 0.0163 - val_mean_squared_logarithmic_error: 0.0163\n",
            "Epoch 288/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0089 - mean_squared_logarithmic_error: 0.0089 - val_loss: 0.0153 - val_mean_squared_logarithmic_error: 0.0153\n",
            "Epoch 289/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0090 - mean_squared_logarithmic_error: 0.0090 - val_loss: 0.0162 - val_mean_squared_logarithmic_error: 0.0162\n",
            "Epoch 290/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0087 - mean_squared_logarithmic_error: 0.0087 - val_loss: 0.0156 - val_mean_squared_logarithmic_error: 0.0156\n",
            "Epoch 291/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0085 - mean_squared_logarithmic_error: 0.0085 - val_loss: 0.0158 - val_mean_squared_logarithmic_error: 0.0158\n",
            "Epoch 292/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0086 - mean_squared_logarithmic_error: 0.0086 - val_loss: 0.0150 - val_mean_squared_logarithmic_error: 0.0150\n",
            "Epoch 293/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0088 - mean_squared_logarithmic_error: 0.0088 - val_loss: 0.0160 - val_mean_squared_logarithmic_error: 0.0160\n",
            "Epoch 294/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0086 - mean_squared_logarithmic_error: 0.0086 - val_loss: 0.0148 - val_mean_squared_logarithmic_error: 0.0148\n",
            "Epoch 295/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0094 - mean_squared_logarithmic_error: 0.0094 - val_loss: 0.0179 - val_mean_squared_logarithmic_error: 0.0179\n",
            "Epoch 296/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0087 - mean_squared_logarithmic_error: 0.0087 - val_loss: 0.0145 - val_mean_squared_logarithmic_error: 0.0145\n",
            "Epoch 297/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0086 - mean_squared_logarithmic_error: 0.0086 - val_loss: 0.0150 - val_mean_squared_logarithmic_error: 0.0150\n",
            "Epoch 298/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0088 - mean_squared_logarithmic_error: 0.0088 - val_loss: 0.0168 - val_mean_squared_logarithmic_error: 0.0168\n",
            "Epoch 299/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0088 - mean_squared_logarithmic_error: 0.0088 - val_loss: 0.0146 - val_mean_squared_logarithmic_error: 0.0146\n",
            "Epoch 300/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0083 - mean_squared_logarithmic_error: 0.0083 - val_loss: 0.0160 - val_mean_squared_logarithmic_error: 0.0160\n",
            "Epoch 301/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0082 - mean_squared_logarithmic_error: 0.0082 - val_loss: 0.0148 - val_mean_squared_logarithmic_error: 0.0148\n",
            "Epoch 302/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0082 - mean_squared_logarithmic_error: 0.0082 - val_loss: 0.0168 - val_mean_squared_logarithmic_error: 0.0168\n",
            "Epoch 303/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0082 - mean_squared_logarithmic_error: 0.0082 - val_loss: 0.0147 - val_mean_squared_logarithmic_error: 0.0147\n",
            "Epoch 304/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0080 - mean_squared_logarithmic_error: 0.0080 - val_loss: 0.0155 - val_mean_squared_logarithmic_error: 0.0155\n",
            "Epoch 305/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0079 - mean_squared_logarithmic_error: 0.0079 - val_loss: 0.0146 - val_mean_squared_logarithmic_error: 0.0146\n",
            "Epoch 306/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0086 - mean_squared_logarithmic_error: 0.0086 - val_loss: 0.0152 - val_mean_squared_logarithmic_error: 0.0152\n",
            "Epoch 307/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0080 - mean_squared_logarithmic_error: 0.0080 - val_loss: 0.0154 - val_mean_squared_logarithmic_error: 0.0154\n",
            "Epoch 308/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0081 - mean_squared_logarithmic_error: 0.0081 - val_loss: 0.0148 - val_mean_squared_logarithmic_error: 0.0148\n",
            "Epoch 309/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0084 - mean_squared_logarithmic_error: 0.0084 - val_loss: 0.0166 - val_mean_squared_logarithmic_error: 0.0166\n",
            "Epoch 310/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0082 - mean_squared_logarithmic_error: 0.0082 - val_loss: 0.0147 - val_mean_squared_logarithmic_error: 0.0147\n",
            "Epoch 311/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0080 - mean_squared_logarithmic_error: 0.0080 - val_loss: 0.0148 - val_mean_squared_logarithmic_error: 0.0148\n",
            "Epoch 312/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0078 - mean_squared_logarithmic_error: 0.0078 - val_loss: 0.0167 - val_mean_squared_logarithmic_error: 0.0167\n",
            "Epoch 313/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0085 - mean_squared_logarithmic_error: 0.0085 - val_loss: 0.0149 - val_mean_squared_logarithmic_error: 0.0149\n",
            "Epoch 314/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0080 - mean_squared_logarithmic_error: 0.0080 - val_loss: 0.0168 - val_mean_squared_logarithmic_error: 0.0168\n",
            "Epoch 315/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0080 - mean_squared_logarithmic_error: 0.0080 - val_loss: 0.0150 - val_mean_squared_logarithmic_error: 0.0150\n",
            "Epoch 316/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0076 - mean_squared_logarithmic_error: 0.0076 - val_loss: 0.0146 - val_mean_squared_logarithmic_error: 0.0146\n",
            "Epoch 317/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0075 - mean_squared_logarithmic_error: 0.0075 - val_loss: 0.0150 - val_mean_squared_logarithmic_error: 0.0150\n",
            "Epoch 318/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0076 - mean_squared_logarithmic_error: 0.0076 - val_loss: 0.0152 - val_mean_squared_logarithmic_error: 0.0152\n",
            "Epoch 319/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0074 - mean_squared_logarithmic_error: 0.0074 - val_loss: 0.0147 - val_mean_squared_logarithmic_error: 0.0147\n",
            "Epoch 320/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0075 - mean_squared_logarithmic_error: 0.0075 - val_loss: 0.0150 - val_mean_squared_logarithmic_error: 0.0150\n",
            "Epoch 321/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0075 - mean_squared_logarithmic_error: 0.0075 - val_loss: 0.0155 - val_mean_squared_logarithmic_error: 0.0155\n",
            "Epoch 322/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0075 - mean_squared_logarithmic_error: 0.0075 - val_loss: 0.0147 - val_mean_squared_logarithmic_error: 0.0147\n",
            "Epoch 323/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0076 - mean_squared_logarithmic_error: 0.0076 - val_loss: 0.0155 - val_mean_squared_logarithmic_error: 0.0155\n",
            "Epoch 324/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0074 - mean_squared_logarithmic_error: 0.0074 - val_loss: 0.0150 - val_mean_squared_logarithmic_error: 0.0150\n",
            "Epoch 325/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0075 - mean_squared_logarithmic_error: 0.0075 - val_loss: 0.0141 - val_mean_squared_logarithmic_error: 0.0141\n",
            "Epoch 326/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0074 - mean_squared_logarithmic_error: 0.0074 - val_loss: 0.0167 - val_mean_squared_logarithmic_error: 0.0167\n",
            "Epoch 327/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0073 - mean_squared_logarithmic_error: 0.0073 - val_loss: 0.0149 - val_mean_squared_logarithmic_error: 0.0149\n",
            "Epoch 328/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0074 - mean_squared_logarithmic_error: 0.0074 - val_loss: 0.0166 - val_mean_squared_logarithmic_error: 0.0166\n",
            "Epoch 329/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0074 - mean_squared_logarithmic_error: 0.0074 - val_loss: 0.0150 - val_mean_squared_logarithmic_error: 0.0150\n",
            "Epoch 330/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0073 - mean_squared_logarithmic_error: 0.0073 - val_loss: 0.0151 - val_mean_squared_logarithmic_error: 0.0151\n",
            "Epoch 331/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0076 - mean_squared_logarithmic_error: 0.0076 - val_loss: 0.0161 - val_mean_squared_logarithmic_error: 0.0161\n",
            "Epoch 332/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0069 - mean_squared_logarithmic_error: 0.0069 - val_loss: 0.0153 - val_mean_squared_logarithmic_error: 0.0153\n",
            "Epoch 333/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0069 - mean_squared_logarithmic_error: 0.0069 - val_loss: 0.0173 - val_mean_squared_logarithmic_error: 0.0173\n",
            "Epoch 334/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0078 - mean_squared_logarithmic_error: 0.0078 - val_loss: 0.0161 - val_mean_squared_logarithmic_error: 0.0161\n",
            "Epoch 335/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0094 - mean_squared_logarithmic_error: 0.0094 - val_loss: 0.0149 - val_mean_squared_logarithmic_error: 0.0149\n",
            "Epoch 336/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0076 - mean_squared_logarithmic_error: 0.0076 - val_loss: 0.0153 - val_mean_squared_logarithmic_error: 0.0153\n",
            "Epoch 337/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0070 - mean_squared_logarithmic_error: 0.0070 - val_loss: 0.0153 - val_mean_squared_logarithmic_error: 0.0153\n",
            "Epoch 338/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0069 - mean_squared_logarithmic_error: 0.0069 - val_loss: 0.0152 - val_mean_squared_logarithmic_error: 0.0152\n",
            "Epoch 339/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0069 - mean_squared_logarithmic_error: 0.0069 - val_loss: 0.0159 - val_mean_squared_logarithmic_error: 0.0159\n",
            "Epoch 340/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0069 - mean_squared_logarithmic_error: 0.0069 - val_loss: 0.0152 - val_mean_squared_logarithmic_error: 0.0152\n",
            "Epoch 341/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0071 - mean_squared_logarithmic_error: 0.0071 - val_loss: 0.0157 - val_mean_squared_logarithmic_error: 0.0157\n",
            "Epoch 342/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0070 - mean_squared_logarithmic_error: 0.0070 - val_loss: 0.0156 - val_mean_squared_logarithmic_error: 0.0156\n",
            "Epoch 343/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0067 - mean_squared_logarithmic_error: 0.0067 - val_loss: 0.0156 - val_mean_squared_logarithmic_error: 0.0156\n",
            "Epoch 344/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0066 - mean_squared_logarithmic_error: 0.0066 - val_loss: 0.0153 - val_mean_squared_logarithmic_error: 0.0153\n",
            "Epoch 345/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0066 - mean_squared_logarithmic_error: 0.0066 - val_loss: 0.0157 - val_mean_squared_logarithmic_error: 0.0157\n",
            "Epoch 346/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0065 - mean_squared_logarithmic_error: 0.0065 - val_loss: 0.0148 - val_mean_squared_logarithmic_error: 0.0148\n",
            "Epoch 347/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0065 - mean_squared_logarithmic_error: 0.0065 - val_loss: 0.0148 - val_mean_squared_logarithmic_error: 0.0148\n",
            "Epoch 348/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0068 - mean_squared_logarithmic_error: 0.0068 - val_loss: 0.0161 - val_mean_squared_logarithmic_error: 0.0161\n",
            "Epoch 349/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0065 - mean_squared_logarithmic_error: 0.0065 - val_loss: 0.0150 - val_mean_squared_logarithmic_error: 0.0150\n",
            "Epoch 350/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0068 - mean_squared_logarithmic_error: 0.0068 - val_loss: 0.0159 - val_mean_squared_logarithmic_error: 0.0159\n",
            "Epoch 351/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0065 - mean_squared_logarithmic_error: 0.0065 - val_loss: 0.0151 - val_mean_squared_logarithmic_error: 0.0151\n",
            "Epoch 352/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0065 - mean_squared_logarithmic_error: 0.0065 - val_loss: 0.0151 - val_mean_squared_logarithmic_error: 0.0151\n",
            "Epoch 353/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0064 - mean_squared_logarithmic_error: 0.0064 - val_loss: 0.0150 - val_mean_squared_logarithmic_error: 0.0150\n",
            "Epoch 354/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0065 - mean_squared_logarithmic_error: 0.0065 - val_loss: 0.0157 - val_mean_squared_logarithmic_error: 0.0157\n",
            "Epoch 355/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0065 - mean_squared_logarithmic_error: 0.0065 - val_loss: 0.0154 - val_mean_squared_logarithmic_error: 0.0154\n",
            "Epoch 356/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0062 - mean_squared_logarithmic_error: 0.0062 - val_loss: 0.0156 - val_mean_squared_logarithmic_error: 0.0156\n",
            "Epoch 357/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0065 - mean_squared_logarithmic_error: 0.0065 - val_loss: 0.0159 - val_mean_squared_logarithmic_error: 0.0159\n",
            "Epoch 358/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0061 - mean_squared_logarithmic_error: 0.0061 - val_loss: 0.0154 - val_mean_squared_logarithmic_error: 0.0154\n",
            "Epoch 359/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0060 - mean_squared_logarithmic_error: 0.0060 - val_loss: 0.0153 - val_mean_squared_logarithmic_error: 0.0153\n",
            "Epoch 360/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0062 - mean_squared_logarithmic_error: 0.0062 - val_loss: 0.0160 - val_mean_squared_logarithmic_error: 0.0160\n",
            "Epoch 361/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0059 - mean_squared_logarithmic_error: 0.0059 - val_loss: 0.0155 - val_mean_squared_logarithmic_error: 0.0155\n",
            "Epoch 362/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0063 - mean_squared_logarithmic_error: 0.0063 - val_loss: 0.0157 - val_mean_squared_logarithmic_error: 0.0157\n",
            "Epoch 363/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0061 - mean_squared_logarithmic_error: 0.0061 - val_loss: 0.0152 - val_mean_squared_logarithmic_error: 0.0152\n",
            "Epoch 364/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0060 - mean_squared_logarithmic_error: 0.0060 - val_loss: 0.0159 - val_mean_squared_logarithmic_error: 0.0159\n",
            "Epoch 365/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0060 - mean_squared_logarithmic_error: 0.0060 - val_loss: 0.0158 - val_mean_squared_logarithmic_error: 0.0158\n",
            "Epoch 366/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0059 - mean_squared_logarithmic_error: 0.0059 - val_loss: 0.0149 - val_mean_squared_logarithmic_error: 0.0149\n",
            "Epoch 367/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0058 - mean_squared_logarithmic_error: 0.0058 - val_loss: 0.0150 - val_mean_squared_logarithmic_error: 0.0150\n",
            "Epoch 368/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0058 - mean_squared_logarithmic_error: 0.0058 - val_loss: 0.0152 - val_mean_squared_logarithmic_error: 0.0152\n",
            "Epoch 369/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0058 - mean_squared_logarithmic_error: 0.0058 - val_loss: 0.0155 - val_mean_squared_logarithmic_error: 0.0155\n",
            "Epoch 370/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0062 - mean_squared_logarithmic_error: 0.0062 - val_loss: 0.0151 - val_mean_squared_logarithmic_error: 0.0151\n",
            "Epoch 371/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0057 - mean_squared_logarithmic_error: 0.0057 - val_loss: 0.0162 - val_mean_squared_logarithmic_error: 0.0162\n",
            "Epoch 372/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0059 - mean_squared_logarithmic_error: 0.0059 - val_loss: 0.0157 - val_mean_squared_logarithmic_error: 0.0157\n",
            "Epoch 373/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0057 - mean_squared_logarithmic_error: 0.0057 - val_loss: 0.0160 - val_mean_squared_logarithmic_error: 0.0160\n",
            "Epoch 374/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0064 - mean_squared_logarithmic_error: 0.0064 - val_loss: 0.0161 - val_mean_squared_logarithmic_error: 0.0161\n",
            "Epoch 375/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0062 - mean_squared_logarithmic_error: 0.0062 - val_loss: 0.0168 - val_mean_squared_logarithmic_error: 0.0168\n",
            "Epoch 376/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0059 - mean_squared_logarithmic_error: 0.0059 - val_loss: 0.0154 - val_mean_squared_logarithmic_error: 0.0154\n",
            "Epoch 377/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0056 - mean_squared_logarithmic_error: 0.0056 - val_loss: 0.0152 - val_mean_squared_logarithmic_error: 0.0152\n",
            "Epoch 378/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0056 - mean_squared_logarithmic_error: 0.0056 - val_loss: 0.0149 - val_mean_squared_logarithmic_error: 0.0149\n",
            "Epoch 379/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0059 - mean_squared_logarithmic_error: 0.0059 - val_loss: 0.0166 - val_mean_squared_logarithmic_error: 0.0166\n",
            "Epoch 380/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0054 - mean_squared_logarithmic_error: 0.0054 - val_loss: 0.0146 - val_mean_squared_logarithmic_error: 0.0146\n",
            "Epoch 381/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0054 - mean_squared_logarithmic_error: 0.0054 - val_loss: 0.0156 - val_mean_squared_logarithmic_error: 0.0156\n",
            "Epoch 382/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0053 - mean_squared_logarithmic_error: 0.0053 - val_loss: 0.0156 - val_mean_squared_logarithmic_error: 0.0156\n",
            "Epoch 383/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0055 - mean_squared_logarithmic_error: 0.0055 - val_loss: 0.0153 - val_mean_squared_logarithmic_error: 0.0153\n",
            "Epoch 384/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0055 - mean_squared_logarithmic_error: 0.0055 - val_loss: 0.0153 - val_mean_squared_logarithmic_error: 0.0153\n",
            "Epoch 385/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0054 - mean_squared_logarithmic_error: 0.0054 - val_loss: 0.0159 - val_mean_squared_logarithmic_error: 0.0159\n",
            "Epoch 386/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0053 - mean_squared_logarithmic_error: 0.0053 - val_loss: 0.0153 - val_mean_squared_logarithmic_error: 0.0153\n",
            "Epoch 387/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0054 - mean_squared_logarithmic_error: 0.0054 - val_loss: 0.0154 - val_mean_squared_logarithmic_error: 0.0154\n",
            "Epoch 388/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0057 - mean_squared_logarithmic_error: 0.0057 - val_loss: 0.0160 - val_mean_squared_logarithmic_error: 0.0160\n",
            "Epoch 389/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0055 - mean_squared_logarithmic_error: 0.0055 - val_loss: 0.0156 - val_mean_squared_logarithmic_error: 0.0156\n",
            "Epoch 390/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0053 - mean_squared_logarithmic_error: 0.0053 - val_loss: 0.0157 - val_mean_squared_logarithmic_error: 0.0157\n",
            "Epoch 391/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0054 - mean_squared_logarithmic_error: 0.0054 - val_loss: 0.0154 - val_mean_squared_logarithmic_error: 0.0154\n",
            "Epoch 392/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0051 - mean_squared_logarithmic_error: 0.0051 - val_loss: 0.0156 - val_mean_squared_logarithmic_error: 0.0156\n",
            "Epoch 393/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0050 - mean_squared_logarithmic_error: 0.0050 - val_loss: 0.0162 - val_mean_squared_logarithmic_error: 0.0162\n",
            "Epoch 394/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0058 - mean_squared_logarithmic_error: 0.0058 - val_loss: 0.0153 - val_mean_squared_logarithmic_error: 0.0153\n",
            "Epoch 395/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0054 - mean_squared_logarithmic_error: 0.0054 - val_loss: 0.0151 - val_mean_squared_logarithmic_error: 0.0151\n",
            "Epoch 396/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0052 - mean_squared_logarithmic_error: 0.0052 - val_loss: 0.0153 - val_mean_squared_logarithmic_error: 0.0153\n",
            "Epoch 397/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0052 - mean_squared_logarithmic_error: 0.0052 - val_loss: 0.0158 - val_mean_squared_logarithmic_error: 0.0158\n",
            "Epoch 398/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0051 - mean_squared_logarithmic_error: 0.0051 - val_loss: 0.0165 - val_mean_squared_logarithmic_error: 0.0165\n",
            "Epoch 399/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0050 - mean_squared_logarithmic_error: 0.0050 - val_loss: 0.0154 - val_mean_squared_logarithmic_error: 0.0154\n",
            "Epoch 400/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0050 - mean_squared_logarithmic_error: 0.0050 - val_loss: 0.0154 - val_mean_squared_logarithmic_error: 0.0154\n",
            "Epoch 401/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0049 - mean_squared_logarithmic_error: 0.0049 - val_loss: 0.0155 - val_mean_squared_logarithmic_error: 0.0155\n",
            "Epoch 402/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0048 - mean_squared_logarithmic_error: 0.0048 - val_loss: 0.0158 - val_mean_squared_logarithmic_error: 0.0158\n",
            "Epoch 403/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0050 - mean_squared_logarithmic_error: 0.0050 - val_loss: 0.0177 - val_mean_squared_logarithmic_error: 0.0177\n",
            "Epoch 404/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0057 - mean_squared_logarithmic_error: 0.0057 - val_loss: 0.0143 - val_mean_squared_logarithmic_error: 0.0143\n",
            "Epoch 405/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0055 - mean_squared_logarithmic_error: 0.0055 - val_loss: 0.0159 - val_mean_squared_logarithmic_error: 0.0159\n",
            "Epoch 406/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0057 - mean_squared_logarithmic_error: 0.0057 - val_loss: 0.0154 - val_mean_squared_logarithmic_error: 0.0154\n",
            "Epoch 407/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0051 - mean_squared_logarithmic_error: 0.0051 - val_loss: 0.0147 - val_mean_squared_logarithmic_error: 0.0147\n",
            "Epoch 408/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0052 - mean_squared_logarithmic_error: 0.0052 - val_loss: 0.0158 - val_mean_squared_logarithmic_error: 0.0158\n",
            "Epoch 409/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0050 - mean_squared_logarithmic_error: 0.0050 - val_loss: 0.0144 - val_mean_squared_logarithmic_error: 0.0144\n",
            "Epoch 410/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0052 - mean_squared_logarithmic_error: 0.0052 - val_loss: 0.0159 - val_mean_squared_logarithmic_error: 0.0159\n",
            "Epoch 411/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0050 - mean_squared_logarithmic_error: 0.0050 - val_loss: 0.0155 - val_mean_squared_logarithmic_error: 0.0155\n",
            "Epoch 412/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0047 - mean_squared_logarithmic_error: 0.0047 - val_loss: 0.0149 - val_mean_squared_logarithmic_error: 0.0149\n",
            "Epoch 413/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0045 - mean_squared_logarithmic_error: 0.0045 - val_loss: 0.0157 - val_mean_squared_logarithmic_error: 0.0157\n",
            "Epoch 414/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0049 - mean_squared_logarithmic_error: 0.0049 - val_loss: 0.0144 - val_mean_squared_logarithmic_error: 0.0144\n",
            "Epoch 415/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0047 - mean_squared_logarithmic_error: 0.0047 - val_loss: 0.0140 - val_mean_squared_logarithmic_error: 0.0140\n",
            "Epoch 416/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0046 - mean_squared_logarithmic_error: 0.0046 - val_loss: 0.0143 - val_mean_squared_logarithmic_error: 0.0143\n",
            "Epoch 417/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0046 - mean_squared_logarithmic_error: 0.0046 - val_loss: 0.0144 - val_mean_squared_logarithmic_error: 0.0144\n",
            "Epoch 418/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0046 - mean_squared_logarithmic_error: 0.0046 - val_loss: 0.0158 - val_mean_squared_logarithmic_error: 0.0158\n",
            "Epoch 419/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0045 - mean_squared_logarithmic_error: 0.0045 - val_loss: 0.0152 - val_mean_squared_logarithmic_error: 0.0152\n",
            "Epoch 420/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0049 - mean_squared_logarithmic_error: 0.0049 - val_loss: 0.0152 - val_mean_squared_logarithmic_error: 0.0152\n",
            "Epoch 421/500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: 0.0042 - mean_squared_logarithmic_error: 0.0042 - val_loss: 0.0154 - val_mean_squared_logarithmic_error: 0.0154\n",
            "Epoch 422/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0045 - mean_squared_logarithmic_error: 0.0045 - val_loss: 0.0157 - val_mean_squared_logarithmic_error: 0.0157\n",
            "Epoch 423/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0044 - mean_squared_logarithmic_error: 0.0044 - val_loss: 0.0150 - val_mean_squared_logarithmic_error: 0.0150\n",
            "Epoch 424/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0045 - mean_squared_logarithmic_error: 0.0045 - val_loss: 0.0149 - val_mean_squared_logarithmic_error: 0.0149\n",
            "Epoch 425/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0049 - mean_squared_logarithmic_error: 0.0049 - val_loss: 0.0147 - val_mean_squared_logarithmic_error: 0.0147\n",
            "Epoch 426/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0047 - mean_squared_logarithmic_error: 0.0047 - val_loss: 0.0151 - val_mean_squared_logarithmic_error: 0.0151\n",
            "Epoch 427/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0044 - mean_squared_logarithmic_error: 0.0044 - val_loss: 0.0147 - val_mean_squared_logarithmic_error: 0.0147\n",
            "Epoch 428/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: 0.0042 - mean_squared_logarithmic_error: 0.0042 - val_loss: 0.0145 - val_mean_squared_logarithmic_error: 0.0145\n",
            "Epoch 429/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0042 - mean_squared_logarithmic_error: 0.0042 - val_loss: 0.0147 - val_mean_squared_logarithmic_error: 0.0147\n",
            "Epoch 430/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0043 - mean_squared_logarithmic_error: 0.0043 - val_loss: 0.0141 - val_mean_squared_logarithmic_error: 0.0141\n",
            "Epoch 431/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0042 - mean_squared_logarithmic_error: 0.0042 - val_loss: 0.0145 - val_mean_squared_logarithmic_error: 0.0145\n",
            "Epoch 432/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0040 - mean_squared_logarithmic_error: 0.0040 - val_loss: 0.0146 - val_mean_squared_logarithmic_error: 0.0146\n",
            "Epoch 433/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0040 - mean_squared_logarithmic_error: 0.0040 - val_loss: 0.0162 - val_mean_squared_logarithmic_error: 0.0162\n",
            "Epoch 434/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0043 - mean_squared_logarithmic_error: 0.0043 - val_loss: 0.0149 - val_mean_squared_logarithmic_error: 0.0149\n",
            "Epoch 435/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0041 - mean_squared_logarithmic_error: 0.0041 - val_loss: 0.0149 - val_mean_squared_logarithmic_error: 0.0149\n",
            "Epoch 436/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0042 - mean_squared_logarithmic_error: 0.0042 - val_loss: 0.0145 - val_mean_squared_logarithmic_error: 0.0145\n",
            "Epoch 437/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0039 - mean_squared_logarithmic_error: 0.0039 - val_loss: 0.0150 - val_mean_squared_logarithmic_error: 0.0150\n",
            "Epoch 438/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0042 - mean_squared_logarithmic_error: 0.0042 - val_loss: 0.0142 - val_mean_squared_logarithmic_error: 0.0142\n",
            "Epoch 439/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0043 - mean_squared_logarithmic_error: 0.0043 - val_loss: 0.0146 - val_mean_squared_logarithmic_error: 0.0146\n",
            "Epoch 440/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0041 - mean_squared_logarithmic_error: 0.0041 - val_loss: 0.0149 - val_mean_squared_logarithmic_error: 0.0149\n",
            "Epoch 441/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0039 - mean_squared_logarithmic_error: 0.0039 - val_loss: 0.0151 - val_mean_squared_logarithmic_error: 0.0151\n",
            "Epoch 442/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0038 - mean_squared_logarithmic_error: 0.0038 - val_loss: 0.0147 - val_mean_squared_logarithmic_error: 0.0147\n",
            "Epoch 443/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0038 - mean_squared_logarithmic_error: 0.0038 - val_loss: 0.0146 - val_mean_squared_logarithmic_error: 0.0146\n",
            "Epoch 444/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0038 - mean_squared_logarithmic_error: 0.0038 - val_loss: 0.0148 - val_mean_squared_logarithmic_error: 0.0148\n",
            "Epoch 445/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0040 - mean_squared_logarithmic_error: 0.0040 - val_loss: 0.0147 - val_mean_squared_logarithmic_error: 0.0147\n",
            "Epoch 446/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0038 - mean_squared_logarithmic_error: 0.0038 - val_loss: 0.0155 - val_mean_squared_logarithmic_error: 0.0155\n",
            "Epoch 447/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0041 - mean_squared_logarithmic_error: 0.0041 - val_loss: 0.0143 - val_mean_squared_logarithmic_error: 0.0143\n",
            "Epoch 448/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0038 - mean_squared_logarithmic_error: 0.0038 - val_loss: 0.0151 - val_mean_squared_logarithmic_error: 0.0151\n",
            "Epoch 449/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0039 - mean_squared_logarithmic_error: 0.0039 - val_loss: 0.0147 - val_mean_squared_logarithmic_error: 0.0147\n",
            "Epoch 450/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0039 - mean_squared_logarithmic_error: 0.0039 - val_loss: 0.0144 - val_mean_squared_logarithmic_error: 0.0144\n",
            "Epoch 451/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0037 - mean_squared_logarithmic_error: 0.0037 - val_loss: 0.0150 - val_mean_squared_logarithmic_error: 0.0150\n",
            "Epoch 452/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0039 - mean_squared_logarithmic_error: 0.0039 - val_loss: 0.0142 - val_mean_squared_logarithmic_error: 0.0142\n",
            "Epoch 453/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0043 - mean_squared_logarithmic_error: 0.0043 - val_loss: 0.0150 - val_mean_squared_logarithmic_error: 0.0150\n",
            "Epoch 454/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0039 - mean_squared_logarithmic_error: 0.0039 - val_loss: 0.0140 - val_mean_squared_logarithmic_error: 0.0140\n",
            "Epoch 455/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0036 - mean_squared_logarithmic_error: 0.0036 - val_loss: 0.0135 - val_mean_squared_logarithmic_error: 0.0135\n",
            "Epoch 456/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0042 - mean_squared_logarithmic_error: 0.0042 - val_loss: 0.0143 - val_mean_squared_logarithmic_error: 0.0143\n",
            "Epoch 457/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0044 - mean_squared_logarithmic_error: 0.0044 - val_loss: 0.0160 - val_mean_squared_logarithmic_error: 0.0160\n",
            "Epoch 458/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0040 - mean_squared_logarithmic_error: 0.0040 - val_loss: 0.0141 - val_mean_squared_logarithmic_error: 0.0141\n",
            "Epoch 459/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0036 - mean_squared_logarithmic_error: 0.0036 - val_loss: 0.0138 - val_mean_squared_logarithmic_error: 0.0138\n",
            "Epoch 460/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0037 - mean_squared_logarithmic_error: 0.0037 - val_loss: 0.0147 - val_mean_squared_logarithmic_error: 0.0147\n",
            "Epoch 461/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0040 - mean_squared_logarithmic_error: 0.0040 - val_loss: 0.0143 - val_mean_squared_logarithmic_error: 0.0143\n",
            "Epoch 462/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0036 - mean_squared_logarithmic_error: 0.0036 - val_loss: 0.0144 - val_mean_squared_logarithmic_error: 0.0144\n",
            "Epoch 463/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0037 - mean_squared_logarithmic_error: 0.0037 - val_loss: 0.0144 - val_mean_squared_logarithmic_error: 0.0144\n",
            "Epoch 464/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0040 - mean_squared_logarithmic_error: 0.0040 - val_loss: 0.0139 - val_mean_squared_logarithmic_error: 0.0139\n",
            "Epoch 465/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0039 - mean_squared_logarithmic_error: 0.0039 - val_loss: 0.0140 - val_mean_squared_logarithmic_error: 0.0140\n",
            "Epoch 466/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0035 - mean_squared_logarithmic_error: 0.0035 - val_loss: 0.0145 - val_mean_squared_logarithmic_error: 0.0145\n",
            "Epoch 467/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0037 - mean_squared_logarithmic_error: 0.0037 - val_loss: 0.0147 - val_mean_squared_logarithmic_error: 0.0147\n",
            "Epoch 468/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0038 - mean_squared_logarithmic_error: 0.0038 - val_loss: 0.0148 - val_mean_squared_logarithmic_error: 0.0148\n",
            "Epoch 469/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0036 - mean_squared_logarithmic_error: 0.0036 - val_loss: 0.0152 - val_mean_squared_logarithmic_error: 0.0152\n",
            "Epoch 470/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0033 - mean_squared_logarithmic_error: 0.0033 - val_loss: 0.0150 - val_mean_squared_logarithmic_error: 0.0150\n",
            "Epoch 471/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0034 - mean_squared_logarithmic_error: 0.0034 - val_loss: 0.0151 - val_mean_squared_logarithmic_error: 0.0151\n",
            "Epoch 472/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0035 - mean_squared_logarithmic_error: 0.0035 - val_loss: 0.0154 - val_mean_squared_logarithmic_error: 0.0154\n",
            "Epoch 473/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0034 - mean_squared_logarithmic_error: 0.0034 - val_loss: 0.0143 - val_mean_squared_logarithmic_error: 0.0143\n",
            "Epoch 474/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0033 - mean_squared_logarithmic_error: 0.0033 - val_loss: 0.0157 - val_mean_squared_logarithmic_error: 0.0157\n",
            "Epoch 475/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0034 - mean_squared_logarithmic_error: 0.0034 - val_loss: 0.0152 - val_mean_squared_logarithmic_error: 0.0152\n",
            "Epoch 476/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0034 - mean_squared_logarithmic_error: 0.0034 - val_loss: 0.0147 - val_mean_squared_logarithmic_error: 0.0147\n",
            "Epoch 477/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0032 - mean_squared_logarithmic_error: 0.0032 - val_loss: 0.0145 - val_mean_squared_logarithmic_error: 0.0145\n",
            "Epoch 478/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0034 - mean_squared_logarithmic_error: 0.0034 - val_loss: 0.0146 - val_mean_squared_logarithmic_error: 0.0146\n",
            "Epoch 479/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0036 - mean_squared_logarithmic_error: 0.0036 - val_loss: 0.0142 - val_mean_squared_logarithmic_error: 0.0142\n",
            "Epoch 480/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0033 - mean_squared_logarithmic_error: 0.0033 - val_loss: 0.0146 - val_mean_squared_logarithmic_error: 0.0146\n",
            "Epoch 481/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0033 - mean_squared_logarithmic_error: 0.0033 - val_loss: 0.0156 - val_mean_squared_logarithmic_error: 0.0156\n",
            "Epoch 482/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0033 - mean_squared_logarithmic_error: 0.0033 - val_loss: 0.0146 - val_mean_squared_logarithmic_error: 0.0146\n",
            "Epoch 483/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0034 - mean_squared_logarithmic_error: 0.0034 - val_loss: 0.0155 - val_mean_squared_logarithmic_error: 0.0155\n",
            "Epoch 484/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0036 - mean_squared_logarithmic_error: 0.0036 - val_loss: 0.0155 - val_mean_squared_logarithmic_error: 0.0155\n",
            "Epoch 485/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0037 - mean_squared_logarithmic_error: 0.0037 - val_loss: 0.0139 - val_mean_squared_logarithmic_error: 0.0139\n",
            "Epoch 486/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0032 - mean_squared_logarithmic_error: 0.0032 - val_loss: 0.0147 - val_mean_squared_logarithmic_error: 0.0147\n",
            "Epoch 487/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0031 - mean_squared_logarithmic_error: 0.0031 - val_loss: 0.0150 - val_mean_squared_logarithmic_error: 0.0150\n",
            "Epoch 488/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0030 - mean_squared_logarithmic_error: 0.0030 - val_loss: 0.0140 - val_mean_squared_logarithmic_error: 0.0140\n",
            "Epoch 489/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0029 - mean_squared_logarithmic_error: 0.0029 - val_loss: 0.0144 - val_mean_squared_logarithmic_error: 0.0144\n",
            "Epoch 490/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0031 - mean_squared_logarithmic_error: 0.0031 - val_loss: 0.0143 - val_mean_squared_logarithmic_error: 0.0143\n",
            "Epoch 491/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0032 - mean_squared_logarithmic_error: 0.0032 - val_loss: 0.0150 - val_mean_squared_logarithmic_error: 0.0150\n",
            "Epoch 492/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0035 - mean_squared_logarithmic_error: 0.0035 - val_loss: 0.0153 - val_mean_squared_logarithmic_error: 0.0153\n",
            "Epoch 493/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0039 - mean_squared_logarithmic_error: 0.0039 - val_loss: 0.0141 - val_mean_squared_logarithmic_error: 0.0141\n",
            "Epoch 494/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0031 - mean_squared_logarithmic_error: 0.0031 - val_loss: 0.0148 - val_mean_squared_logarithmic_error: 0.0148\n",
            "Epoch 495/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0030 - mean_squared_logarithmic_error: 0.0030 - val_loss: 0.0140 - val_mean_squared_logarithmic_error: 0.0140\n",
            "Epoch 496/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0029 - mean_squared_logarithmic_error: 0.0029 - val_loss: 0.0141 - val_mean_squared_logarithmic_error: 0.0141\n",
            "Epoch 497/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0030 - mean_squared_logarithmic_error: 0.0030 - val_loss: 0.0148 - val_mean_squared_logarithmic_error: 0.0148\n",
            "Epoch 498/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0030 - mean_squared_logarithmic_error: 0.0030 - val_loss: 0.0154 - val_mean_squared_logarithmic_error: 0.0154\n",
            "Epoch 499/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0032 - mean_squared_logarithmic_error: 0.0032 - val_loss: 0.0146 - val_mean_squared_logarithmic_error: 0.0146\n",
            "Epoch 500/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0029 - mean_squared_logarithmic_error: 0.0029 - val_loss: 0.0145 - val_mean_squared_logarithmic_error: 0.0145\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f41371eaeb0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc_jN5XwcBu9"
      },
      "source": [
        "## Question 3\n",
        "\n",
        "Now that you know how MSLE works, you need to plot the behavior of MSLE for the synthetic errors given.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_USeo3P7cBu-"
      },
      "source": [
        "### Answer 3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "bvQXqsI--7mi"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHr_XxgUcBu-",
        "outputId": "e88bc3a8-7698-42ce-f343-e78f442d50a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "actual_outputs = np.arange(0, 51)\n",
        "n = len(actual_outputs)\n",
        "estimated_outputs = np.zeros(n)\n",
        "\n",
        "msle = (np.log(actual_outputs + 1) - np.log(estimated_outputs + 1))**2\n",
        "          #This algo is 1:1 with the image above. It starts after the sigma notation.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(actual_outputs, msle, c='#F47789', marker='o')\n",
        "plt.grid()\n",
        "plt.xlabel('Actual ouputs')\n",
        "plt.ylabel('Mean Squared Logarithmic Errors')\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEHCAYAAACp9y31AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5zcdX3v8dd7N7sbwiaGEFguAQN4KwQEsygIxQQRYkFRsAqopVZPausFW63VWg9ij+fYllo9tac9qSLeDik3kXILEQkBlVtIgAiIt6AIglyWzSZkr5/zx++3YbI7M/vb2ZnZnfm9n49HHjvzm9/l+2WXz373870pIjAzs/xome4CmJlZfTnwm5nljAO/mVnOOPCbmeWMA7+ZWc448JuZ5cysWt1Y0kXAacCTEbGk4PiHgA8Aw8C1EfHxie61cOHCWLx4cUXl2LZtG7vvvntF1zYq1zkfXOd8mEqdN2zY8FRE7DX2eM0CP3Ax8GXgG6MHJC0HTgdeGRH9kvbOcqPFixdz9913V1SIdevWsWzZsoqubVSucz64zvkwlTpLeqTY8ZqleiJiPfDMmMN/Bnw+IvrTc56s1fPNzKw41XLmrqTFwDWjqR5Jm4DvAiuAHcDHIuKuEteuBFYCdHV1LV29enVFZejr66Ozs7OiaxuV65wPrnM+TKXOy5cv3xAR3WOP1zLVU8wsYAFwDHA0cKmkg6PIb5+IWAWsAuju7o5K/9Txn4b54Drng+tcHfUe1fMocGUk7gRGgIV1LoOZWa7VO/BfBSwHkPQyoB14qs5lMDPLtVoO57wEWAYslPQocD5wEXCRpM3AAHBusTSPmVneDW58gME16+nu6WX77Q/RdsoJtB11aFXuXbPAHxFnl/joXbV6pplZMxjc+AADV94Ag0MIiJ7e5D1UJfjXu3PXzMxSo6366OlF8+ftbNUPrlkPg0NjTh5icM16B34zs0ZV2KqHtFV/xfUM3rOZ6Oktek2p45PlwG9mVmPFWvZFW/VDw8RPt8CsWTA0NO4+mj+vKuXxIm1mZjU02rIfba1HTy8Dl19ftvXefuYKaBvTLm+bRdspJ1SlTG7xm5lVSeaW/fBwyXto/rydefzBNesZ6emlpSD/Xw0O/GZmVVAqZ89Q6SBP26xdfykUtOrbjjqUtqMOrcnMXQd+M7NJmkzOvpTC68aO6qk1B34zs0moZst+tFVfbw78ZmYlNHrLvhQHfjOzIpqhZV+Kh3OamRVRScu+/YwVO8faj76fSQF/lFv8ZpZ7Y1M6s5YdU36WbIO07Etxi9/Mcq3YBKvBq24seX4jtexLcYvfzHJjXMv+DcczeN268SkdgI52GBlp6JZ9KW7xm1kuFG3ZX3YdbNte/IL+gYZv2ZfiFr+ZNZ2iwzCvX1e8ZS9Bkf2gRpdOaIZAP5YDv5k1laLDMC+9tmhwT06IsksnNKNabr14EXAa8GRELBnz2UeBC4G9IsJ77ppZRTJPsCqzw+tMnGBVa5MK/JL2AA6IiPsynH4x8GXgG2PucQBwMvCryTzbzKxQ0Zb9ZdclHbKlNPgwzGqZsHNX0jpJ8yQtAO4B/kPSFya6LiLWA88U+eifgY8D3mTdzCpWtGVfJug3wzDMalGU+RMIQNLGiDhK0vtIWvvnS7ovIo6Y8ObSYuCa0VSPpNOBEyPiPElbgO5SqR5JK4GVAF1dXUtXr149iWq9oK+vj87OzoqubVSucz7kqc4LHnuKRQ8/SvuOAQZmt/NM1x7s88gTqMi5AYy0tNBa8EtguKWFLUsW88x+C+tW5mqZyvd5+fLlGyKie+zxLKmeWZL2Bd4OfKqipwOS5gB/Q5LmmVBErAJWAXR3d0el61HXYi3rmc51zoe81Hlw4wMM3HTPztZ9x44B9n3kiZLnt8yfR8eYnP1up5zAEQ3asp+u9fgvANYAt0XEXZIOBn5awbMOAQ4C7pUEsAi4R9KrI+K3FdzPzJrMuAlWJx7L4PW3FB+GuVtHsnaOc/aTVjbwS2olSe/sTOtExC+AMyf7oIi4H9i74N5bKJPqMbN8KdZZO3jlmtIXPN9P+ztOy9VonGopG/gjYljS2SQdspMi6RJgGbBQ0qPA+RHx1YpKaWZNo9gQzLajDvUEqzrKkur5gaQvA/8JbBs9GBH3lLsoIs6e4PPFWQpoZs2j6BDMy69n8NY7id6+4hflcIJVrWUJ/EemXz9bcCyAE6tfHDNrZkWHYA4PE4//LlkUrX9g3DWFE6xGenppcUpnyiYM/BGxvB4FMbPmUmwlzJJr3EfQ/paTd/lrABjXWZuXkUy1NmHgl/Qi4Hxg9O+qW4DPRsRztSyYmTWuoh21l11X8vzRfD3gzto6yJLquQjYTDKOH+DdwNeAM2pVKDNrHMXXyykxBLO9LcnZl8jXu7O2PrIE/kMionD45gWSNtWqQGbWOCa9Xs7AoIdgzgBZAv/zko6PiNsAJB0HPF/bYplZI6hkvRy36qdflsD/fuAbaa4f4Fng3NoVycxmovEbkr+mog3Jbfplmbn77oh4paR5ABFR5jttZs2oaGftVWtLnp/HNe4bSZaZu8enrx3wzXKgaGftDSU6a5t4Q/JmliXVs1HS1cBl7Dpz98qalcrMpsWkO2v7B9xZ24CyBP7ZwNPsOlM3AAd+sybjztp8yJLjfzoiPlan8phZnYzrrH39a91ZmxNlt16MiGHguDqVxczqZDSlMxroo6eXwStuKHm+ty1sLllSPZuc4zdrLkVTOgAdbTBSfGatUzrNwzl+sya3a0pnLi2vOKR0SqffM2vzIMvqnO+pR0HMrPrGj9LZyvDtm7y5Sc6VDPySLo2It6ev/z4i/rrgsxsjouym6ZIuAk4DnoyIJemxfwTeBAwAPwfeExE9U6+GmRUdf19qV6vZHTA05M7anCrXufvSgtdvGPPZXhnufTGwYsyxtcCSdA/fh4FPZriPmU2gWGftwKXXlt7V6vkd7qzNsXKpnvF/B2b7LDkhYr2kxWOO3Vjw9nbgbRPdx8wmVrSztkgqZ5RTOvlWLvDPkXQUyV8Fu6Wvlf7brQrP/hOSfXyLkrQSWAnQ1dXFunXrKnpIX19fxdc2Kte5uS147CkWPfwo3TsGeGbdJn7zkv05qKcXFTk3gJGWFloLJmENt7Sw5cCFPNOA/73y9H0eVYs6K0q0CiTdXO7CLFsypi3+a0Zz/AXHPwV0A2dEqQIU6O7ujrvvvnui04rK41ZtrnPzGttZO5FmWywtL9/nQlOps6QNEdE99njJFn+t9tqV9Mcknb6vzxL0zewFHn9v1ZBlHH/VSFoBfBx4XURsr+ezzRrNuCUVjj3K4++tKmoW+CVdAiwDFkp6lGTD9k8CHcBaSQC3R8T7a1UGs0ZVdP37628peb47a20yahb4I+LsIoe/WqvnmTWTkimd3TpgaNjj721KJgz8kt4KfD8inkvfzweWRcRVtS6cWR6MTem0HP6y0imd5/t3pnRGenppcUrHKpClxX9+RHxn9E1E9Eg6H3DgN5uiYimd4VvvTgZNFxn6UJjSyeMIF6uOsssylzmnrp3CZs2qZEpndkey/n0hp3SsSrIE8LslfQH41/T9B4ANtSuSWXMal9J52UGZUjoepWPVliXwfwj4NC/Msl1LEvzNLKOiKZ077/UqmTYtsizLvA34RB3KYta0Btfc4lUybcYotyzzFyPiI5L+iyLdTBHx5pqWzKwBjZt09YbjUQTRs7X4Bc/vcErH6q5ci/+b6dcL61EQs0ZXdNLVZdclH7a2wPDIuGuc0rHpUG6tng3p19LTBc1sp5IjdHbfjbZTT2TwO2uc0rEZIcsErtOAvwNenJ4vICJiXo3LZjZjjUvpnPz7pUfobHue9lcdhiSndGxGyDKq54vAGcD9Xk3TrFRK59qS54/ucuWUjs0UWSZw/RrY7KBvlii+2xXJhCtPurIGkKXF/3HgOkm3AP2jByPiCzUrldkMUWwD85IpncEhj9CxhpAl8H8O6ANmA+21LY7ZzFEspTNwafmUjtM51giyBP79xm6daJYHJTcwb22FFnmEjjWsLDn+6ySdXPOSmM0wJVM6w8O0n7FiZ6et5s+j/YwVbulbw8jS4v8z4GOS+oFBPJzTmtC4BdRefrDX0bGmNWGLPyLmRkRLROwWEfPS9xMGfUkXSXpS0uaCYwskrZX00/TrHlOtgNlUjebyR1v40dPL8B2bknV0ZrXuerJTOtYEsqR6kLS/pNdKOmH0X4bLLgZWjDn2CeCmiHgpcBNe/M1mgFIzbtXRTvuZb3RKx5pOlpm7fw+8A3gAGE4PB7C+3HURsV7S4jGHTyfZgB3g68A64K+zFtZsqsbNuF32mpK5/OjpdUrHmpImmpcl6SfAERHRX/bE4tcuBq4ZHRUkqSci5qevBTw7+r7ItSuBlQBdXV1LV69ePdnHA9DX10dnZ2dF1zYq17m4BY89xeLNW2gdeWGxtNGffhU5v392O/ctO7J6hawyf5/zYSp1Xr58+YaI6B57PEvn7i+ANgomb1VDRISkkr91ImIVsAqgu7s7Kt1bNI/7krrOxW3//L8TI7uukCmAjnYYGRk3PHPu6SezbAa39v19zoda1Lncevz/QtIg2g5sknQTu87c/XAFz3tC0r4R8bikfYEnK7iHWUVKDs/sH/CMW8uVci3+u9OvG4Crx3xW6bo9VwPnAp9Pv363wvuYlbVLLv9Fc2HhgpLnenim5U259fi/DiDpvIj4UuFnks6b6MaSLiHpyF0o6VHgfJKAf6mk9wKPAG+vvOhmxY1bauG5rfDcVth7T3j2Oc+4tdzLMpzz3CLH/niiiyLi7IjYNyLaImJRRHw1Ip6OiNdHxEsj4qSIeGbSJTabQMnhmQODnnFrRvkc/9nAOcBBkgpTPXMBB2ybEUZTOt09vWy//SFmve7VHp5pNoFyOf4fAo8DC4F/Kji+FbivloUyy6IwpSPSDVG++72S54+29M3yrlyO/xGSPPyx9SuOWXYl97id3QHDw87lm5VQMscv6bb061ZJvQX/tkoqMS7OrH5KDs/c0e9cvlkZ5Vr8x6df59avOGbFjVs982WLvXqmWYXKjuqR1CrpoXoVxqyYoqtn3nkfzJnt1TPNKlA28EfEMPATSQfWqTxm45QcntnWtnP1zMApHbOssqzVswfwY0l3AttGD0bEm2tWKrMCWYZn5nENF7NKZQn8n655KcxS45ZaWFB08VbAwzPNKjVh4I+IW+pRELOSSy3ssxc8/ayHZ5pVyYRLNkg6RtJdkvokDUga9nBOq4WSuXwPzzSrqiypni8DZwGXAd3AHwEvq2WhLH8iwkstmNVJlsBPRPxMUms6yudrkjYCn6xt0ayZ7ZLLn9cJu88pea5z+WbVlSXwb5fUTrIZyz+QrN+TaZN2s2LG5fJ7+6C3Dx24H/H4k87lm9VYlgD+bqAV+CDJcM4DgDNrWShrbiXX2Ontcy7frA6yjOp5JH35PHBBbYtjeeBcvtn0mjDwS7qf8VstPkeyNeP/iIinJ/tQSX8BvC+97/3AeyJix2TvYzPfuHH58zpLnutcvll9ZEn1XA9cC7wz/fdfJEH/t8DFk32gpP2BDwPdEbGEJI101mTvYzPfuDV2nttK/PpxWLQPtI1pcziXb1Y3WTp3T4qIVxW8v1/SPRHxKknvmsJzd5M0CMwBHqvwPjaDlRyX37edtjNW7LLaZtspJzjFY1YnWQJ/q6RXR8SdAJKOJmmlAxTpoSsvIn4j6ULgVyT9BjdGxI2TvY/NfM7lm81MiiLrme9yQhLoLwI6AQG9wHuBB4BTI+LSST1Q2gO4AngH0EMyMezyiPjWmPNWAisBurq6lq5evXoyj9mpr6+Pzs7SeeVmNO11jmCfXz7OoocfRUU+7p/dzn3LjqzqI6e9ztPAdc6HqdR5+fLlGyKie+zxCQP/zhOlFwFExHMVleCF+/whsCIi3pu+/yPgmIj481LXdHd3x913313R8/K4amO96zx2MlZ0tMPvnkGL9iGeeGrcuPxaDNH09zkfXOfJkVQ08GcZ1fMi4HzghPT9LcBnp/AL4FfAMZLmkKR6Xk/SWWwNqOhkLKD16CPoOOMUhjY96Fy+2QyTJcd/EbAZeHv6/t3A14AzKnlgRNwh6XLgHpI+go3AqkruZdOvVAfuyE+3IMm5fLMZKEvgPyQiCmfqXiBp01QeGhHnk/wVYQ2uXAeumc1MWQL/85KOj4jbACQdR5KisZwZt+H5yw8uea4nY5nNXFkC//uBb4x27gLPAufWrkg2E43L5ff0MnzHJuicAzsGYMgLq5k1igln7kbEvRHxSuAI4IiIOAo4seYlsxml5GSsWbNoP9MLq5k1kkzr8QNERGHS9i+BL1a/ODZTeTKWWfOodF39YvNyrEnF0DB0tBX9zLl8s8aTucU/RrZZX9aQxk3ImjUL+gehRTBS8K13Lt+sIZUM/JK2UjzAC9itZiWyaVVyQtaxr6L1wP08GcusCZQM/BExt54FsZmh5ISsB3/G7NNPcqA3awLeO9d24QlZZs3Pgd92GunphdbiPxLuxDVrHpV27loTKOzEpXMODAwCgtZWGB5+4UR34po1FQf+nBrbiUvfdgDa3vg6NG+uO3HNmlglo3oAiAj/7d/ASnXiDv1oI3M+8X4HerMmNuGoHkl/BzwOfJNkKOc7gX3rUjqrGXfimuVXls7dN0fE/4mIrRHRGxH/Bpxe64JZ7Yw80wMt7sQ1y6ssOf5tkt4JrCZJ/ZwNbKtpqayqinbitghaWmHInbhmeZOlxX8Oye5bT6T//jA9Zg1gtBN3ZwqnbzsMDNJ28vG0n/lGr6pplkMTtvgjYgtVTu1Img98BVhC8lfEn0TEj6r5DEuU7MT9oTtxzfJqwha/pJdJuknS5vT9EZL+dorP/RJwQ0S8Angl8OAU72cluBPXzMbKkur5D+CTwCBARNwHnFXpA9OdvE4AvprebyAieiq9n5UWA4Mwq/gfde7ENcsvRZRfYVnSXRFxtKSN6e5bSNoUEUdW9EDpSGAV8ABJa38DcF5EbBtz3kpgJUBXV9fS1atXV/I4+vr66OzsrOjaRrPgsadY9PCjtO8YYKCjjWhpoeP5fkKipeD7PNzSwpYli3lmv4XTWNrqytP3eZTrnA9TqfPy5cs3RET32ONZRvU8JekQ0slckt5GMq6/UrOAVwEfiog7JH0J+ATw6cKTImIVyS8Iuru7Y9myZRU9bN26dVR6bSMZ3PgAAzfdszOf39E/CEDrcUtpXbTvLjNxdzvlBI5ostx+Xr7PhVznfKhFnbME/g+QBOBXSPoN8EuSSVyVehR4NCLuSN9fThL4bQpKLqf8458y+02vdyeume1UNvBLagX+PCJOkrQ70BIRW6fywIj4raRfS3p5RPwEeD1J2semwJ24ZpZV2cAfEcOSjk9fV3PS1oeAb0tqB34BvKeK986n3efAtu3jDrsT18zGypLq2SjpauAyCmbsRsSVlT40IjYB4zocrDJD9/8Eto8P+p6Ja2bFZAn8s4GngRMLjgVQceC3qdllCYY5s2H7DlpevD+tS5cw9P0fMdLTS4uXUzazErLM3HUaZgYZt47+9h0g0dp9OO1HH0H7q1+Zy5EPZpbdhIFf0mzgvcBhJK1/ACLiT2pYLiuh6OidCIZu+iHtRx8xPYUys4aSZebuN4F9gFOAW4BFwJRG9ljlPHrHzKYqS+B/SUR8GtgWEV8HTgVeU9tiWUmzO4oe9ugdM8sqS+AfTL/2SFoCvAjYu3ZFslIG1t4GO/pB2vUDj94xs0nIMqpnlaQ9SJZUuBroBP57TUtlwJjRO7M7YEc/s5Yejg4+kKG1t3ozdDOrSJZRPV9JX94CHFzb4tiocaN3dvRDi9DBB9K+9DDalx42vQU0s4aVZVRP0dZ9RHy2+sWxUUVH74wEQ2tvddA3synJtOduwevZwGl445Sa8+gdM6uVLKmefyp8L+lCYE3NSmSJ3WbD8zvGHfboHTObqiyjesaaQzKW32pkcMPmJOh79I6Z1UCWHP/9pJuwAK3AXoDz+zUytPlhBi6/npaXvJjWIw9l6Hs/8OgdM6uqLDn+0wpeDwFPRMT4HT+sYrsM2wRYMJ/Z734r6minvfvw6S2cmTWdLKmerQX/ngfmSVow+q+mpcuB0WGbu3Tabu1j6IGfTV+hzKypZWnx3wMcADwLCJgP/Cr9LPDY/ikpOmxzcIjBNeud1jGzmsjS4l8LvCkiFkbEniSpnxsj4qCIcNCfIg/bNLN6yxL4j4mI60bfRMT1wGun+mBJrZI2SrpmqvdqVPH8Dmgp/i3wsE0zq5Usgf8xSX8raXH671PAY1V49nnkeCJYDA2x45vfgRiB1tZdP/SwTTOroSw5/rOB84HvpO/Xp8cqJmkRyfLOnwP+cir3aiS7jN5pmwWDQ3S841QC7TzuYZtmVmuKiInPGj05WaWzJyZzUfH7XA78L2Au8LGIOK3IOSuBlQBdXV1LV69eXdGz+vr66OzsnEJpq2PBY0+xePMWWkdGdh4bkfjl4QfxzH4Lq/qsmVLnenKd88F1npzly5dviIjuscdLtvjTxdkujYiHJHUA1wOvBIYlnRMR36ukIJJOA56MiA2SlpU6LyJWAasAuru7o9I9ZGfK/rPbP//vREHQB2iJ4CW/eoo557ytqs+aKXWuJ9c5H1zn6iiX438H8JP09bnpuXsDrwP+5xSeeRzwZklbgNXAiZK+NYX7NQSP3jGzmaJc4B8oSOmcAlwSEcMR8SDZ+gaKiohPRsSiiFgMnAV8PyLeVen9GoXm7l78uEfvmFmdlQv8/ZKWSNoLWA7cWPDZnNoWq7nEtufHpXkAj94xs2lRLvCfB1wOPAT8c0T8EkDSHwAbq/HwiFhXrGO3mcTwMDu+fRX0DzDrpON2tvA1fx7tZ6zw6B0zq7uSKZuIuAN4RZHj1wHXjb/Cihm4+iZGfvFrOt5xKrOOOgxOOm66i2RmOVdxrt5KG7vaZssrDkmCvpnZDFDJRixWRrHVNkd+/giDGx+YxlKZmb3Agb/Kyq22aWY2E2RK9Uh6LbC48PyI+EaNytTQPF7fzGa6LFsvfhM4BNgEDKeHA3DgL6a9DQYGxx32eH0zmymytPi7gUOnuj5PHgxu2JwE/ZYWKBy37/H6ZjaDZMnxbwb2qXVBGt3Ib3/HwFU30nLwAbSducLj9c1sxsrS4l8IPCDpTqB/9GBEvLlmpWowsaOfHd+6Cs3uoOPsN9Eyt5P2pUumu1hmZkVlCfyfqXUhGtXY8fqzlh9Ly9x8LRlrZo1nwsAfEbfUoyCNZnS8fuHQzaHb7qJl7z2d1jGzGW3CHL+kYyTdJalP0oCkYUm5H5vo8fpm1qiydO5+mWSrxZ8CuwHvA/61loVqBB6vb2aNKtPM3Yj4GdCarsf/NWBFbYvVANrbih72eH0zm+mydO5ul9QObJL0D8Dj5Hyph6H7HvJ4fTNrWFkC+LvT8z4IbAMOAM6sZaFmspGeXvqvXEPLAft6vL6ZNaQso3oekbQbsG9EXDDVB0o6gGS5hy6SpR9WRcSXpnrfeoiREfr/81oYGaHjrNNo2XMPj9c3s4aTZa2eNwEXAu3AQZKOBD47hQlcQ8BHI+IeSXOBDZLWRsSMXLd4l7H6sztgRz/tb3sjLXvuMd1FMzOrSJZUz2eAVwM9ABGxCTio0gdGxOMRcU/6eivwILB/pferpXFr6+/oB4loyXUXh5k1OE209pqk2yPiGEkbI+Ko9Nh9EXHElB8uLQbWA0sionfMZyuBlQBdXV1LV69eXdEz+vr66OysbDbtEes20bFjYNzx/tnt3LfsyIruWQ9TqXOjcp3zwXWenOXLl2+IiO6xx7OM6vmxpHOAVkkvBT4M/LCiUhSQ1AlcAXxkbNAHiIhVwCqA7u7uWLZsWUXPWbduHZVeu+2GO4se79gxUPE962EqdW5UrnM+uM7VkSVn8SHgMJIF2i4BeoGPTOWhktpIgv63I+LKqdyrlkqNyfdYfTNrZBMG/ojYHhGfioijI6I7fb2j0gdKEvBV4MGI+EKl96mHWSe+dvxBj9U3swZXMtUj6epyF05hVM9xJHMD7pe0KT32NxFxXYX3q5l4/MnkRecc6NuO5s+j7ZQTPFbfzBpauRz/scCvSdI7dwCqxgMj4rZq3auWhn/+K4Z+dA+zjltKx5teP93FMTOrmnKBfx/gDSQLtJ0DXAtcEhE/rkfBplMMDNB/xfVoz/m0O61jZk2mZOCPiGHgBuAGSR0kvwDWSbogIr5crwLWyy4TtdIN02f/6dmoxGJsZmaNquxwzjTgn0oS9BcD/xv4Tu2LVV/jNlUZGIQWMdKzldbpLZqZWdWV69z9BrAEuA64ICI2161UdVZ0U5WRYHDNenfkmlnTKdfifxfJapznAR9ORmECScdsRETTDGb3pipmliflcvy5WZBG8+cVDfKeqGVmzSg3wb2cWSd5opaZ5UeWtXqa3++eTb7uPge2eaKWmTW33Af+4V8/zuD6O5l19BF0nOmthM2s+eU61RNDw/Rffj2auzvtpy6f7uKYmdVFrgP/4M0/Ip54iva3noxmd0x3cczM6iJ3qZ5dZugCOnA/Zv3eS6a5VGZm9ZOrFv+4rRRJVuAc3Dgjt/s1M6uJfAX+YjN0B4eS42ZmOZGrwO8ZumZmOQr8EQEd7UU/8wxdM8uT3AT+wbW3Qf8AtIzZA8YzdM0sZ6ZlVI+kFcCXgFbgKxHx+Wo/Y3T0TndPL9vW3Qs7+pnVfTg66ECG1t5K9PR6hq6Z5VLdA7+kVuBfSXb3ehS4S9LVEVG1oTWF6+sLYEc/SOigA2lfehjtSw+r1qPMzBrOdKR6Xg38LCJ+EREDwGrg9Go+oOjonQiG1t5azceYmTWk6Uj17E+yifuoR4HXjD1J0kpgJUBXVxfr1q3L/IDunt6iu7mP9PRO6j6Nqq+vLxf1LOQ654PrXB0zduZuRKwCVgF0d3fHsmXLMl+7/faHig7RbJk/j8ncp1GtW7cuF/Us5Drng+tcHdOR6vkNcEDB+0XpsappO+UEaBvzO82jd8zMgOlp8d8FvFTSQSQB/yzgnGo+YHSUzuCa9Yz09NLi0TtmZjvVPfBHxJCkD8U8ILQAAAaSSURBVAJrSIZzXhQRP672c9qOOpS2ow7N5Z+GZmblTEuOPyKuA66bjmebmeVdbmbumplZwoHfzCxnHPjNzHLGgd/MLGcUEdNdhglJ+h3wSIWXLwSeqmJxGoHrnA+ucz5Mpc4vjoi9xh5siMA/FZLujoju6S5HPbnO+eA650Mt6uxUj5lZzjjwm5nlTB4C/6rpLsA0cJ3zwXXOh6rXuelz/GZmtqs8tPjNzKyAA7+ZWc40deCXtELSTyT9TNInprs8tSDpIklPStpccGyBpLWSfpp+3WM6y1hNkg6QdLOkByT9WNJ56fFmrvNsSXdKujet8wXp8YMk3ZH+fP+npPbpLmu1SWqVtFHSNen7pq6zpC2S7pe0SdLd6bGq/2w3beAv2NT9jcChwNmSmnFB/ouBFWOOfQK4KSJeCtyUvm8WQ8BHI+JQ4BjgA+n3tZnr3A+cGBGvBI4EVkg6Bvh74J8j4iXAs8B7p7GMtXIe8GDB+zzUeXlEHFkwdr/qP9tNG/ipw6buM0FErAeeGXP4dODr6euvA2+pa6FqKCIej4h70tdbSYLC/jR3nSMi+tK3bem/AE4ELk+PN1WdASQtAk4FvpK+F01e5xKq/rPdzIG/2Kbu+09TWeqtKyIeT1//FuiazsLUiqTFwFHAHTR5ndOUxybgSWAt8HOgJyKG0lOa8ef7i8DHgZH0/Z40f50DuFHSBkkr02NV/9mesZutW3VEREhqujG7kjqBK4CPRERv0hhMNGOdI2IYOFLSfOA7wCumuUg1Jek04MmI2CBp2XSXp46Oj4jfSNobWCvpocIPq/Wz3cwt/ppv6j6DPSFpX4D065PTXJ6qktRGEvS/HRFXpoebus6jIqIHuBk4FpgvabTx1mw/38cBb5a0hSRNeyLwJZq7zkTEb9KvT5L8gn81NfjZbubAv3NT97Tn/yzg6mkuU71cDZybvj4X+O40lqWq0jzvV4EHI+ILBR81c533Slv6SNoNeANJ38bNwNvS05qqzhHxyYhYFBGLSf7f/X5EvJMmrrOk3SXNHX0NnAxspgY/2009c1fSH5DkCUc3df/cNBep6iRdAiwjWbr1CeB84CrgUuBAkuWs3x4RYzuAG5Kk44Fbgft5Iff7NyR5/mat8xEknXqtJI21SyPis5IOJmkNLwA2Au+KiP7pK2ltpKmej0XEac1c57Ru30nfzgL+X0R8TtKeVPlnu6kDv5mZjdfMqR4zMyvCgd/MLGcc+M3McsaB38wsZxz4zcxyxoHfGpqkt0gKSRPOZJX0EUlzpvCsP5b05UqvnwpJyyS9djqebc3Hgd8a3dnAbenXiXwEqDjwT7NlgAO/VYUDvzWsdL2e40mW5j2r4HirpAslbZZ0n6QPSfowsB9ws6Sb0/P6Cq55m6SL09dvStd83yjpe5LKLoqVrpd+Vfqs29MJV0j6jKSPFZy3WdLi9N9Dkr4t6UFJl4/+JZKux74wfd0taV26GN37gb9I12n/fUl/mN7vXknrp/5f0/LEi7RZIzsduCEiHpb0tKSlEbEBWAksBo6MiCFJCyLiGUl/SbLW+VMT3Pc24Jh0Qaz3kawQ+dEy518AbIyIt0g6EfgGybr55bwceG9E/EDSRcCfAxcWOzEitkj6d6AvIi4EkHQ/cEq6oNf8CZ5ltgu3+K2RnU0yfZ/062i65yTg/44u31vB9PZFwJo0uP4VcNgE5x8PfDN91veBPSXNm+CaX0fED9LX30rvMRk/AC6W9N9IlnIwy8wtfmtIkhaQrNh4eLpMbSsQkv5qErcpXK9kdsHrfwG+EBFXp+vEfKbCYg6xa+Oq8Blj10oZfV94zWxKiIj3S3oNyUYlG9K/dp6usJyWM27xW6N6G/DNiHhxRCyOiAOAXwK/T7JRyZ+OLt+b/pIA2ArMLbjHE5J+T1IL8NaC4y/iheV+z2VitwLvTJ+1DHgqInqBLcCr0uOvAg4quOZAScemr88hSS+RXrM0fX1mwfm7lF3SIRFxR0T8d+B37LoEuVlZDvzWqM7mhZUMR12RHv8K8CvgPkn3kgRWgFXADaOduyR7l14D/BB4vOA+nwEuk7QBmKg/YPT8pZLuAz7PC78srgAWSPox8EHg4YJrfkKyX/CDwB7Av6XHLwC+pGSj7eGC8/8LeOto5y7wj0o25d6clv/eDOU0A7w6p1ndpaN0romIJdNcFMspt/jNzHLGLX4zs5xxi9/MLGcc+M3McsaB38wsZxz4zcxyxoHfzCxn/j9Pw3VFqveHjgAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BylzTZ1W9Ma"
      },
      "source": [
        "## Question 4\n",
        "\n",
        "Why do we add $1$ to the outputs before passing it through $\\log()$? \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX5w42vRXMWj"
      },
      "source": [
        "### Answer 4\n",
        "\n",
        "Adding one helps to maintain numbers larger than zero because we cannot calculate the log of a negative number."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaQiO_XeYTjE"
      },
      "source": [
        "## Question 5\n",
        "\n",
        "Write your observations about MSE, MAE, and MSLE; and compare the results achieved with all 3 loss functions. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOUf7iOkYxcM"
      },
      "source": [
        "### Answer 5\n",
        "\n",
        "MSE penalizes higher error outputs more than the others. With MSLE(Logarithmic) it is the same as MSE but it takes into consideration the log of actual/estimated outputs. MSE is also a V shape. MSLE is the opposite compared to MAE since it penalizes less strictly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Efp4KP5GfDL7"
      },
      "source": [
        "## Question 6\n",
        "\n",
        "Plug-in any of the loss functions from [TensorFlow](https://www.tensorflow.org/api_docs/python/tf/keras/losses) docs to the `model.compile` method and see if the difference in model performance as compared to MSE, MAE, and MSLE."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_9nfLOffJ_P"
      },
      "source": [
        "### Answer 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDWlkms1flkZ",
        "outputId": "e97d269f-3a14-4d2e-b8a5-9e56e28da672",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = keras.Sequential([\n",
        "        tf.keras.layers.Dense(100, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(50, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(20, activation='relu', input_shape=[len(train_features[0])]),\n",
        "        tf.keras.layers.Dense(1)\n",
        "    ])\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['binary_crossentropy'])\n",
        "\n",
        "\n",
        "# Things plugged in.\n",
        "\n",
        "  #tf.keras.losses.MeanAbsolutePercentageError()\n",
        "    #tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "      #tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "  #['mean_absolute_percentage_error']\n",
        "    #['sparse_categorical_crossentropy']\n",
        "    #['binary_crossentropy']\n",
        "\n",
        "model.fit(train_features, train_labels, epochs=500, validation_split = 0.1)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "12/12 [==============================] - 2s 23ms/step - loss: 16.9385 - binary_crossentropy: 16.9385 - val_loss: -121.8883 - val_binary_crossentropy: -121.8883\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -222.8250 - binary_crossentropy: -222.8250 - val_loss: -288.6686 - val_binary_crossentropy: -288.6686\n",
            "Epoch 3/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -319.0729 - binary_crossentropy: -319.0729 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 4/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -326.5595 - binary_crossentropy: -326.5595 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 5/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 6/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 7/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 8/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 9/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 10/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 11/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 12/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 13/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 14/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 15/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 16/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 17/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 18/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 19/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 20/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 21/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 22/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 23/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 24/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 25/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 26/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 27/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 28/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 29/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 30/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 31/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 32/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 33/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 34/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 35/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 36/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 37/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 38/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 39/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 40/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 41/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 42/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 43/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 44/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 45/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 46/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 47/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 48/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 49/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 50/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 51/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 52/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 53/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 54/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 55/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 56/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 57/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 58/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 59/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 60/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 61/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 62/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 63/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 64/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 65/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 66/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 67/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 68/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 69/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 70/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 71/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7661 - binary_crossentropy: -327.7661 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 72/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 73/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 74/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 75/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 76/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 77/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 78/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 79/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 80/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 81/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 82/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 83/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 84/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 85/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 86/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 87/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 88/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 89/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 90/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 91/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 92/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 93/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 94/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 95/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 96/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 97/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 98/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 99/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 100/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 101/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 102/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 103/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 104/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 105/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 106/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 107/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 108/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 109/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 110/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 111/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 112/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 113/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 114/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 115/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 116/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 117/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 118/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 119/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 120/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 121/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 122/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 123/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 124/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 125/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 126/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 127/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 128/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 129/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 130/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 131/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 132/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 133/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 134/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 135/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 136/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 137/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 138/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 139/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 140/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 141/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 142/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 143/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 144/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 145/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 146/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 147/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 148/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 149/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 150/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 151/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 152/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 153/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 154/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 155/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 156/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 157/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 158/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 159/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 160/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 161/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 162/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 163/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 164/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 165/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 166/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 167/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 168/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 169/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 170/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 171/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 172/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 173/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7661 - binary_crossentropy: -327.7661 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 174/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 175/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 176/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 177/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 178/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 179/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 180/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 181/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 182/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 183/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 184/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 185/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 186/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 187/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 188/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 189/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 190/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 191/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 192/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 193/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 194/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 195/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 196/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 197/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 198/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 199/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 200/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 201/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 202/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 203/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 204/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 205/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 206/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 207/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 208/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 209/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 210/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 211/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 212/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 213/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 214/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 215/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 216/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 217/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 218/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 219/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 220/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 221/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 222/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 223/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 224/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 225/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 226/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 227/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 228/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 229/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 230/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 231/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 232/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 233/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 234/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 235/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 236/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 237/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 238/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 239/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 240/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 241/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 242/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 243/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 244/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 245/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 246/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 247/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 248/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 249/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 250/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 251/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 252/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 253/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 254/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 255/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 256/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 257/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 258/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 259/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 260/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 261/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 262/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 263/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 264/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 265/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 266/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 267/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 268/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 269/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 270/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 271/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 272/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 273/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 274/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 275/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 276/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 277/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 278/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 279/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 280/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 281/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 282/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 283/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 284/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 285/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 286/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 287/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 288/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 289/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 290/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 291/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 292/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 293/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 294/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 295/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 296/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 297/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 298/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 299/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 300/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 301/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 302/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 303/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 304/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 305/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 306/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 307/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 308/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 309/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 310/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 311/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 312/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 313/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 314/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 315/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 316/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 317/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 318/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 319/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 320/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 321/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 322/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 323/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 324/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 325/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 326/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 327/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 328/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 329/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 330/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 331/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 332/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 333/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 334/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 335/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 336/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 337/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 338/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 339/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 340/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 341/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 342/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 343/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 344/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 345/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 346/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 347/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 348/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 349/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 350/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 351/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 352/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 353/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 354/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 355/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 356/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 357/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 358/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 359/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 360/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 361/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 362/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 363/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 364/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 365/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 366/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 367/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 368/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 369/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 370/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 371/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 372/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 373/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 374/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 375/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 376/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 377/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 378/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 379/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 380/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 381/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 382/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 383/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 384/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 385/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 386/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 387/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 388/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 389/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 390/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 391/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 392/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 393/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 394/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 395/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 396/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 397/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 398/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 399/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 400/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 401/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 402/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 403/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 404/500\n",
            "12/12 [==============================] - 0s 13ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 405/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 406/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 407/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 408/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 409/500\n",
            "12/12 [==============================] - 0s 14ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 410/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 411/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 412/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 413/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 414/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 415/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 416/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 417/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 418/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 419/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 420/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 421/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 422/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 423/500\n",
            "12/12 [==============================] - 0s 12ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 424/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 425/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 426/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 427/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 428/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 429/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 430/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 431/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 432/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 433/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 434/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 435/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 436/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 437/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 438/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 439/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 440/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 441/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 442/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 443/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 444/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 445/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 446/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 447/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 448/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 449/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 450/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 451/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 452/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 453/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 454/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 455/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 456/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 457/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 458/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 459/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 460/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 461/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 462/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 463/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 464/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 465/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 466/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 467/500\n",
            "12/12 [==============================] - 0s 6ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 468/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 469/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 470/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 471/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 472/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 473/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 474/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 475/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 476/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 477/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 478/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 479/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 480/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 481/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7661 - binary_crossentropy: -327.7661 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 482/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 483/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 484/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 485/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 486/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 487/500\n",
            "12/12 [==============================] - 0s 10ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 488/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 489/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 490/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 491/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 492/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 493/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 494/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 495/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 496/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 497/500\n",
            "12/12 [==============================] - 0s 8ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 498/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 499/500\n",
            "12/12 [==============================] - 0s 7ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n",
            "Epoch 500/500\n",
            "12/12 [==============================] - 0s 9ms/step - loss: -327.7662 - binary_crossentropy: -327.7662 - val_loss: -312.9070 - val_binary_crossentropy: -312.9070\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4146538a60>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RDBtUuYjuFh"
      },
      "source": [
        "# **Upload this Day 5 Colab Notebook to your Github repository under \"Day 5\" folder. Also add your *Reflection* on today's learning in README.md**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mupD9JvzD1BU"
      },
      "source": [
        "#Fun Fact\n",
        "\n",
        "Google Translate is getting better all the time, but it's still not perfect. Translate a sentence into another language and back into English, and you might get a hilarious surprise. That's what Malinda Kathleen Reese got when she reverse Google Translated the lyrics to \"Let It Go\" from Disney's Frozen into Chinese, Macedonian, French, Polish, Creole, Tamil and others. It doesn't come out as utter gibberish, but as a slightly off version with a slightly different message from the original. Which makes it even funnier. Plus, Malinda can really sing.\n",
        "\n",
        "Link to video: https://www.youtube.com/watch?v=2bVAoVlFYf0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cgg0bvRjS9un"
      },
      "source": [
        "Sources:\n",
        "\n",
        "https://towardsdatascience.com/common-loss-functions-in-machine-learning-46af0ffc4d23\n",
        "\n",
        "https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/mean-squared-logarithmic-error-(msle)"
      ]
    }
  ]
}